<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Valeurs propres | IA4Ndada</title>

    <!-- MathJax pour les formules mathÃ©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">ğŸ  Accueil</a>
          <span>â€º</span>
          <span>ğŸ§® MathÃ©matiques</span>
          <span>â€º</span>
          <span>Valeurs propres</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>ğŸ¯ Valeurs propres et Vecteurs propres</h1>
      <p class="subtitle">Module 1.3 - AlgÃ¨bre LinÃ©aire pour l'IA</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>ğŸ¯ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajoutÃ©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajoutÃ© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>ğŸ‰ Checkpoint - Valeurs propres</h3>
        <p>
          FÃ©licitations ! Vous comprenez maintenant comment l'IA trouve les
          directions les plus importantes dans les donnÃ©es.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme complÃ©tÃ©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="matrices.html" class="nav-link" id="prev-link"
          >â† Module prÃ©cÃ©dent : Matrices</a
        >
        <a href="derivatives.html" class="nav-link" id="next-link"
          >Module suivant : DÃ©rivÃ©es â†’</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Valeurs propres
      const moduleConfig = {
        id: "math-eigenvalues",
        title: "Valeurs propres et Vecteurs propres",
        category: "MathÃ©matiques",
        objectives: [
          "Comprendre les espaces vectoriels et les bases",
          "MaÃ®triser les valeurs propres et vecteurs propres",
          "DÃ©couvrir les dÃ©compositions matricielles (eigen, SVD)",
          "Comprendre les applications en IA (PCA, compression)",
        ],
        content: [
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Espaces vectoriels : l'environnement des vecteurs",
            content: `
                        <p>Un <strong>espace vectoriel</strong> est l'environnement mathÃ©matique oÃ¹ vivent les vecteurs. C'est comme dÃ©finir les rÃ¨gles du jeu avant de commencer Ã  jouer.</p>
                        
                        <p><strong>ğŸ”‘ RÃ¨gles fondamentales :</strong></p>
                        <ul>
                            <li>â• <strong>Addition</strong> : on peut additionner deux vecteurs</li>
                            <li>âœ–ï¸ <strong>Multiplication scalaire</strong> : on peut multiplier par un nombre</li>
                            <li>ğŸ¯ <strong>Vecteur zÃ©ro</strong> : point de rÃ©fÃ©rence neutre</li>
                            <li>â†”ï¸ <strong>Vecteur opposÃ©</strong> : pour chaque vecteur, il existe son opposÃ©</li>
                        </ul>
                        
                        <p><strong>ğŸŒ Exemples concrets :</strong></p>
                        <ul>
                            <li>ğŸ“ <strong>â„Â²</strong> : plan (positions sur une carte)</li>
                            <li>ğŸ“¦ <strong>â„Â³</strong> : espace (objets dans une piÃ¨ce)</li>
                            <li>ğŸ¤– <strong>â„â¿</strong> : donnÃ©es IA (n caractÃ©ristiques par exemple)</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Pourquoi important en IA ?</strong></p>
                        <p>Chaque donnÃ©e devient un point dans un espace vectoriel. L'IA trouve des patterns en analysant la gÃ©omÃ©trie de cet espace.</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : espaces vectoriels",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>VÃ©rifiez que â„Â² est bien un espace vectoriel en testant les propriÃ©tÃ©s :</p>
                        
                        <p><strong>ğŸ“ Soient :</strong> \\(\\vec{u} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}\\), \\(\\vec{v} = \\begin{bmatrix} 1 \\\\ 4 \\end{bmatrix}\\), \\(\\vec{0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\)</p>
                        
                        <ol>
                            <li>Calculez \\(\\vec{u} + \\vec{v}\\) et \\(\\vec{v} + \\vec{u}\\) (commutativitÃ©)</li>
                            <li>Calculez \\(3 \\times \\vec{u}\\) (multiplication scalaire)</li>
                            <li>VÃ©rifiez que \\(\\vec{u} + \\vec{0} = \\vec{u}\\) (Ã©lÃ©ment neutre)</li>
                            <li>Trouvez \\(-\\vec{u}\\) tel que \\(\\vec{u} + (-\\vec{u}) = \\vec{0}\\)</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('vector-space-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="vector-space-exercise" style="display: none;">
                        <ol>
                            <li>\\(\\vec{u} + \\vec{v} = \\begin{bmatrix} 3 \\\\ 7 \\end{bmatrix} = \\vec{v} + \\vec{u}\\) âœ“</li>
                            <li>\\(3 \\times \\vec{u} = \\begin{bmatrix} 6 \\\\ 9 \\end{bmatrix}\\)</li>
                            <li>\\(\\vec{u} + \\vec{0} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} = \\vec{u}\\) âœ“</li>
                            <li>\\(-\\vec{u} = \\begin{bmatrix} -2 \\\\ -3 \\end{bmatrix}\\) car \\(\\vec{u} + (-\\vec{u}) = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\) âœ“</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Base d'un espace vectoriel : systÃ¨me de coordonnÃ©es",
            content: `
                        <p>Une <strong>base</strong> est un ensemble de vecteurs qui servent de "systÃ¨me de coordonnÃ©es" pour tout l'espace. Avec une base, on peut dÃ©crire n'importe quel vecteur de l'espace.</p>
                        
                        <p><strong>ğŸ§­ Analogie simple :</strong></p>
                        <p>Pour dÃ©crire une position sur une carte, on utilise :</p>
                        <ul>
                            <li>ğŸ“ <strong>Direction Est-Ouest</strong> : combien de km vers l'est</li>
                            <li>ğŸ“ <strong>Direction Nord-Sud</strong> : combien de km vers le nord</li>
                        </ul>
                        <p>Ces deux directions forment une "base" pour localiser n'importe quel point !</p>
                        
                        <p><strong>ğŸ”‘ PropriÃ©tÃ©s d'une base :</strong></p>
                        <ul>
                            <li>ğŸ¯ <strong>IndÃ©pendance linÃ©aire</strong> : aucun vecteur ne peut Ãªtre obtenu en combinant les autres</li>
                            <li>ğŸ“ <strong>GÃ©nÃ©ration</strong> : tout vecteur de l'espace peut Ãªtre Ã©crit comme combinaison de la base</li>
                            <li>ğŸ“Š <strong>Dimension</strong> : nombre de vecteurs dans la base = dimension de l'espace</li>
                        </ul>
                        
                        <p><strong>ğŸ“ Base canonique de â„Â² :</strong></p>
                        <p>$$\\vec{e_1} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad \\vec{e_2} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$</p>
                        <p>Tout vecteur \\(\\vec{v} = \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix}\\) s'Ã©crit : \\(\\vec{v} = 3\\vec{e_1} + 4\\vec{e_2}\\)</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : bases et coordonnÃ©es",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>ConsidÃ©rons une nouvelle base \\(\\mathcal{B} = \\{\\vec{b_1}, \\vec{b_2}\\}\\) avec :</p>
                        <p>$$\\vec{b_1} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\quad \\vec{b_2} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Questions :</strong></p>
                        <ol>
                            <li>VÃ©rifiez que \\(\\vec{b_1}\\) et \\(\\vec{b_2}\\) sont linÃ©airement indÃ©pendants</li>
                            <li>Exprimez \\(\\vec{v} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}\\) dans la base \\(\\mathcal{B}\\)</li>
                            <li>VÃ©rifiez votre rÃ©sultat</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('basis-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="basis-exercise" style="display: none;">
                        <ol>
                            <li><strong>IndÃ©pendance :</strong> \\(\\vec{b_1}\\) et \\(\\vec{b_2}\\) ne sont pas colinÃ©aires car \\(\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} â‰  k \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\) pour tout k âœ“</li>
                            <li><strong>Changement de base :</strong> On cherche \\(\\alpha, \\beta\\) tels que :\\(\\vec{v} = \\alpha \\vec{b_1} + \\beta \\vec{b_2}\\)
                                <br>\\(\\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} = \\alpha \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + \\beta \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\)
                                <br>SystÃ¨me : \\(\\alpha + \\beta = 3\\) et \\(\\alpha - \\beta = 1\\)
                                <br>Solution : \\(\\alpha = 2, \\beta = 1\\)</li>
                            <li><strong>VÃ©rification :</strong> \\(2\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + 1\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}\\) âœ“</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Valeurs propres : directions privilÃ©giÃ©es",
            content: `
                        <p>Les <strong>valeurs propres</strong> et <strong>vecteurs propres</strong> rÃ©vÃ¨lent les directions oÃ¹ une matrice agit le plus simplement : elle ne fait qu'Ã©tirer ou rÃ©trÃ©cir, sans rotation.</p>
                        
                        <p><strong>ğŸ¯ DÃ©finition mathÃ©matique :</strong></p>
                        <p>Pour une matrice \\(A\\), un vecteur \\(\\vec{v}\\) est un <strong>vecteur propre</strong> avec valeur propre \\(\\lambda\\) si :</p>
                        <p>$$A\\vec{v} = \\lambda\\vec{v}$$</p>
                        
                        <p><strong>ğŸ’¡ InterprÃ©tation :</strong></p>
                        <ul>
                            <li>ğŸ§­ <strong>Direction prÃ©servÃ©e</strong> : \\(\\vec{v}\\) garde sa direction</li>
                            <li>ğŸ“ <strong>Longueur modifiÃ©e</strong> : multipliÃ©e par \\(\\lambda\\)</li>
                            <li>ğŸ”„ <strong>Pas de rotation</strong> : transformation la plus simple possible</li>
                        </ul>
                        
                        <p><strong>ğŸ” Analogie du ressort :</strong></p>
                        <p>Un ressort a des directions naturelles d'Ã©tirement. Si vous tirez dans ces directions, il s'Ã©tire proprement. Si vous tirez en diagonale, il se dÃ©forme de maniÃ¨re complexe.</p>
                        
                        <p><strong>ğŸ¤– Applications en IA :</strong></p>
                        <ul>
                            <li>ğŸ“Š <strong>PCA</strong> : trouver les directions de plus grande variance</li>
                            <li>ğŸ” <strong>PageRank</strong> : Google utilise la valeur propre dominante</li>
                            <li>ğŸ§  <strong>StabilitÃ©</strong> : analyser la convergence des algorithmes</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : calcul de valeurs propres 2Ã—2",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Soit la matrice $$A = \\begin{bmatrix} 5 & 2 \\\\ 2 & 2 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Calculez :</strong></p>
                        <ol>
                            <li>Les valeurs propres \\(\\lambda_1\\) et \\(\\lambda_2\\)</li>
                            <li>Le vecteur propre pour \\(\\lambda_1\\)</li>
                            <li>VÃ©rifiez que \\(A\\vec{v_1} = \\lambda_1\\vec{v_1}\\)</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('eigenvalue-calculation-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="eigenvalue-calculation-exercise" style="display: none;">
                        <ol>
                            <li><strong>Ã‰quation caractÃ©ristique :</strong>
                                <br>\\(\\det(A - \\lambda I) = \\det\\begin{bmatrix} 5-\\lambda & 2 \\\\ 2 & 2-\\lambda \\end{bmatrix} = (5-\\lambda)(2-\\lambda) - 4 = 0\\)
                                <br>\\(\\lambda^2 - 7\\lambda + 6 = 0\\)
                                <br>\\((\\lambda - 6)(\\lambda - 1) = 0\\)
                                <br>Donc \\(\\lambda_1 = 6\\) et \\(\\lambda_2 = 1\\)</li>
                            <li><strong>Vecteur propre pour \\(\\lambda_1 = 6\\) :</strong>
                                <br>\\((A - 6I)\\vec{v} = \\vec{0}\\)
                                <br>\\(\\begin{bmatrix} -1 & 2 \\\\ 2 & -4 \\end{bmatrix}\\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\)
                                <br>De \\(-x + 2y = 0\\), on obtient \\(x = 2y\\)
                                <br>Donc \\(\\vec{v_1} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\)</li>
                            <li><strong>VÃ©rification :</strong>
                                <br>\\(A\\vec{v_1} = \\begin{bmatrix} 5 & 2 \\\\ 2 & 2 \\end{bmatrix}\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 12 \\\\ 6 \\end{bmatrix} = 6\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = 6\\vec{v_1}\\) âœ“</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title:
              "DÃ©composition en valeurs propres : dÃ©composer pour comprendre",
            content: `
                        <p>La <strong>dÃ©composition en valeurs propres</strong> consiste Ã  rÃ©Ã©crire une matrice en termes de ses directions privilÃ©giÃ©es. C'est comme dÃ©composer une transformation complexe en Ã©tapes simples.</p>
                        
                        <p><strong>ğŸ“ Formule de dÃ©composition :</strong></p>
                        <p>$$A = P \\Lambda P^{-1}$$</p>
                        
                        <p><strong>ğŸ” Composants :</strong></p>
                        <ul>
                            <li>\\(P\\) = <strong>matrice des vecteurs propres</strong> (changement de base)</li>
                            <li>\\(\\Lambda\\) = <strong>matrice diagonale des valeurs propres</strong> (Ã©tirements)</li>
                            <li>\\(P^{-1}\\) = <strong>retour Ã  la base originale</strong></li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ InterprÃ©tation gÃ©omÃ©trique :</strong></p>
                        <ol>
                            <li>\\(P^{-1}\\) : <strong>tourner vers les axes naturels</strong></li>
                            <li>\\(\\Lambda\\) : <strong>Ã©tirer dans chaque direction</strong></li>
                            <li>\\(P\\) : <strong>tourner pour revenir aux axes originaux</strong></li>
                        </ol>
                        
                        <p><strong>ğŸ¯ Avantages :</strong></p>
                        <ul>
                            <li>ğŸ” <strong>ComprÃ©hension</strong> : voir les composants fondamentaux</li>
                            <li>âš¡ <strong>Calculs efficaces</strong> : \\(A^n = P\\Lambda^n P^{-1}\\)</li>
                            <li>ğŸ›ï¸ <strong>Analyse de stabilitÃ©</strong> : valeurs propres rÃ©vÃ¨lent le comportement</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : dÃ©composition complÃ¨te",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Pour la matrice $$A = \\begin{bmatrix} 3 & 1 \\\\ 0 & 2 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Effectuez la dÃ©composition complÃ¨te :</strong></p>
                        <ol>
                            <li>Trouvez les valeurs propres</li>
                            <li>Trouvez les vecteurs propres correspondants</li>
                            <li>Construisez les matrices P et Î›</li>
                            <li>VÃ©rifiez que \\(A = P\\Lambda P^{-1}\\)</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('eigen-decomposition-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="eigen-decomposition-exercise" style="display: none;">
                        <ol>
                            <li><strong>Valeurs propres :</strong>
                                <br>\\(\\det(A - \\lambda I) = (3-\\lambda)(2-\\lambda) = 0\\)
                                <br>Donc \\(\\lambda_1 = 3\\) et \\(\\lambda_2 = 2\\)</li>
                            <li><strong>Vecteurs propres :</strong>
                                <br>Pour \\(\\lambda_1 = 3\\) : \\(\\vec{v_1} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\)
                                <br>Pour \\(\\lambda_2 = 2\\) : \\(\\vec{v_2} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\)</li>
                            <li><strong>Matrices :</strong>
                                <br>\\(P = \\begin{bmatrix} 1 & 1 \\\\ 0 & -1 \\end{bmatrix}\\), \\(\\Lambda = \\begin{bmatrix} 3 & 0 \\\\ 0 & 2 \\end{bmatrix}\\)
                                <br>\\(P^{-1} = \\begin{bmatrix} 1 & 1 \\\\ 0 & -1 \\end{bmatrix}\\)</li>
                            <li><strong>VÃ©rification :</strong>
                                <br>\\(P\\Lambda P^{-1} = \\begin{bmatrix} 1 & 1 \\\\ 0 & -1 \\end{bmatrix}\\begin{bmatrix} 3 & 0 \\\\ 0 & 2 \\end{bmatrix}\\begin{bmatrix} 1 & 1 \\\\ 0 & -1 \\end{bmatrix} = \\begin{bmatrix} 3 & 1 \\\\ 0 & 2 \\end{bmatrix} = A\\) âœ“</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "SVD : la dÃ©composition universelle",
            content: `
                        <p>La <strong>DÃ©composition en Valeurs SinguliÃ¨res</strong> (SVD) fonctionne pour TOUTES les matrices, mÃªme non carrÃ©es. C'est l'outil le plus puissant de l'algÃ¨bre linÃ©aire.</p>
                        
                        <p><strong>ğŸ¯ Pourquoi "universelle" ?</strong></p>
                        <ul>
                            <li>âœ… <strong>Matrices rectangulaires</strong> : 3Ã—5, 100Ã—50, etc.</li>
                            <li>âœ… <strong>Matrices singuliÃ¨res</strong> : dÃ©terminant = 0</li>
                            <li>âœ… <strong>Toujours possible</strong> : aucune condition restrictive</li>
                        </ul>
                        
                        <p><strong>ğŸ“ DÃ©composition SVD :</strong></p>
                        <p>$$A = U \\Sigma V^T$$</p>
                        
                        <p><strong>ğŸ” Composants :</strong></p>
                        <ul>
                            <li>\\(U\\) = <strong>vecteurs singuliers gauches</strong> (directions de sortie)</li>
                            <li>\\(\\Sigma\\) = <strong>valeurs singuliÃ¨res</strong> (facteurs d'Ã©tirement, â‰¥ 0)</li>
                            <li>\\(V^T\\) = <strong>vecteurs singuliers droits</strong> (directions d'entrÃ©e)</li>
                        </ul>
                        
                        <p><strong>ğŸµ Analogie musicale :</strong></p>
                        <p>Imaginez dÃ©composer une chanson complexe :</p>
                        <ul>
                            <li>ğŸ¥ <strong>PremiÃ¨re valeur singuliÃ¨re</strong> : rythme principal (le plus important)</li>
                            <li>ğŸ¸ <strong>DeuxiÃ¨me</strong> : mÃ©lodie principale</li>
                            <li>ğŸº <strong>Suivantes</strong> : harmonies secondaires</li>
                            <li>ğŸ”‡ <strong>Petites valeurs</strong> : dÃ©tails nÃ©gligeables</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : SVD d'une matrice simple",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Soit la matrice $$A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Calculez la SVD Ã©tape par Ã©tape :</strong></p>
                        <ol>
                            <li>Calculez \\(A^T A\\) et trouvez ses valeurs propres</li>
                            <li>Les valeurs singuliÃ¨res sont \\(\\sigma_i = \\sqrt{\\lambda_i}\\)</li>
                            <li>Trouvez les vecteurs propres de \\(A^T A\\) (colonnes de V)</li>
                            <li>Construisez la matrice \\(\\Sigma\\)</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('svd-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="svd-exercise" style="display: none;">
                        <ol>
                            <li><strong>\\(A^T A\\) :</strong>
                                <br>\\(A^T A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}\\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix} = \\begin{bmatrix} 10 & 6 \\\\ 6 & 10 \\end{bmatrix}\\)
                                <br>Valeurs propres : \\(\\det\\begin{bmatrix} 10-\\lambda & 6 \\\\ 6 & 10-\\lambda \\end{bmatrix} = (10-\\lambda)^2 - 36 = 0\\)
                                <br>\\(\\lambda_1 = 16, \\lambda_2 = 4\\)</li>
                            <li><strong>Valeurs singuliÃ¨res :</strong>
                                <br>\\(\\sigma_1 = \\sqrt{16} = 4\\), \\(\\sigma_2 = \\sqrt{4} = 2\\)</li>
                            <li><strong>Vecteurs propres de \\(A^T A\\) :</strong>
                                <br>Pour \\(\\lambda_1 = 16\\) : \\(\\vec{v_1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\)
                                <br>Pour \\(\\lambda_2 = 4\\) : \\(\\vec{v_2} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\)</li>
                            <li><strong>Matrice \\(\\Sigma\\) :</strong>
                                <br>\\(\\Sigma = \\begin{bmatrix} 4 & 0 \\\\ 0 & 2 \\end{bmatrix}\\)</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "PCA : rÃ©duction de dimension intelligente",
            content: `
                        <p>L'<strong>Analyse en Composantes Principales</strong> (PCA) utilise les valeurs propres pour identifier les directions les plus importantes dans vos donnÃ©es.</p>
                        
                        <p><strong>ğŸ¯ Objectif simple :</strong></p>
                        <p>Passer de 1000 dimensions Ã  10 dimensions en gardant 95% de l'information utile !</p>
                        
                        <p><strong>ğŸ”‘ Principe :</strong></p>
                        <ol>
                            <li><strong>Centrer</strong> : soustraire la moyenne de chaque variable</li>
                            <li><strong>Covariance</strong> : mesurer comment les variables varient ensemble</li>
                            <li><strong>Valeurs propres</strong> : trouver les directions de plus grande variance</li>
                            <li><strong>Projection</strong> : garder seulement les directions importantes</li>
                        </ol>
                        
                        <p><strong>ğŸ’¡ Analogie de la photographie :</strong></p>
                        <p>Pour photographier un objet complexe, vous cherchez le meilleur angle qui capture l'essentiel. PCA fait pareil avec les donnÃ©es : elle trouve les "angles" qui capturent le maximum d'information.</p>
                        
                        <p><strong>ğŸ¤– Applications rÃ©volutionnaires :</strong></p>
                        <ul>
                            <li>ğŸ–¼ï¸ <strong>Compression d'images</strong> : rÃ©duire la taille sans perte visible</li>
                            <li>ğŸ“Š <strong>Visualisation</strong> : afficher des donnÃ©es complexes en 2D</li>
                            <li>ğŸ§  <strong>Preprocessing ML</strong> : simplifier avant entraÃ®nement</li>
                            <li>ğŸ’¬ <strong>NLP</strong> : rÃ©duire la dimension des mots</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : PCA sur donnÃ©es Ã©conomiques",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>DonnÃ©es de 3 rÃ©gions avec 2 variables (PIB, Population) :</p>
                        <p>$$X = \\begin{bmatrix} 4 & 2 \\\\ 2 & 4 \\\\ 6 & 6 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Effectuez la PCA :</strong></p>
                        <ol>
                            <li>Centrez les donnÃ©es (soustrayez la moyenne de chaque colonne)</li>
                            <li>Calculez la matrice de covariance</li>
                            <li>Trouvez les valeurs propres de la matrice de covariance</li>
                            <li>Quelle proportion de variance explique la premiÃ¨re composante ?</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('pca-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="pca-exercise" style="display: none;">
                        <ol>
                            <li><strong>Centrage :</strong>
                                <br>Moyennes : PIB = 4, Population = 4
                                <br>\\(X_{centrÃ©} = \\begin{bmatrix} 0 & -2 \\\\ -2 & 0 \\\\ 2 & 2 \\end{bmatrix}\\)</li>
                            <li><strong>Matrice de covariance :</strong>
                                <br>\\(C = \\frac{1}{2}X_{centrÃ©}^T X_{centrÃ©} = \\frac{1}{2}\\begin{bmatrix} 8 & 4 \\\\ 4 & 8 \\end{bmatrix} = \\begin{bmatrix} 4 & 2 \\\\ 2 & 4 \\end{bmatrix}\\)</li>
                            <li><strong>Valeurs propres :</strong>
                                <br>\\(\\det\\begin{bmatrix} 4-\\lambda & 2 \\\\ 2 & 4-\\lambda \\end{bmatrix} = (4-\\lambda)^2 - 4 = 0\\)
                                <br>\\(\\lambda_1 = 6, \\lambda_2 = 2\\)</li>
                            <li><strong>Proportion de variance :</strong>
                                <br>PC1 explique : \\(\\frac{6}{6+2} = \\frac{6}{8} = 75\\%\\) de la variance
                                <br>PC2 explique : \\(\\frac{2}{8} = 25\\%\\) de la variance</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Comparaison : Eigen-dÃ©composition vs SVD",
            content: `
                        <p><strong>ğŸ¤” Quelle dÃ©composition choisir ?</strong></p>
                        
                        <table style="width: 100%; border-collapse: collapse; margin: 1rem 0;">
                            <tr style="background: #f8f9fa;">
                                <th style="padding: 0.8rem; border: 1px solid #dee2e6;">CritÃ¨re</th>
                                <th style="padding: 0.8rem; border: 1px solid #dee2e6;">Eigen-dÃ©composition</th>
                                <th style="padding: 0.8rem; border: 1px solid #dee2e6;">SVD</th>
                            </tr>
                            <tr>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;"><strong>Matrices acceptÃ©es</strong></td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">CarrÃ©es uniquement</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Toutes (carrÃ©es, rectangulaires)</td>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;"><strong>Existence garantie</strong></td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Non (matrices diagonalisables)</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Oui (toujours)</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;"><strong>StabilitÃ© numÃ©rique</strong></td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Moyenne</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Excellente</td>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;"><strong>Applications principales</strong></td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Analyse de transformations</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Analyse de donnÃ©es, ML</td>
                            </tr>
                        </table>
                        
                        <p><strong>ğŸ¯ Guide de choix :</strong></p>
                        <ul>
                            <li>ğŸ”§ <strong>Transformations gÃ©omÃ©triques</strong> â†’ Eigen-dÃ©composition</li>
                            <li>ğŸ“Š <strong>Analyse de donnÃ©es</strong> â†’ SVD</li>
                            <li>ğŸ¤– <strong>Machine Learning</strong> â†’ SVD (plus robuste)</li>
                            <li>ğŸ§® <strong>ThÃ©orie mathÃ©matique</strong> â†’ Eigen-dÃ©composition</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ En pratique :</strong> SVD est devenue l'outil de rÃ©fÃ©rence en IA car elle est plus robuste et universelle.</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : comparaison des dÃ©compositions",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Pour la matrice $$A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Comparez les deux approches :</strong></p>
                        <ol>
                            <li>Calculez la dÃ©composition en valeurs propres</li>
                            <li>Calculez les valeurs singuliÃ¨res (\\(\\sigma_i = \\sqrt{\\lambda_i}\\) oÃ¹ \\(\\lambda_i\\) sont les valeurs propres de \\(A^T A\\))</li>
                            <li>Comparez les rÃ©sultats</li>
                            <li>Cette matrice est-elle bien conditionnÃ©e ?</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('decomposition-comparison-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="decomposition-comparison-exercise" style="display: none;">
                        <ol>
                            <li><strong>Valeurs propres de A :</strong>
                                <br>\\(\\det\\begin{bmatrix} 2-\\lambda & 1 \\\\ 1 & 2-\\lambda \\end{bmatrix} = (2-\\lambda)^2 - 1 = 0\\)
                                <br>\\(\\lambda_1 = 3, \\lambda_2 = 1\\)</li>
                            <li><strong>Valeurs singuliÃ¨res :</strong>
                                <br>\\(A^T A = A^2 = \\begin{bmatrix} 5 & 4 \\\\ 4 & 5 \\end{bmatrix}\\)
                                <br>Valeurs propres de \\(A^T A\\) : \\(\\lambda_1 = 9, \\lambda_2 = 1\\)
                                <br>Valeurs singuliÃ¨res : \\(\\sigma_1 = 3, \\sigma_2 = 1\\)</li>
                            <li><strong>Comparaison :</strong>
                                <br>Valeurs propres de A : [3, 1]
                                <br>Valeurs singuliÃ¨res de A : [3, 1]
                                <br>Elles coÃ¯ncident car A est symÃ©trique !</li>
                            <li><strong>Conditionnement :</strong>
                                <br>Nombre de condition = \\(\\frac{\\sigma_{max}}{\\sigma_{min}} = \\frac{3}{1} = 3\\)
                                <br>C'est bien conditionnÃ© (< 10)</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "warning",
            icon: "âš ï¸",
            title: "Impact rÃ©volutionnaire en IA",
            content: `
                        <p><strong>ğŸš€ Ces concepts ont rÃ©volutionnÃ© l'IA moderne :</strong></p>
                        
                        <p><strong>ğŸ“Š RÃ©duction de dimension (PCA) :</strong></p>
                        <ul>
                            <li>ğŸ–¼ï¸ <strong>Images</strong> : 1M pixels â†’ 100 features essentielles</li>
                            <li>ğŸ’¬ <strong>Texte</strong> : 50k mots â†’ 300 dimensions d'embedding</li>
                            <li>ğŸ§¬ <strong>GÃ©nomique</strong> : 20k gÃ¨nes â†’ 10 signatures biologiques</li>
                        </ul>
                        
                        <p><strong>ğŸ¬ SystÃ¨mes de recommandation (SVD) :</strong></p>
                        <ul>
                            <li>ğŸµ <strong>Spotify</strong> : dÃ©couvrir vos goÃ»ts musicaux cachÃ©s</li>
                            <li>ğŸ“º <strong>Netflix</strong> : "Vous aimerez probablement..."</li>
                            <li>ğŸ›’ <strong>E-commerce</strong> : "Les clients ayant achetÃ© ceci..."</li>
                        </ul>
                        
                        <p><strong>ğŸ” Moteurs de recherche (PageRank) :</strong></p>
                        <ul>
                            <li>ğŸ” <strong>Google</strong> : classer les pages par importance</li>
                            <li>ğŸŒ <strong>RÃ©seaux sociaux</strong> : identifier les influenceurs</li>
                            <li>ğŸ“Š <strong>Analyse de rÃ©seaux</strong> : dÃ©tecter les communautÃ©s</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Point clÃ© :</strong> Les valeurs propres et la SVD ne sont pas juste des outils mathÃ©matiques - ils sont les <strong>fondations invisibles</strong> de l'IA moderne. Ils permettent de transformer des donnÃ©es complexes en insights actionnables !</p>
                    `,
          },
        ],
        quiz: {
          question:
            "ğŸ¤” Quelle est la principale diffÃ©rence entre la dÃ©composition en valeurs propres et la SVD ?",
          options: [
            "A) La SVD est plus rapide Ã  calculer",
            "B) La SVD fonctionne pour toutes les matrices, pas seulement les carrÃ©es",
            "C) Les valeurs propres sont plus prÃ©cises",
            "D) Il n'y a pas de diffÃ©rence",
          ],
          correct: 1,
          explanation:
            "La SVD est universelle et fonctionne pour toutes les matrices (carrÃ©es, rectangulaires, singuliÃ¨res), tandis que la dÃ©composition en valeurs propres ne fonctionne que pour les matrices carrÃ©es diagonalisables.",
        },
        prevModule: "matrices.html",
        nextModule: "derivatives.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
