<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Distributions de Probabilit√©s | IA4Ndada</title>

    <!-- MathJax pour les formules math√©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>üßÆ Math√©matiques</span>
          <span>‚Ä∫</span>
          <span>Distributions de Probabilit√©s</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>üìä Distributions de Probabilit√©s</h1>
      <p class="subtitle">Module 1.7 - Les formes que prennent le hasard</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajout√©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajout√© dynamiquement -->
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="probability.html" class="nav-link" id="prev-link"
          >‚Üê Module pr√©c√©dent : Probabilit√©s</a
        >
        <a href="random-variables.html" class="nav-link" id="next-link"
          >Module suivant : Variables al√©atoires ‚Üí</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      const moduleConfig = {
        id: "math-distributions",
        title: "Distributions de Probabilit√©s",
        category: "Math√©matiques",
        objectives: [
          "Comprendre ce qu'est une distribution de probabilit√©",
          "Ma√Ætriser la distribution uniforme",
          "Ma√Ætriser la distribution de Bernoulli et binomiale",
          "Ma√Ætriser la distribution normale (Gaussienne)",
          "Comprendre la distribution de Poisson",
          "Visualiser et simuler des distributions avec Python",
        ],
        content: [
          // ===== SECTION 1: INTRODUCTION =====
          {
            type: "concept",
            icon: "üí°",
            title: "Qu'est-ce qu'une distribution de probabilit√© ?",
            content: `
              <p>Une <strong>distribution de probabilit√©</strong> d√©crit comment les probabilit√©s sont r√©parties sur les diff√©rentes valeurs possibles d'une variable al√©atoire.</p>

              <p><strong>üéØ Pourquoi c'est crucial en IA ?</strong></p>
              <ul>
                <li><strong>Mod√©lisation</strong> : On suppose que nos donn√©es suivent une certaine distribution</li>
                <li><strong>G√©n√©ration</strong> : Les LLMs g√©n√®rent des mots selon une distribution de probabilit√©</li>
                <li><strong>Initialisation</strong> : Les poids des r√©seaux sont initialis√©s avec des distributions sp√©cifiques</li>
                <li><strong>Bruit</strong> : Le bruit dans les donn√©es est souvent mod√©lis√© par une distribution normale</li>
              </ul>

              <p><strong>üìä Deux types de distributions :</strong></p>
              <ul>
                <li><strong>Discr√®te</strong> : valeurs distinctes (lancer de d√©, nombre d'emails)</li>
                <li><strong>Continue</strong> : valeurs sur un intervalle (taille, temp√©rature)</li>
              </ul>
            `,
          },

          // ===== SECTION 2: DISTRIBUTION UNIFORME =====
          {
            type: "mathematique",
            icon: "üìè",
            title: "Distribution uniforme : l'√©galit√© parfaite",
            content: `
              <p>Dans une <strong>distribution uniforme</strong>, toutes les valeurs ont la <strong>m√™me probabilit√©</strong>.</p>

              <p><strong>üé≤ Uniforme discr√®te :</strong></p>
              <p>Exemple : un d√© √©quilibr√©</p>
              <p>$$P(X = k) = \\frac{1}{n} \\text{ pour } k \\in \\{1, 2, ..., n\\}$$</p>

              <p><strong>üìè Uniforme continue U(a, b) :</strong></p>
              <p>$$f(x) = \\begin{cases} \\frac{1}{b-a} & \\text{si } a \\leq x \\leq b \\\\ 0 & \\text{sinon} \\end{cases}$$</p>

              <p><strong>üìä Param√®tres :</strong></p>
              <ul>
                <li>Esp√©rance : \\(E[X] = \\frac{a+b}{2}\\)</li>
                <li>Variance : \\(Var(X) = \\frac{(b-a)^2}{12}\\)</li>
              </ul>

              <p><strong>ü§ñ En IA :</strong></p>
              <ul>
                <li>Initialisation al√©atoire des poids (Xavier, He)</li>
                <li>√âchantillonnage al√©atoire pour le dropout</li>
                <li>G√©n√©ration de nombres al√©atoires</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 1 : Distribution uniforme",
            content: `
              <p>Une variable X suit une distribution uniforme sur [0, 10].</p>
              <p>Quelle est l'esp√©rance E[X] ?</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 5,
            tolerance: 0,
            explanation: "E[X] = (a + b) / 2 = (0 + 10) / 2 = 5",
            completesObjective: 1,
          },

          // ===== SECTION 3: DISTRIBUTION DE BERNOULLI =====
          {
            type: "mathematique",
            icon: "üéØ",
            title: "Distribution de Bernoulli : succ√®s ou √©chec",
            content: `
              <p>La <strong>distribution de Bernoulli</strong> mod√©lise une exp√©rience avec <strong>deux issues</strong> : succ√®s (1) ou √©chec (0).</p>

              <p><strong>üìê D√©finition :</strong></p>
              <p>$$P(X = 1) = p \\quad \\text{et} \\quad P(X = 0) = 1 - p = q$$</p>

              <p><strong>üìä Param√®tres :</strong></p>
              <ul>
                <li>Esp√©rance : \\(E[X] = p\\)</li>
                <li>Variance : \\(Var(X) = p(1-p) = pq\\)</li>
              </ul>

              <p><strong>üéØ Exemples :</strong></p>
              <ul>
                <li>Un email est spam (1) ou non (0)</li>
                <li>Un patient est malade (1) ou sain (0)</li>
                <li>Un utilisateur clique (1) ou ne clique pas (0)</li>
              </ul>

              <p><strong>ü§ñ En IA :</strong></p>
              <ul>
                <li><strong>Classification binaire</strong> : la sortie d'un neurone sigmo√Øde</li>
                <li><strong>Dropout</strong> : chaque neurone est gard√© avec probabilit√© p</li>
                <li><strong>A/B testing</strong> : conversion ou non</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 2 : Variance de Bernoulli",
            content: `
              <p>Un mod√®le de classification pr√©dit "spam" avec probabilit√© p = 0.3.</p>
              <p>Quelle est la variance de cette pr√©diction de Bernoulli ?</p>
              <p>Rappel : Var(X) = p(1-p)</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 0.21,
            tolerance: 0.01,
            explanation: "Var(X) = p(1-p) = 0.3 √ó 0.7 = 0.21",
            completesObjective: 2,
          },

          // ===== SECTION 4: DISTRIBUTION BINOMIALE =====
          {
            type: "mathematique",
            icon: "üé≤",
            title: "Distribution binomiale : compter les succ√®s",
            content: `
              <p>La <strong>distribution binomiale</strong> compte le nombre de succ√®s sur n essais de Bernoulli ind√©pendants.</p>

              <p><strong>üìê Formule :</strong></p>
              <p>$$P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}$$</p>

              <p>o√π \\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\) est le coefficient binomial.</p>

              <p><strong>üìä Param√®tres :</strong></p>
              <ul>
                <li>Esp√©rance : \\(E[X] = np\\)</li>
                <li>Variance : \\(Var(X) = np(1-p)\\)</li>
              </ul>

              <p><strong>üéØ Exemple :</strong></p>
              <p>On lance 10 pi√®ces (p = 0.5). Combien de piles en moyenne ?</p>
              <p>E[X] = np = 10 √ó 0.5 = 5 piles</p>

              <p><strong>ü§ñ En IA :</strong></p>
              <ul>
                <li>Nombre de pr√©dictions correctes sur n tests</li>
                <li>Nombre de clics sur n impressions publicitaires</li>
                <li>Nombre de neurones actifs apr√®s dropout</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 3 : Esp√©rance binomiale",
            content: `
              <p>Un mod√®le a 80% de pr√©cision (p = 0.8).</p>
              <p>Sur 100 pr√©dictions, combien seront correctes en moyenne ?</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 80,
            tolerance: 0,
            explanation: "E[X] = np = 100 √ó 0.8 = 80 pr√©dictions correctes",
            completesObjective: 2,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 4 : Coefficient binomial",
            content: `
              <p>Calculez le nombre de fa√ßons de choisir 2 √©l√©ments parmi 5.</p>
              <p>C'est le coefficient binomial \\(\\binom{5}{2} = \\frac{5!}{2! \\times 3!}\\)</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 10,
            tolerance: 0,
            explanation: "C(5,2) = 5!/(2!√ó3!) = (5√ó4)/(2√ó1) = 20/2 = 10",
            completesObjective: 2,
          },

          // ===== SECTION 5: DISTRIBUTION NORMALE =====
          {
            type: "concept",
            icon: "üîî",
            title: "Distribution normale : la reine des distributions",
            content: `
              <p>La <strong>distribution normale</strong> (ou Gaussienne) est la distribution la plus importante en statistiques et en IA.</p>

              <p><strong>üîî Pourquoi "normale" ?</strong></p>
              <p>Le <strong>th√©or√®me central limite</strong> dit que la moyenne d'un grand nombre de variables al√©atoires tend vers une distribution normale, quelle que soit la distribution originale !</p>

              <p><strong>üìê Formule de densit√© :</strong></p>
              <p>$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$</p>

              <p><strong>üìä Param√®tres :</strong></p>
              <ul>
                <li>\\(\\mu\\) = moyenne (centre de la cloche)</li>
                <li>\\(\\sigma\\) = √©cart-type (largeur de la cloche)</li>
                <li>\\(\\sigma^2\\) = variance</li>
              </ul>

              <p><strong>üìè Notation :</strong> \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)</p>
            `,
          },
          {
            type: "mathematique",
            icon: "üìä",
            title: "La r√®gle 68-95-99.7",
            content: `
              <p>Pour une distribution normale, les donn√©es se r√©partissent ainsi :</p>

              <ul>
                <li><strong>68%</strong> des donn√©es dans \\([\\mu - \\sigma, \\mu + \\sigma]\\)</li>
                <li><strong>95%</strong> des donn√©es dans \\([\\mu - 2\\sigma, \\mu + 2\\sigma]\\)</li>
                <li><strong>99.7%</strong> des donn√©es dans \\([\\mu - 3\\sigma, \\mu + 3\\sigma]\\)</li>
              </ul>

              <p><strong>üîç Applications :</strong></p>
              <ul>
                <li><strong>D√©tection d'anomalies</strong> : une valeur au-del√† de 3œÉ est suspecte (probabilit√© < 0.3%)</li>
                <li><strong>Intervalles de confiance</strong> : ¬±1.96œÉ contient 95% des donn√©es</li>
                <li><strong>Contr√¥le qualit√©</strong> : les "6 sigma" en industrie</li>
              </ul>

              <p><strong>ü§ñ En IA :</strong></p>
              <ul>
                <li>Initialisation des poids : \\(W \\sim \\mathcal{N}(0, \\frac{1}{n})\\)</li>
                <li>Bruit gaussien dans les VAE et diffusion models</li>
                <li>Erreurs de r√©gression suppos√©es normales</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 5 : R√®gle 68-95-99.7",
            content: `
              <p>Les QI suivent une loi normale avec Œº = 100 et œÉ = 15.</p>
              <p>Quel pourcentage de la population a un QI entre 85 et 115 ?</p>
              <p>(Indice : 85 = 100 - 15 = Œº - œÉ)</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 68,
            tolerance: 1,
            explanation: "L'intervalle [85, 115] = [Œº-œÉ, Œº+œÉ]. Selon la r√®gle, 68% des donn√©es sont dans cet intervalle.",
            completesObjective: 3,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 6 : D√©tection d'anomalie",
            content: `
              <p>Une machine produit des pi√®ces avec un diam√®tre moyen Œº = 50mm et œÉ = 0.5mm.</p>
              <p>Une pi√®ce mesure 52mm. Combien d'√©carts-types est-elle au-dessus de la moyenne ?</p>
              <p>Z = (x - Œº) / œÉ</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 4,
            tolerance: 0,
            explanation: "Z = (52 - 50) / 0.5 = 2 / 0.5 = 4. Cette pi√®ce est √† 4œÉ de la moyenne, c'est clairement une anomalie !",
            completesObjective: 3,
          },

          // ===== SECTION 6: DISTRIBUTION DE POISSON =====
          {
            type: "mathematique",
            icon: "‚è±Ô∏è",
            title: "Distribution de Poisson : compter les √©v√©nements rares",
            content: `
              <p>La <strong>distribution de Poisson</strong> mod√©lise le nombre d'√©v√©nements qui se produisent dans un intervalle de temps ou d'espace fix√©.</p>

              <p><strong>üìê Formule :</strong></p>
              <p>$$P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$</p>

              <p><strong>üìä Param√®tres :</strong></p>
              <ul>
                <li>\\(\\lambda\\) = nombre moyen d'√©v√©nements</li>
                <li>Esp√©rance : \\(E[X] = \\lambda\\)</li>
                <li>Variance : \\(Var(X) = \\lambda\\)</li>
              </ul>

              <p><strong>üéØ Exemples :</strong></p>
              <ul>
                <li>Nombre d'emails re√ßus par heure</li>
                <li>Nombre de requ√™tes sur un serveur par seconde</li>
                <li>Nombre de bugs trouv√©s par jour</li>
                <li>Nombre de mutations dans un g√®ne</li>
              </ul>

              <p><strong>üí° Propri√©t√© remarquable :</strong></p>
              <p>Pour Poisson, E[X] = Var(X) = Œª. Si vous observez que la moyenne ‚âà variance, c'est peut-√™tre une Poisson !</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 7 : Distribution de Poisson",
            content: `
              <p>Un serveur re√ßoit en moyenne Œª = 5 requ√™tes par seconde.</p>
              <p>Quelle est la variance du nombre de requ√™tes par seconde ?</p>
              <p>(Rappel : pour Poisson, Var(X) = Œª)</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 5,
            tolerance: 0,
            explanation: "Pour une distribution de Poisson, Var(X) = Œª = 5",
            completesObjective: 4,
          },

          // ===== SECTION 7: VISUALISATION PYTHON =====
          {
            type: "code",
            icon: "üêç",
            title: "Visualiser les distributions avec Python",
            content: `
              <p>Comparons visuellement les diff√©rentes distributions :</p>
            `,
            code: `import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# 1. Distribution Uniforme
ax1 = axes[0, 0]
x_uniform = np.linspace(-0.5, 1.5, 1000)
y_uniform = stats.uniform.pdf(x_uniform, 0, 1)
ax1.plot(x_uniform, y_uniform, 'b-', linewidth=2)
ax1.fill_between(x_uniform, y_uniform, alpha=0.3)
ax1.set_title('Distribution Uniforme U(0, 1)', fontsize=12)
ax1.set_xlabel('x')
ax1.set_ylabel('Densit√© f(x)')
ax1.grid(True, alpha=0.3)

# 2. Distribution Binomiale
ax2 = axes[0, 1]
n, p = 20, 0.5
x_binom = np.arange(0, n+1)
y_binom = stats.binom.pmf(x_binom, n, p)
ax2.bar(x_binom, y_binom, color='green', alpha=0.7)
ax2.axvline(n*p, color='red', linestyle='--', label=f'E[X] = {n*p}')
ax2.set_title(f'Distribution Binomiale B({n}, {p})', fontsize=12)
ax2.set_xlabel('k (nombre de succ√®s)')
ax2.set_ylabel('P(X = k)')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. Distribution Normale
ax3 = axes[1, 0]
x_norm = np.linspace(-4, 4, 1000)
for mu, sigma, color in [(0, 1, 'blue'), (0, 0.5, 'red'), (1, 1, 'green')]:
    y_norm = stats.norm.pdf(x_norm, mu, sigma)
    ax3.plot(x_norm, y_norm, color=color, linewidth=2,
             label=f'Œº={mu}, œÉ={sigma}')
ax3.set_title('Distribution Normale', fontsize=12)
ax3.set_xlabel('x')
ax3.set_ylabel('Densit√© f(x)')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. Distribution de Poisson
ax4 = axes[1, 1]
for lam, color in [(2, 'blue'), (5, 'green'), (10, 'red')]:
    x_pois = np.arange(0, 20)
    y_pois = stats.poisson.pmf(x_pois, lam)
    ax4.plot(x_pois, y_pois, 'o-', color=color, label=f'Œª={lam}', markersize=6)
ax4.set_title('Distribution de Poisson', fontsize=12)
ax4.set_xlabel('k')
ax4.set_ylabel('P(X = k)')
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('distributions.png', dpi=100, bbox_inches='tight')
plt.show()

print("üìä R√©sum√© des distributions :")
print("‚Ä¢ Uniforme : toutes valeurs √©quiprobables")
print("‚Ä¢ Binomiale : nombre de succ√®s sur n essais")
print("‚Ä¢ Normale : forme de cloche, th√©or√®me central limite")
print("‚Ä¢ Poisson : √©v√©nements rares, E[X] = Var(X)")`,
          },
          {
            type: "exercise-code",
            icon: "üíª",
            title: "Exercice 8 : Simuler et comparer",
            content: `
              <p>Simulez 10000 lancers de 20 pi√®ces et v√©rifiez que :</p>
              <ul>
                <li>La moyenne observ√©e ‚âà np = 10</li>
                <li>La distribution ressemble √† une binomiale</li>
              </ul>
            `,
            starterCode: `import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
n_experiences = 10000
n_pieces = 20
p = 0.5

# TODO: Simuler les lancers
# Pour chaque exp√©rience, compter le nombre de "piles" (succ√®s)
# Indice: np.random.binomial(n, p, size) g√©n√®re des √©chantillons binomiaux

resultats = np.random.binomial(___, ___, ___)  # Compl√©ter

# Calculer statistiques
moyenne = ___
variance = ___

print(f"Moyenne observ√©e : {moyenne:.2f}")
print(f"Moyenne th√©orique (np) : {n_pieces * p}")
print(f"Variance observ√©e : {variance:.2f}")
print(f"Variance th√©orique (np(1-p)) : {n_pieces * p * (1-p)}")`,
            solution: `import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

np.random.seed(42)
n_experiences = 10000
n_pieces = 20
p = 0.5

# Simuler les lancers
resultats = np.random.binomial(n_pieces, p, n_experiences)

# Calculer statistiques
moyenne = np.mean(resultats)
variance = np.var(resultats)

print(f"üìä Simulation de {n_experiences} exp√©riences")
print(f"   (chaque exp√©rience = lancer {n_pieces} pi√®ces)")
print()
print(f"Moyenne observ√©e : {moyenne:.2f}")
print(f"Moyenne th√©orique (np) : {n_pieces * p}")
print()
print(f"Variance observ√©e : {variance:.2f}")
print(f"Variance th√©orique (np(1-p)) : {n_pieces * p * (1-p)}")

# Visualisation
plt.figure(figsize=(10, 5))

# Histogramme des r√©sultats
valeurs, counts = np.unique(resultats, return_counts=True)
plt.bar(valeurs, counts/n_experiences, alpha=0.7, label='Simul√©', color='steelblue')

# Courbe th√©orique
x = np.arange(0, n_pieces+1)
y = stats.binom.pmf(x, n_pieces, p)
plt.plot(x, y, 'ro-', label='Binomiale th√©orique', markersize=5)

plt.xlabel('Nombre de piles')
plt.ylabel('Probabilit√©')
plt.title(f'Distribution du nombre de piles sur {n_pieces} lancers')
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('binomial_simulation.png', dpi=100, bbox_inches='tight')
plt.show()`,
            expectedOutput: "Moyenne observ√©e",
            completesObjective: 5,
          },

          // ===== SECTION 8: QUIZ FINAL =====
          {
            type: "quiz",
            icon: "üéØ",
            title: "Quiz final : Distributions",
            question: "Pour initialiser les poids d'un r√©seau de neurones, on utilise souvent une distribution normale centr√©e en 0. Pourquoi pas une distribution uniforme sur un grand intervalle [-100, 100] ?",
            options: [
              "L'uniforme est plus lente √† calculer",
              "La normale concentre les valeurs pr√®s de 0, √©vitant des gradients qui explosent ou disparaissent",
              "L'uniforme n'existe pas pour les nombres r√©els",
              "C'est juste une convention arbitraire"
            ],
            correctAnswer: 1,
            explanation: "La distribution normale avec œÉ petit concentre la majorit√© des poids pr√®s de 0, ce qui √©vite les probl√®mes de gradients explosifs (poids trop grands) ou √©vanescents (non-lin√©arit√©s satur√©es). L'uniforme sur [-100, 100] donnerait des poids initiaux beaucoup trop grands !",
          },
        ],
        prevModule: "probability.html",
        nextModule: "random-variables.html",
      };

      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
