<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Les Probabilit√©s | IA4Ndada</title>

    <!-- MathJax pour les formules math√©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>üßÆ Math√©matiques</span>
          <span>‚Ä∫</span>
          <span>Les Probabilit√©s</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>üé≤ Les Probabilit√©s</h1>
      <p class="subtitle">Module 1.6 - Comment l'IA g√®re l'incertitude</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajout√©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajout√© dynamiquement -->
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="gradients.html" class="nav-link" id="prev-link"
          >‚Üê Module pr√©c√©dent : Gradients</a
        >
        <a href="statistics.html" class="nav-link" id="next-link"
          >Module suivant : Statistiques ‚Üí</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Probabilit√©s
      const moduleConfig = {
        id: "math-probability",
        title: "Les Probabilit√©s",
        category: "Math√©matiques",
        objectives: [
          "Comprendre ce qu'est une probabilit√©",
          "Calculer des probabilit√©s simples",
          "Appliquer les r√®gles de probabilit√© (addition, multiplication)",
          "Comprendre la probabilit√© conditionnelle et Bayes",
          "Calculer l'esp√©rance et la variance",
          "Simuler des probabilit√©s avec Python",
        ],
        content: [
          // ===== SECTION 1: INTRODUCTION AUX PROBABILIT√âS =====
          {
            type: "concept",
            icon: "üí°",
            title: "Qu'est-ce qu'une probabilit√© ?",
            content: `
              <p>Une <strong>probabilit√©</strong> est un nombre entre 0 et 1 qui mesure la <strong>chance qu'un √©v√©nement se produise</strong>.</p>

              <p><strong>üéØ Pourquoi c'est important en IA ?</strong></p>
              <p>L'IA travaille dans un monde <strong>incertain</strong>. Elle ne peut jamais √™tre s√ªre √† 100%. Les probabilit√©s lui permettent de :</p>
              <ul>
                <li>Quantifier son incertitude : "Je suis s√ªr √† 95% que c'est un chat"</li>
                <li>Prendre des d√©cisions rationnelles malgr√© l'incertitude</li>
                <li>G√©n√©rer du texte (LLMs) : chaque mot a une probabilit√©</li>
              </ul>

              <p><strong>üìê Notation et valeurs :</strong></p>
              <p>$$P(A) = \\text{probabilit√© que l'√©v√©nement A se produise}$$</p>
              <ul>
                <li>\\(P(A) = 0\\) ‚Üí √©v√©nement <strong>impossible</strong></li>
                <li>\\(P(A) = 0.5\\) ‚Üí √©v√©nement <strong>√©quiprobable</strong> (50%)</li>
                <li>\\(P(A) = 1\\) ‚Üí √©v√©nement <strong>certain</strong></li>
              </ul>

              <p><strong>üîë Formule de base :</strong></p>
              <p>$$P(A) = \\frac{\\text{nombre de cas favorables}}{\\text{nombre de cas possibles}}$$</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 1 : Probabilit√© d'un d√©",
            content: `
              <p>On lance un d√© √† 6 faces √©quilibr√©. Quelle est la probabilit√© d'obtenir un 6 ?</p>
              <p>Exprimez votre r√©ponse sous forme d√©cimale (arrondie √† 2 d√©cimales).</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 0.17,
            tolerance: 0.01,
            explanation: "Il y a 1 cas favorable (obtenir 6) sur 6 cas possibles. Donc P(6) = 1/6 ‚âà 0.167",
            completesObjective: 0,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 2 : Probabilit√© d'un nombre pair",
            content: `
              <p>Toujours avec un d√© √† 6 faces. Quelle est la probabilit√© d'obtenir un nombre <strong>pair</strong> (2, 4 ou 6) ?</p>
              <p>Exprimez votre r√©ponse sous forme d√©cimale.</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 0.5,
            tolerance: 0.01,
            explanation: "Il y a 3 cas favorables (2, 4, 6) sur 6 cas possibles. Donc P(pair) = 3/6 = 0.5 = 50%",
            completesObjective: 1,
          },

          // ===== SECTION 2: R√àGLES DE PROBABILIT√â =====
          {
            type: "mathematique",
            icon: "‚àë",
            title: "Les r√®gles fondamentales",
            content: `
              <p>Voici les r√®gles essentielles pour calculer des probabilit√©s :</p>

              <p><strong>üìã R√®gle 1 : Compl√©mentaire</strong></p>
              <p>$$P(\\text{non } A) = 1 - P(A)$$</p>
              <p>Exemple : Si P(pluie) = 0.3, alors P(pas de pluie) = 0.7</p>

              <p><strong>üìã R√®gle 2 : Addition (OU)</strong></p>
              <p>$$P(A \\text{ ou } B) = P(A) + P(B) - P(A \\text{ et } B)$$</p>
              <p>On soustrait l'intersection pour ne pas compter deux fois !</p>

              <p><strong>üìã R√®gle 3 : Multiplication (ET) - cas ind√©pendant</strong></p>
              <p>Si A et B sont <strong>ind√©pendants</strong> (l'un n'influence pas l'autre) :</p>
              <p>$$P(A \\text{ et } B) = P(A) \\times P(B)$$</p>

              <p><strong>üìã R√®gle 4 : Somme totale</strong></p>
              <p>La somme des probabilit√©s de tous les √©v√©nements possibles = 1</p>
              <p>$$\\sum_{\\text{tous √©v√©nements}} P(\\text{√©v√©nement}) = 1$$</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 3 : R√®gle du compl√©mentaire",
            content: `
              <p>Un mod√®le d'IA pr√©dit qu'il y a 85% de chance qu'un email soit un spam.</p>
              <p>Quelle est la probabilit√© que l'email ne soit <strong>pas</strong> un spam ?</p>
              <p>R√©pondez en pourcentage (juste le nombre, sans le symbole %).</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 15,
            tolerance: 0,
            explanation: "P(pas spam) = 1 - P(spam) = 1 - 0.85 = 0.15 = 15%",
            completesObjective: 2,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 4 : √âv√©nements ind√©pendants",
            content: `
              <p>On lance une pi√®ce (P(pile) = 0.5) et un d√© (P(6) = 1/6 ‚âà 0.167).</p>
              <p>Quelle est la probabilit√© d'obtenir pile ET un 6 ?</p>
              <p>Les deux √©v√©nements sont ind√©pendants. Arrondissez √† 2 d√©cimales.</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 0.08,
            tolerance: 0.01,
            explanation: "P(pile ET 6) = P(pile) √ó P(6) = 0.5 √ó (1/6) = 0.5 √ó 0.167 ‚âà 0.083",
            completesObjective: 2,
          },

          // ===== SECTION 3: PROBABILIT√â CONDITIONNELLE =====
          {
            type: "concept",
            icon: "üîó",
            title: "Probabilit√© conditionnelle",
            content: `
              <p>La <strong>probabilit√© conditionnelle</strong> P(B|A) est la probabilit√© de B <strong>sachant que</strong> A s'est d√©j√† produit.</p>

              <p><strong>üìê Formule :</strong></p>
              <p>$$P(B|A) = \\frac{P(A \\text{ et } B)}{P(A)}$$</p>

              <p><strong>üéØ Exemple concret :</strong></p>
              <p>Dans une classe de 100 √©tudiants :</p>
              <ul>
                <li>60 aiment les maths</li>
                <li>40 aiment la programmation</li>
                <li>30 aiment les deux</li>
              </ul>

              <p><strong>Question :</strong> Si un √©tudiant aime les maths, quelle est la probabilit√© qu'il aime aussi la programmation ?</p>

              <p>$$P(\\text{prog}|\\text{maths}) = \\frac{P(\\text{maths et prog})}{P(\\text{maths})} = \\frac{30/100}{60/100} = \\frac{30}{60} = 0.5$$</p>

              <p><strong>ü§ñ En IA :</strong> Les LLMs utilisent exactement cela ! P(mot suivant | mots pr√©c√©dents)</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 5 : Probabilit√© conditionnelle",
            content: `
              <p>Dans une entreprise de 200 employ√©s :</p>
              <ul>
                <li>120 utilisent Python</li>
                <li>80 travaillent en IA</li>
                <li>60 utilisent Python ET travaillent en IA</li>
              </ul>
              <p>Si un employ√© utilise Python, quelle est la probabilit√© qu'il travaille en IA ?</p>
              <p>R√©pondez sous forme d√©cimale.</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 0.5,
            tolerance: 0.01,
            explanation: "P(IA|Python) = P(Python et IA) / P(Python) = (60/200) / (120/200) = 60/120 = 0.5",
            completesObjective: 3,
          },

          // ===== SECTION 4: TH√âOR√àME DE BAYES =====
          {
            type: "mathematique",
            icon: "üßÆ",
            title: "Le th√©or√®me de Bayes",
            content: `
              <p>Le <strong>th√©or√®me de Bayes</strong> permet d'inverser une probabilit√© conditionnelle. C'est fondamental en IA pour mettre √† jour nos croyances avec de nouvelles donn√©es.</p>

              <p><strong>üìê Formule :</strong></p>
              <p>$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$</p>

              <p><strong>üîç D√©cryptage :</strong></p>
              <ul>
                <li>\\(P(A)\\) = probabilit√© <strong>a priori</strong> (avant d'avoir l'info B)</li>
                <li>\\(P(A|B)\\) = probabilit√© <strong>a posteriori</strong> (apr√®s avoir observ√© B)</li>
                <li>\\(P(B|A)\\) = <strong>vraisemblance</strong> (chance d'observer B si A est vrai)</li>
              </ul>

              <p><strong>üè• Exemple m√©dical :</strong></p>
              <ul>
                <li>1% de la population a une maladie : P(malade) = 0.01</li>
                <li>Le test d√©tecte 95% des malades : P(positif|malade) = 0.95</li>
                <li>Le test a 5% de faux positifs : P(positif|sain) = 0.05</li>
              </ul>

              <p><strong>Question :</strong> Si le test est positif, quelle est la chance d'√™tre vraiment malade ?</p>

              <p>$$P(\\text{malade}|\\text{positif}) = \\frac{0.95 \\times 0.01}{0.95 \\times 0.01 + 0.05 \\times 0.99} ‚âà 0.16$$</p>

              <p><strong>üí° Surprise :</strong> Seulement 16% ! La maladie est rare, donc la plupart des tests positifs sont des faux positifs.</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 6 : Appliquer Bayes",
            content: `
              <p>Un filtre anti-spam a les caract√©ristiques suivantes :</p>
              <ul>
                <li>10% des emails re√ßus sont des spams : P(spam) = 0.10</li>
                <li>90% des spams contiennent le mot "gratuit" : P(gratuit|spam) = 0.90</li>
                <li>5% des emails normaux contiennent "gratuit" : P(gratuit|normal) = 0.05</li>
              </ul>
              <p>Si un email contient "gratuit", quelle est la probabilit√© que ce soit un spam ?</p>
              <p>Arrondissez √† 2 d√©cimales.</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 0.67,
            tolerance: 0.02,
            explanation: "P(gratuit) = P(gratuit|spam)√óP(spam) + P(gratuit|normal)√óP(normal) = 0.90√ó0.10 + 0.05√ó0.90 = 0.135. Donc P(spam|gratuit) = (0.90 √ó 0.10) / 0.135 = 0.09/0.135 ‚âà 0.67",
            completesObjective: 3,
          },

          // ===== SECTION 5: ESP√âRANCE ET VARIANCE =====
          {
            type: "mathematique",
            icon: "üìä",
            title: "Esp√©rance : la valeur moyenne attendue",
            content: `
              <p>L'<strong>esp√©rance</strong> E[X] d'une variable al√©atoire est la valeur "moyenne" qu'on s'attend √† obtenir sur le long terme.</p>

              <p><strong>üìê Formule :</strong></p>
              <p>$$E[X] = \\sum_{i} x_i \\times P(X = x_i)$$</p>

              <p><strong>üé≤ Exemple : Lancer de d√©</strong></p>
              <p>$$E[X] = 1 \\times \\frac{1}{6} + 2 \\times \\frac{1}{6} + 3 \\times \\frac{1}{6} + 4 \\times \\frac{1}{6} + 5 \\times \\frac{1}{6} + 6 \\times \\frac{1}{6}$$</p>
              <p>$$E[X] = \\frac{1+2+3+4+5+6}{6} = \\frac{21}{6} = 3.5$$</p>

              <p><strong>üí° Interpr√©tation :</strong> En moyenne, sur beaucoup de lancers, on obtient 3.5 points par lancer.</p>

              <p><strong>ü§ñ En IA :</strong></p>
              <ul>
                <li>L'esp√©rance du gain pr√©dit par un mod√®le de trading</li>
                <li>Le nombre moyen de mots g√©n√©r√©s par un LLM</li>
                <li>Le score moyen d'une strat√©gie de jeu</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 7 : Calculer une esp√©rance",
            content: `
              <p>Un jeu de hasard a les r√©sultats suivants :</p>
              <ul>
                <li>50% de chance de perdre 1‚Ç¨</li>
                <li>30% de chance de gagner 2‚Ç¨</li>
                <li>20% de chance de gagner 5‚Ç¨</li>
              </ul>
              <p>Quelle est l'esp√©rance de gain (en euros) ?</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 1.1,
            tolerance: 0.01,
            explanation: "E[X] = (-1)√ó0.5 + 2√ó0.3 + 5√ó0.2 = -0.5 + 0.6 + 1.0 = 1.1‚Ç¨. En moyenne, on gagne 1.10‚Ç¨ par partie.",
            completesObjective: 4,
          },
          {
            type: "mathematique",
            icon: "üìè",
            title: "Variance : mesurer la dispersion",
            content: `
              <p>La <strong>variance</strong> mesure √† quel point les valeurs sont "dispers√©es" autour de l'esp√©rance.</p>

              <p><strong>üìê Formule :</strong></p>
              <p>$$\\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$</p>

              <p><strong>üìè √âcart-type :</strong></p>
              <p>$$\\sigma = \\sqrt{\\text{Var}(X)}$$</p>
              <p>L'√©cart-type est dans la m√™me unit√© que X, donc plus facile √† interpr√©ter.</p>

              <p><strong>üîç Interpr√©tation :</strong></p>
              <ul>
                <li>Variance <strong>faible</strong> ‚Üí valeurs proches de la moyenne ‚Üí pr√©dictions stables</li>
                <li>Variance <strong>√©lev√©e</strong> ‚Üí valeurs dispers√©es ‚Üí pr√©dictions incertaines</li>
              </ul>

              <p><strong>ü§ñ En IA :</strong></p>
              <ul>
                <li>Un mod√®le avec haute variance donne des pr√©dictions tr√®s diff√©rentes</li>
                <li>On cherche souvent √† minimiser la variance des erreurs</li>
                <li>Le compromis biais-variance est fondamental en ML</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 8 : Calculer une variance",
            content: `
              <p>Une variable X peut prendre les valeurs suivantes :</p>
              <ul>
                <li>X = 0 avec probabilit√© 0.5</li>
                <li>X = 4 avec probabilit√© 0.5</li>
              </ul>
              <p>Calculez d'abord E[X], puis la variance Var(X).</p>
              <p>Quelle est la variance ?</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 4,
            tolerance: 0.01,
            explanation: "E[X] = 0√ó0.5 + 4√ó0.5 = 2. E[X¬≤] = 0¬≤√ó0.5 + 4¬≤√ó0.5 = 8. Var(X) = E[X¬≤] - (E[X])¬≤ = 8 - 4 = 4",
            completesObjective: 4,
          },

          // ===== SECTION 6: SIMULATION PYTHON =====
          {
            type: "code",
            icon: "üêç",
            title: "Simuler des probabilit√©s avec Python",
            content: `
              <p>V√©rifions la loi des grands nombres : plus on r√©p√®te une exp√©rience, plus la moyenne observ√©e se rapproche de l'esp√©rance th√©orique.</p>
            `,
            code: `import numpy as np
import matplotlib.pyplot as plt

# Simuler des lancers de d√©
np.random.seed(42)
n_lancers = 10000
lancers = np.random.randint(1, 7, n_lancers)  # 1 √† 6

# Calculer la moyenne cumul√©e
moyennes_cumulees = np.cumsum(lancers) / np.arange(1, n_lancers + 1)

# Esp√©rance th√©orique
esperance_theorique = 3.5

# Visualisation
plt.figure(figsize=(12, 5))

# Graphique 1 : Convergence vers l'esp√©rance
plt.subplot(1, 2, 1)
plt.plot(moyennes_cumulees, 'b-', alpha=0.7, label='Moyenne observ√©e')
plt.axhline(y=esperance_theorique, color='r', linestyle='--',
            linewidth=2, label=f'E[X] = {esperance_theorique}')
plt.xlabel('Nombre de lancers')
plt.ylabel('Moyenne')
plt.title('Loi des grands nombres')
plt.legend()
plt.grid(True, alpha=0.3)

# Graphique 2 : Distribution des r√©sultats
plt.subplot(1, 2, 2)
valeurs, counts = np.unique(lancers, return_counts=True)
frequences = counts / n_lancers
plt.bar(valeurs, frequences, color='steelblue', alpha=0.7, label='Observ√©')
plt.axhline(y=1/6, color='r', linestyle='--', label='Th√©orique (1/6)')
plt.xlabel('Valeur du d√©')
plt.ylabel('Fr√©quence')
plt.title('Distribution des r√©sultats')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('probability_simulation.png', dpi=100, bbox_inches='tight')
plt.show()

print(f"üìä Statistiques sur {n_lancers} lancers :")
print(f"‚Ä¢ Moyenne observ√©e : {np.mean(lancers):.4f}")
print(f"‚Ä¢ Esp√©rance th√©orique : {esperance_theorique}")
print(f"‚Ä¢ √âcart : {abs(np.mean(lancers) - esperance_theorique):.4f}")`,
          },
          {
            type: "exercise-code",
            icon: "üíª",
            title: "Exercice 9 : Simuler le th√©or√®me de Bayes",
            content: `
              <p>Simulez le probl√®me du test m√©dical :</p>
              <ul>
                <li>1% de malades dans la population</li>
                <li>95% de d√©tection (vrais positifs)</li>
                <li>5% de faux positifs</li>
              </ul>
              <p>V√©rifiez que parmi les tests positifs, environ 16% sont vraiment malades.</p>
            `,
            starterCode: `import numpy as np

np.random.seed(42)
n_personnes = 100000

# TODO: Simuler la population
# 1. G√©n√©rer le statut malade/sain pour chaque personne
#    (1% de chance d'√™tre malade)
malades = np.random.random(n_personnes) < ___  # Compl√©ter

# 2. Simuler les r√©sultats des tests
# Pour les malades : 95% de tests positifs
# Pour les sains : 5% de tests positifs
tests_positifs = np.where(
    malades,
    np.random.random(n_personnes) < ___,  # Si malade
    np.random.random(n_personnes) < ___   # Si sain
)

# 3. Calculer P(malade | test positif)
# = nombre de (malades ET positifs) / nombre de positifs
nb_positifs = ___
nb_vrais_positifs = ___  # malades ET test positif
p_malade_si_positif = ___

print(f"Nombre de tests positifs : {nb_positifs}")
print(f"P(malade | test positif) = {p_malade_si_positif:.2%}")`,
            solution: `import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
n_personnes = 100000

# Simuler la population
# 1% de chance d'√™tre malade
malades = np.random.random(n_personnes) < 0.01

# Simuler les r√©sultats des tests
# Pour les malades : 95% de tests positifs
# Pour les sains : 5% de tests positifs
tests_positifs = np.where(
    malades,
    np.random.random(n_personnes) < 0.95,  # Si malade
    np.random.random(n_personnes) < 0.05   # Si sain
)

# Calculer les diff√©rentes cat√©gories
vrais_positifs = malades & tests_positifs
faux_positifs = ~malades & tests_positifs
vrais_negatifs = ~malades & ~tests_positifs
faux_negatifs = malades & ~tests_positifs

# P(malade | test positif)
nb_positifs = np.sum(tests_positifs)
nb_vrais_positifs = np.sum(vrais_positifs)
p_malade_si_positif = nb_vrais_positifs / nb_positifs

print(f"üìä Simulation sur {n_personnes} personnes")
print(f"\\nüè• Population :")
print(f"‚Ä¢ Malades : {np.sum(malades)} ({np.mean(malades):.2%})")
print(f"‚Ä¢ Sains : {np.sum(~malades)}")
print(f"\\nüî¨ R√©sultats des tests :")
print(f"‚Ä¢ Tests positifs : {nb_positifs}")
print(f"‚Ä¢ Vrais positifs : {nb_vrais_positifs}")
print(f"‚Ä¢ Faux positifs : {np.sum(faux_positifs)}")
print(f"\\nüìà P(malade | test positif) = {p_malade_si_positif:.2%}")
print(f"Valeur th√©orique ‚âà 16%")

# Visualisation
fig, ax = plt.subplots(figsize=(8, 6))
categories = ['Vrais positifs\\n(malades d√©tect√©s)',
              'Faux positifs\\n(sains mal diagnostiqu√©s)',
              'Vrais n√©gatifs\\n(sains corrects)',
              'Faux n√©gatifs\\n(malades manqu√©s)']
valeurs = [np.sum(vrais_positifs), np.sum(faux_positifs),
           np.sum(vrais_negatifs), np.sum(faux_negatifs)]
colors = ['green', 'red', 'lightgreen', 'orange']

bars = ax.bar(categories, valeurs, color=colors)
ax.set_ylabel('Nombre de personnes')
ax.set_title('Matrice de confusion du test m√©dical')
for bar, val in zip(bars, valeurs):
    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,
            str(val), ha='center', va='bottom', fontsize=10)
plt.xticks(rotation=15, ha='right')
plt.tight_layout()
plt.savefig('bayes_simulation.png', dpi=100, bbox_inches='tight')
plt.show()`,
            expectedOutput: "P(malade | test positif)",
            completesObjective: 5,
          },

          // ===== SECTION 7: QUIZ FINAL =====
          {
            type: "quiz",
            icon: "üéØ",
            title: "Quiz final : Les probabilit√©s",
            question: "Un LLM g√©n√®re le prochain mot en choisissant parmi des milliers de mots possibles. Comment utilise-t-il les probabilit√©s ?",
            options: [
              "Il choisit toujours le mot avec P = 1",
              "Il attribue une probabilit√© √† chaque mot possible et √©chantillonne selon cette distribution",
              "Il choisit un mot au hasard avec probabilit√© uniforme",
              "Il n'utilise pas de probabilit√©s, juste des r√®gles de grammaire"
            ],
            correctAnswer: 1,
            explanation: "Les LLMs calculent une distribution de probabilit√© sur tous les mots possibles (P(mot|contexte)) et √©chantillonnent selon cette distribution. Le param√®tre 'temp√©rature' contr√¥le la dispersion : temp√©rature basse = choix presque d√©terministe du mot le plus probable, temp√©rature haute = plus de cr√©ativit√©/al√©atoire.",
          },
        ],
        prevModule: "gradients.html",
        nextModule: "statistics.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
