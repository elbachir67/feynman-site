<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Variables Al√©atoires | IA4Ndada</title>

    <!-- MathJax pour les formules math√©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>üßÆ Math√©matiques</span>
          <span>‚Ä∫</span>
          <span>Variables Al√©atoires</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>üé≤ Variables Al√©atoires</h1>
      <p class="subtitle">Module 1.8 - Esp√©rance, variance et covariance</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajout√©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajout√© dynamiquement -->
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="distributions.html" class="nav-link" id="prev-link"
          >‚Üê Module pr√©c√©dent : Distributions</a
        >
        <a href="maximum-likelihood.html" class="nav-link" id="next-link"
          >Module suivant : Maximum de vraisemblance ‚Üí</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      const moduleConfig = {
        id: "math-random-variables",
        title: "Variables Al√©atoires",
        category: "Math√©matiques",
        objectives: [
          "Comprendre ce qu'est une variable al√©atoire",
          "Calculer l'esp√©rance d'une variable al√©atoire",
          "Calculer et interpr√©ter la variance",
          "Comprendre la covariance et la corr√©lation",
          "Ma√Ætriser les propri√©t√©s de lin√©arit√©",
          "Appliquer ces concepts avec Python",
        ],
        content: [
          // ===== SECTION 1: INTRODUCTION =====
          {
            type: "concept",
            icon: "üí°",
            title: "Qu'est-ce qu'une variable al√©atoire ?",
            content: `
              <p>Une <strong>variable al√©atoire</strong> X est une fonction qui associe un nombre √† chaque r√©sultat d'une exp√©rience al√©atoire.</p>

              <p><strong>üé≤ Exemple concret :</strong></p>
              <p>Exp√©rience : lancer un d√©</p>
              <p>X = "valeur obtenue" est une variable al√©atoire qui peut prendre les valeurs {1, 2, 3, 4, 5, 6}</p>

              <p><strong>üìä Deux types :</strong></p>
              <ul>
                <li><strong>Discr√®te</strong> : valeurs d√©nombrables (1, 2, 3, ...)</li>
                <li><strong>Continue</strong> : valeurs sur un intervalle (temp√©rature, taille)</li>
              </ul>

              <p><strong>ü§ñ En IA, les variables al√©atoires mod√©lisent :</strong></p>
              <ul>
                <li>Les <strong>features</strong> d'un dataset (√¢ge, salaire, ...)</li>
                <li>Les <strong>pr√©dictions</strong> d'un mod√®le</li>
                <li>Les <strong>erreurs</strong> de pr√©diction</li>
                <li>Les <strong>poids</strong> d'un r√©seau de neurones (avant entra√Ænement)</li>
              </ul>
            `,
          },

          // ===== SECTION 2: ESP√âRANCE =====
          {
            type: "mathematique",
            icon: "üìä",
            title: "L'esp√©rance : la moyenne th√©orique",
            content: `
              <p>L'<strong>esp√©rance</strong> E[X] est la valeur moyenne qu'on s'attend √† obtenir sur un grand nombre d'exp√©riences.</p>

              <p><strong>üìê Formule (cas discret) :</strong></p>
              <p>$$E[X] = \\sum_{i} x_i \\cdot P(X = x_i)$$</p>

              <p><strong>üìê Formule (cas continu) :</strong></p>
              <p>$$E[X] = \\int_{-\\infty}^{+\\infty} x \\cdot f(x) \\, dx$$</p>

              <p><strong>üé≤ Exemple : D√© √©quilibr√©</strong></p>
              <p>$$E[X] = \\sum_{k=1}^{6} k \\cdot \\frac{1}{6} = \\frac{1+2+3+4+5+6}{6} = 3.5$$</p>

              <p><strong>üí° Interpr√©tation :</strong></p>
              <p>Si on lance le d√© un million de fois et qu'on fait la moyenne des r√©sultats, on obtiendra ‚âà 3.5</p>

              <p><strong>ü§ñ En IA :</strong></p>
              <ul>
                <li>E[erreur] = erreur moyenne du mod√®le</li>
                <li>E[gain] = gain moyen d'une strat√©gie de trading</li>
                <li>E[r√©compense] = r√©compense moyenne en RL</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 1 : Calculer une esp√©rance",
            content: `
              <p>Une variable X prend les valeurs suivantes :</p>
              <ul>
                <li>X = 0 avec probabilit√© 0.3</li>
                <li>X = 5 avec probabilit√© 0.5</li>
                <li>X = 10 avec probabilit√© 0.2</li>
              </ul>
              <p>Calculez E[X].</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 4.5,
            tolerance: 0.01,
            explanation: "E[X] = 0√ó0.3 + 5√ó0.5 + 10√ó0.2 = 0 + 2.5 + 2 = 4.5",
            completesObjective: 1,
          },
          {
            type: "mathematique",
            icon: "‚ú®",
            title: "Propri√©t√©s de l'esp√©rance (lin√©arit√©)",
            content: `
              <p>L'esp√©rance a des propri√©t√©s tr√®s utiles :</p>

              <p><strong>üìã Propri√©t√© 1 : Lin√©arit√©</strong></p>
              <p>$$E[aX + b] = a \\cdot E[X] + b$$</p>
              <p>L'esp√©rance d'une transformation lin√©aire est la transformation de l'esp√©rance.</p>

              <p><strong>üìã Propri√©t√© 2 : Somme</strong></p>
              <p>$$E[X + Y] = E[X] + E[Y]$$</p>
              <p>Toujours vraie, m√™me si X et Y sont d√©pendantes !</p>

              <p><strong>üìã Propri√©t√© 3 : Produit (cas ind√©pendant)</strong></p>
              <p>Si X et Y sont <strong>ind√©pendantes</strong> :</p>
              <p>$$E[XY] = E[X] \\cdot E[Y]$$</p>

              <p><strong>üéØ Exemple :</strong></p>
              <p>Si X repr√©sente un score et Y = 2X + 3 est le score transform√© :</p>
              <p>E[Y] = 2¬∑E[X] + 3</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 2 : Lin√©arit√© de l'esp√©rance",
            content: `
              <p>Si E[X] = 10, calculez E[3X - 5].</p>
              <p>Utilisez la propri√©t√© : E[aX + b] = aE[X] + b</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 25,
            tolerance: 0,
            explanation: "E[3X - 5] = 3√óE[X] - 5 = 3√ó10 - 5 = 30 - 5 = 25",
            completesObjective: 4,
          },

          // ===== SECTION 3: VARIANCE =====
          {
            type: "mathematique",
            icon: "üìè",
            title: "La variance : mesurer la dispersion",
            content: `
              <p>La <strong>variance</strong> Var(X) mesure √† quel point les valeurs s'√©cartent de l'esp√©rance.</p>

              <p><strong>üìê D√©finition :</strong></p>
              <p>$$Var(X) = E[(X - E[X])^2]$$</p>
              <p>C'est l'esp√©rance du carr√© des √©carts √† la moyenne.</p>

              <p><strong>üìê Formule de calcul (plus pratique) :</strong></p>
              <p>$$Var(X) = E[X^2] - (E[X])^2$$</p>
              <p>"Moyenne des carr√©s moins carr√© de la moyenne"</p>

              <p><strong>üìè √âcart-type :</strong></p>
              <p>$$\\sigma_X = \\sqrt{Var(X)}$$</p>
              <p>L'√©cart-type a la m√™me unit√© que X, donc plus interpr√©table.</p>

              <p><strong>üîç Interpr√©tation :</strong></p>
              <ul>
                <li>Var(X) = 0 ‚Üí X est constant (pas d'incertitude)</li>
                <li>Var(X) grand ‚Üí X tr√®s dispers√© (haute incertitude)</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 3 : Calculer une variance",
            content: `
              <p>X prend les valeurs {-1, +1} avec probabilit√© 0.5 chacune.</p>
              <p>1. Calculez E[X]</p>
              <p>2. Calculez E[X¬≤]</p>
              <p>3. En d√©duisez Var(X) = E[X¬≤] - (E[X])¬≤</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 1,
            tolerance: 0.01,
            explanation: "E[X] = (-1)√ó0.5 + 1√ó0.5 = 0. E[X¬≤] = 1√ó0.5 + 1√ó0.5 = 1. Var(X) = 1 - 0¬≤ = 1",
            completesObjective: 2,
          },
          {
            type: "mathematique",
            icon: "‚ú®",
            title: "Propri√©t√©s de la variance",
            content: `
              <p>La variance a des propri√©t√©s diff√©rentes de l'esp√©rance :</p>

              <p><strong>üìã Propri√©t√© 1 : Constante</strong></p>
              <p>$$Var(aX + b) = a^2 \\cdot Var(X)$$</p>
              <p>‚ö†Ô∏è La constante b dispara√Æt, et a est au carr√© !</p>

              <p><strong>üìã Propri√©t√© 2 : Somme (cas ind√©pendant)</strong></p>
              <p>Si X et Y sont <strong>ind√©pendantes</strong> :</p>
              <p>$$Var(X + Y) = Var(X) + Var(Y)$$</p>

              <p><strong>‚ö†Ô∏è Attention :</strong> Si X et Y ne sont pas ind√©pendantes :</p>
              <p>$$Var(X + Y) = Var(X) + Var(Y) + 2 \\cdot Cov(X, Y)$$</p>

              <p><strong>üéØ Exemple :</strong></p>
              <p>Si Var(X) = 4, alors :</p>
              <ul>
                <li>Var(2X) = 4 √ó 4 = 16</li>
                <li>Var(X + 10) = 4 (ajouter une constante ne change pas la variance)</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 4 : Propri√©t√©s de la variance",
            content: `
              <p>Si Var(X) = 9, calculez Var(2X + 5).</p>
              <p>Rappel : Var(aX + b) = a¬≤Var(X)</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 36,
            tolerance: 0,
            explanation: "Var(2X + 5) = 2¬≤ √ó Var(X) = 4 √ó 9 = 36. Le +5 n'a pas d'effet sur la variance.",
            completesObjective: 4,
          },

          // ===== SECTION 4: COVARIANCE =====
          {
            type: "concept",
            icon: "üîó",
            title: "La covariance : mesurer les liens",
            content: `
              <p>La <strong>covariance</strong> mesure comment deux variables varient ensemble.</p>

              <p><strong>üìê D√©finition :</strong></p>
              <p>$$Cov(X, Y) = E[(X - E[X])(Y - E[Y])]$$</p>

              <p><strong>üìê Formule de calcul :</strong></p>
              <p>$$Cov(X, Y) = E[XY] - E[X] \\cdot E[Y]$$</p>

              <p><strong>üîç Interpr√©tation :</strong></p>
              <ul>
                <li><strong>Cov(X,Y) > 0</strong> : quand X augmente, Y tend √† augmenter</li>
                <li><strong>Cov(X,Y) < 0</strong> : quand X augmente, Y tend √† diminuer</li>
                <li><strong>Cov(X,Y) = 0</strong> : pas de relation lin√©aire</li>
              </ul>

              <p><strong>üí° Propri√©t√© importante :</strong></p>
              <p>$$Cov(X, X) = Var(X)$$</p>
              <p>La covariance d'une variable avec elle-m√™me est sa variance.</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 5 : Calculer une covariance",
            content: `
              <p>Soient X et Y avec :</p>
              <ul>
                <li>E[X] = 2, E[Y] = 3</li>
                <li>E[XY] = 8</li>
              </ul>
              <p>Calculez Cov(X, Y) = E[XY] - E[X]¬∑E[Y]</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 2,
            tolerance: 0,
            explanation: "Cov(X,Y) = E[XY] - E[X]¬∑E[Y] = 8 - 2√ó3 = 8 - 6 = 2",
            completesObjective: 3,
          },

          // ===== SECTION 5: CORR√âLATION =====
          {
            type: "mathematique",
            icon: "üìà",
            title: "La corr√©lation : covariance normalis√©e",
            content: `
              <p>La <strong>corr√©lation</strong> est une version normalis√©e de la covariance, toujours entre -1 et +1.</p>

              <p><strong>üìê D√©finition :</strong></p>
              <p>$$\\rho_{X,Y} = \\frac{Cov(X, Y)}{\\sigma_X \\cdot \\sigma_Y} = \\frac{Cov(X, Y)}{\\sqrt{Var(X)} \\cdot \\sqrt{Var(Y)}}$$</p>

              <p><strong>üìä Interpr√©tation :</strong></p>
              <ul>
                <li><strong>œÅ = +1</strong> : corr√©lation positive parfaite (Y = aX + b avec a > 0)</li>
                <li><strong>œÅ = -1</strong> : corr√©lation n√©gative parfaite (Y = aX + b avec a < 0)</li>
                <li><strong>œÅ = 0</strong> : pas de corr√©lation lin√©aire</li>
                <li><strong>|œÅ| > 0.7</strong> : corr√©lation forte</li>
                <li><strong>0.3 < |œÅ| < 0.7</strong> : corr√©lation mod√©r√©e</li>
              </ul>

              <p><strong>‚ö†Ô∏è Attention :</strong></p>
              <p>Corr√©lation ‚â† Causalit√© ! Deux variables peuvent √™tre corr√©l√©es sans que l'une cause l'autre.</p>
            `,
          },
          {
            type: "exercise",
            icon: "‚úèÔ∏è",
            title: "Exercice 6 : Calculer une corr√©lation",
            content: `
              <p>Soient X et Y avec :</p>
              <ul>
                <li>Cov(X, Y) = 6</li>
                <li>œÉ_X = 2 (√©cart-type de X)</li>
                <li>œÉ_Y = 4 (√©cart-type de Y)</li>
              </ul>
              <p>Calculez le coefficient de corr√©lation œÅ.</p>
            `,
            exerciseType: "numeric",
            correctAnswer: 0.75,
            tolerance: 0.01,
            explanation: "œÅ = Cov(X,Y) / (œÉ_X √ó œÉ_Y) = 6 / (2 √ó 4) = 6/8 = 0.75. C'est une corr√©lation positive forte.",
            completesObjective: 3,
          },

          // ===== SECTION 6: APPLICATION =====
          {
            type: "concept",
            icon: "ü§ñ",
            title: "Applications en IA",
            content: `
              <p><strong>1. Compromis biais-variance :</strong></p>
              <p>$$E[(y - \\hat{y})^2] = Biais^2 + Variance + Bruit$$</p>
              <p>L'erreur quadratique moyenne se d√©compose en ces trois termes.</p>

              <p><strong>2. Matrice de covariance :</strong></p>
              <p>Pour un vecteur de features X = (X‚ÇÅ, X‚ÇÇ, ..., X‚Çô), la matrice de covariance Œ£ contient toutes les covariances :</p>
              <p>$$\\Sigma_{ij} = Cov(X_i, X_j)$$</p>
              <p>Utilis√©e en PCA, LDA, et normalisation de donn√©es.</p>

              <p><strong>3. R√©gularisation :</strong></p>
              <p>Minimiser Var(Œ∏) pour des param√®tres plus stables.</p>

              <p><strong>4. Bandit multi-bras :</strong></p>
              <p>Explorer les options avec haute variance vs exploiter les options avec haute esp√©rance.</p>
            `,
          },

          // ===== SECTION 7: CODE PYTHON =====
          {
            type: "code",
            icon: "üêç",
            title: "Calculs avec NumPy",
            content: `
              <p>Calculons esp√©rance, variance et covariance sur des donn√©es r√©elles :</p>
            `,
            code: `import numpy as np
import matplotlib.pyplot as plt

# Simuler des donn√©es corr√©l√©es
np.random.seed(42)
n = 1000

# X et Y corr√©l√©es (Y ‚âà 2X + bruit)
X = np.random.normal(50, 10, n)  # moyenne=50, √©cart-type=10
bruit = np.random.normal(0, 5, n)
Y = 2 * X + 30 + bruit

print("üìä STATISTIQUES")
print("=" * 50)

# Esp√©rances
print(f"E[X] = {np.mean(X):.2f} (th√©orique: 50)")
print(f"E[Y] = {np.mean(Y):.2f} (th√©orique: 2√ó50+30=130)")

# Variances
print(f"\\nVar(X) = {np.var(X):.2f} (th√©orique: 100)")
print(f"œÉ_X = {np.std(X):.2f} (th√©orique: 10)")

# Covariance et corr√©lation
cov_matrix = np.cov(X, Y)
print(f"\\nMatrice de covariance:")
print(f"  Var(X)    Cov(X,Y)   {cov_matrix[0,0]:.1f}  {cov_matrix[0,1]:.1f}")
print(f"  Cov(X,Y)  Var(Y)     {cov_matrix[1,0]:.1f}  {cov_matrix[1,1]:.1f}")

correlation = np.corrcoef(X, Y)[0, 1]
print(f"\\nCorr√©lation œÅ(X,Y) = {correlation:.3f}")

# Visualisation
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Scatter plot
axes[0].scatter(X, Y, alpha=0.5, s=10)
axes[0].set_xlabel('X')
axes[0].set_ylabel('Y')
axes[0].set_title(f'Scatter plot (œÅ = {correlation:.2f})')

# Droite de r√©gression
z = np.polyfit(X, Y, 1)
p = np.poly1d(z)
x_line = np.linspace(X.min(), X.max(), 100)
axes[0].plot(x_line, p(x_line), 'r-', linewidth=2, label=f'y = {z[0]:.1f}x + {z[1]:.1f}')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Histogrammes
axes[1].hist(X, bins=30, alpha=0.5, label='X', density=True)
axes[1].hist(Y, bins=30, alpha=0.5, label='Y', density=True)
axes[1].set_xlabel('Valeur')
axes[1].set_ylabel('Densit√©')
axes[1].set_title('Distributions de X et Y')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('covariance_plot.png', dpi=100, bbox_inches='tight')
plt.show()`,
          },
          {
            type: "exercise-code",
            icon: "üíª",
            title: "Exercice 7 : V√©rifier les propri√©t√©s",
            content: `
              <p>V√©rifiez exp√©rimentalement que :</p>
              <ul>
                <li>E[X + Y] = E[X] + E[Y]</li>
                <li>Var(2X) = 4 √ó Var(X)</li>
                <li>Si X et Y sont ind√©pendantes, Cov(X,Y) ‚âà 0</li>
              </ul>
            `,
            starterCode: `import numpy as np

np.random.seed(42)
n = 100000

# G√©n√©rer X et Y ind√©pendantes
X = np.random.normal(10, 3, n)  # moyenne=10, √©cart-type=3
Y = np.random.normal(5, 2, n)   # moyenne=5, √©cart-type=2

# TODO: V√©rifier E[X + Y] = E[X] + E[Y]
E_X = ___
E_Y = ___
E_X_plus_Y = ___
print(f"E[X] + E[Y] = {E_X + E_Y:.2f}")
print(f"E[X + Y] = {E_X_plus_Y:.2f}")

# TODO: V√©rifier Var(2X) = 4 * Var(X)
Var_X = ___
Var_2X = ___
print(f"\\n4 * Var(X) = {4 * Var_X:.2f}")
print(f"Var(2X) = {Var_2X:.2f}")

# TODO: V√©rifier que Cov(X, Y) ‚âà 0 pour variables ind√©pendantes
cov_XY = ___
print(f"\\nCov(X, Y) = {cov_XY:.4f} (devrait √™tre ‚âà 0)")`,
            solution: `import numpy as np

np.random.seed(42)
n = 100000

# G√©n√©rer X et Y ind√©pendantes
X = np.random.normal(10, 3, n)  # moyenne=10, √©cart-type=3
Y = np.random.normal(5, 2, n)   # moyenne=5, √©cart-type=2

# V√©rifier E[X + Y] = E[X] + E[Y]
E_X = np.mean(X)
E_Y = np.mean(Y)
E_X_plus_Y = np.mean(X + Y)
print("1Ô∏è‚É£ Lin√©arit√© de l'esp√©rance :")
print(f"   E[X] + E[Y] = {E_X:.4f} + {E_Y:.4f} = {E_X + E_Y:.4f}")
print(f"   E[X + Y] = {E_X_plus_Y:.4f}")
print(f"   ‚úì Diff√©rence : {abs(E_X + E_Y - E_X_plus_Y):.6f}")

# V√©rifier Var(2X) = 4 * Var(X)
Var_X = np.var(X)
Var_2X = np.var(2 * X)
print(f"\\n2Ô∏è‚É£ Propri√©t√© de la variance :")
print(f"   4 √ó Var(X) = 4 √ó {Var_X:.4f} = {4 * Var_X:.4f}")
print(f"   Var(2X) = {Var_2X:.4f}")
print(f"   ‚úì Diff√©rence : {abs(4 * Var_X - Var_2X):.6f}")

# V√©rifier que Cov(X, Y) ‚âà 0 pour variables ind√©pendantes
cov_XY = np.cov(X, Y)[0, 1]
print(f"\\n3Ô∏è‚É£ Covariance de variables ind√©pendantes :")
print(f"   Cov(X, Y) = {cov_XY:.6f}")
print(f"   ‚úì Proche de 0 ? {'Oui!' if abs(cov_XY) < 0.1 else 'Non'}")

# Bonus : v√©rifier Var(X+Y) = Var(X) + Var(Y) si ind√©pendantes
Var_X_plus_Y = np.var(X + Y)
print(f"\\n4Ô∏è‚É£ Bonus - Variance de la somme (ind√©pendantes) :")
print(f"   Var(X) + Var(Y) = {Var_X + np.var(Y):.4f}")
print(f"   Var(X + Y) = {Var_X_plus_Y:.4f}")`,
            expectedOutput: "Lin√©arit√© de l'esp√©rance",
            completesObjective: 5,
          },

          // ===== SECTION 8: QUIZ FINAL =====
          {
            type: "quiz",
            icon: "üéØ",
            title: "Quiz final : Variables al√©atoires",
            question: "En machine learning, pourquoi pr√©f√®re-t-on souvent minimiser l'erreur quadratique moyenne (MSE) plut√¥t que l'erreur absolue moyenne (MAE) ?",
            options: [
              "Le MSE est plus rapide √† calculer",
              "Le MSE p√©nalise davantage les grandes erreurs et sa d√©riv√©e est plus simple (lin√©aire)",
              "Le MAE ne fonctionne pas avec les r√©seaux de neurones",
              "C'est purement conventionnel, les deux sont √©quivalents"
            ],
            correctAnswer: 1,
            explanation: "MSE = E[(y-≈∑)¬≤] utilise le carr√©, ce qui p√©nalise plus les grandes erreurs. De plus, sa d√©riv√©e ‚àÇMSE/‚àÇ≈∑ = -2(y-≈∑) est lin√©aire et simple √† calculer, facilitant l'optimisation par gradient. Le MAE a une d√©riv√©e discontinue en 0.",
          },
        ],
        prevModule: "distributions.html",
        nextModule: "maximum-likelihood.html",
      };

      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
