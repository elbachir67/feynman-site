<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Fine-tuning | IA4Ndada</title>

    <!-- MathJax pour les formules mathÃ©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">ğŸ  Accueil</a>
          <span>â€º</span>
          <span>ğŸ’¬ LLMs & IA Moderne</span>
          <span>â€º</span>
          <span>Fine-tuning</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>ğŸ¯ Fine-tuning : Adapter les GÃ©ants Ã  vos Besoins</h1>
      <p class="subtitle">Module 5.4 - Personnalisation de l'IA Moderne</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>ğŸ¯ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajoutÃ©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajoutÃ© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>ğŸ‰ Checkpoint - Fine-tuning</h3>
        <p>
          FÃ©licitations ! Vous maÃ®trisez maintenant l'art d'adapter l'IA de
          pointe Ã  vos besoins spÃ©cifiques.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme complÃ©tÃ©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="gpt-bert.html" class="nav-link" id="prev-link"
          >â† Module prÃ©cÃ©dent : GPT & BERT</a
        >
        <a href="prompt-engineering.html" class="nav-link" id="next-link"
          >Module suivant : Prompt Engineering â†’</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Fine-tuning
      const moduleConfig = {
        id: "llm-fine-tuning",
        title: "Fine-tuning : Adapter les GÃ©ants Ã  vos Besoins",
        category: "LLMs & IA Moderne",
        objectives: [
          "Comprendre pourquoi le fine-tuning rÃ©volutionne l'IA accessible",
          "MaÃ®triser les 4 types de fine-tuning et leurs applications",
          "Calculer l'efficacitÃ© rÃ©volutionnaire de LoRA",
          "Concevoir une stratÃ©gie de fine-tuning pour langues africaines",
          "Estimer coÃ»ts et ressources pour projets rÃ©els",
        ],
        content: [
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "La rÃ©volution Ã©conomique du fine-tuning",
            content: `
                        <p>Le <strong>fine-tuning</strong> a dÃ©mocratisÃ© l'IA de pointe en rendant accessible ce qui Ã©tait rÃ©servÃ© aux gÃ©ants technologiques. C'est la diffÃ©rence entre construire une voiture from scratch et adapter une Tesla existante !</p>
                        
                        <p><strong>ğŸ’° RÃ©volution Ã©conomique quantifiÃ©e :</strong></p>
                        <ul>
                            <li>ğŸ­ <strong>EntraÃ®nement complet GPT-3</strong> : 4.6M$ et 355 ans de calcul</li>
                            <li>âš¡ <strong>Fine-tuning GPT-3</strong> : 100$ et quelques heures</li>
                            <li>ğŸ“Š <strong>Ratio</strong> : 46 000x moins cher !</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Analogie de la formation mÃ©dicale :</strong></p>
                        <ul>
                            <li>ğŸ¥ <strong>Formation gÃ©nÃ©rale</strong> : 8 ans d'Ã©tudes (prÃ©-entraÃ®nement)</li>
                            <li>ğŸ¯ <strong>SpÃ©cialisation</strong> : 2 ans en cardiologie (fine-tuning)</li>
                            <li>ğŸ’¡ <strong>RÃ©sultat</strong> : expert en cardiologie sans refaire toute la mÃ©decine</li>
                        </ul>
                        
                        <p><strong>ğŸš€ Applications rÃ©volutionnaires :</strong></p>
                        <ul>
                            <li>ğŸ‡¸ğŸ‡³ <strong>IA en wolof</strong> : adapter GPT pour les langues africaines</li>
                            <li>ğŸ¥ <strong>IA mÃ©dicale</strong> : spÃ©cialiser pour maladies tropicales</li>
                            <li>âš–ï¸ <strong>IA juridique</strong> : adapter au droit sÃ©nÃ©galais</li>
                            <li>ğŸ“š <strong>IA Ã©ducative</strong> : personnaliser pour le systÃ¨me Ã©ducatif local</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Point clÃ© :</strong> Le fine-tuning transforme un modÃ¨le gÃ©nÃ©raliste en expert spÃ©cialisÃ©, avec une fraction du coÃ»t et du temps d'un entraÃ®nement complet.</p>
                    `,
          },
          {
            type: "intuition",
            icon: "ğŸ§ ",
            title: "L'analogie du mÃ©decin spÃ©cialiste sÃ©nÃ©galais",
            content: `
                        <p>Imaginez <strong>Dr. Aminata Diallo</strong>, mÃ©decin gÃ©nÃ©raliste Ã  l'hÃ´pital Le Dantec qui veut se spÃ©cialiser en cardiologie tropicale :</p>
                        
                        <p><strong>ğŸ“ Option 1 - Recommencer from scratch :</strong></p>
                        <ul>
                            <li>ğŸ“š Refaire 8 ans d'Ã©tudes de mÃ©decine</li>
                            <li>ğŸ’° CoÃ»t : 50 millions FCFA</li>
                            <li>â° Temps : 8 ans</li>
                            <li>ğŸ¤” <strong>Absurde !</strong> Elle connaÃ®t dÃ©jÃ  la mÃ©decine de base</li>
                        </ul>
                        
                        <p><strong>âš¡ Option 2 - SpÃ©cialisation (fine-tuning) :</strong></p>
                        <ul>
                            <li>ğŸ¯ 2 ans de formation spÃ©cialisÃ©e en cardiologie</li>
                            <li>ğŸ’° CoÃ»t : 2 millions FCFA</li>
                            <li>â° Temps : 2 ans</li>
                            <li>âœ… <strong>Intelligent !</strong> Elle garde ses connaissances et ajoute l'expertise</li>
                        </ul>
                        
                        <p><strong>ğŸ§  ParallÃ¨le avec l'IA :</strong></p>
                        <ul>
                            <li>ğŸ¥ <strong>MÃ©decine gÃ©nÃ©rale</strong> = prÃ©-entraÃ®nement (GPT connaÃ®t le langage)</li>
                            <li>â¤ï¸ <strong>Cardiologie</strong> = fine-tuning (spÃ©cialisation mÃ©dicale)</li>
                            <li>ğŸ‡¸ğŸ‡³ <strong>Maladies tropicales</strong> = adaptation culturelle (contexte sÃ©nÃ©galais)</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ RÃ©sultat :</strong> Dr. Diallo devient experte en cardiologie tropicale sans perdre ses connaissances gÃ©nÃ©rales. C'est exactement ce que fait le fine-tuning avec l'IA !</p>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Les 4 types de fine-tuning : mathÃ©matiques et stratÃ©gies",
            content: `
                        <p><strong>ğŸ¯ Quatre approches avec complexitÃ©s croissantes :</strong></p>
                        
                        <p><strong>1ï¸âƒ£ Full Fine-tuning (Complet) :</strong></p>
                        <p>On met Ã  jour <strong>tous</strong> les paramÃ¨tres du modÃ¨le :</p>
                        <p>$$\\theta_{nouveau} = \\theta_{prÃ©-entraÃ®nÃ©} + \\Delta\\theta$$</p>
                        <ul>
                            <li>âœ… <strong>Avantages</strong> : performance maximale, adaptation totale</li>
                            <li>âŒ <strong>InconvÃ©nients</strong> : coÃ»teux, risque d'oubli catastrophique</li>
                            <li>ğŸ¯ <strong>Usage</strong> : domaines trÃ¨s diffÃ©rents, gros budgets</li>
                        </ul>
                        
                        <p><strong>2ï¸âƒ£ Feature Extraction (Extraction) :</strong></p>
                        <p>On <strong>gÃ¨le</strong> le modÃ¨le prÃ©-entraÃ®nÃ© et ajoute des couches :</p>
                        <p>$$y = f_{nouveau}(f_{gelÃ©}(x))$$</p>
                        <ul>
                            <li>âœ… <strong>Avantages</strong> : rapide, peu de donnÃ©es nÃ©cessaires</li>
                            <li>âŒ <strong>InconvÃ©nients</strong> : adaptation limitÃ©e</li>
                            <li>ğŸ¯ <strong>Usage</strong> : domaines similaires, prototypage rapide</li>
                        </ul>
                        
                        <p><strong>3ï¸âƒ£ Partial Fine-tuning (Partiel) :</strong></p>
                        <p>On met Ã  jour seulement les <strong>derniÃ¨res couches</strong> :</p>
                        <p>$$\\theta_{1:k} \\text{ gelÃ©s}, \\quad \\theta_{k+1:L} \\text{ mis Ã  jour}$$</p>
                        <ul>
                            <li>âœ… <strong>Avantages</strong> : Ã©quilibre coÃ»t/performance</li>
                            <li>âŒ <strong>InconvÃ©nients</strong> : choix de k dÃ©licat</li>
                            <li>ğŸ¯ <strong>Usage</strong> : adaptation modÃ©rÃ©e, budgets moyens</li>
                        </ul>
                        
                        <p><strong>4ï¸âƒ£ LoRA (Low-Rank Adaptation) :</strong></p>
                        <p>On approxime les changements par des matrices de <strong>faible rang</strong> :</p>
                        <p>$$W_{nouveau} = W_{original} + \\Delta W = W + AB^T$$</p>
                        <p>OÃ¹ \\(A \\in \\mathbb{R}^{d \\times r}\\), \\(B \\in \\mathbb{R}^{d \\times r}\\) avec \\(r \\ll d\\)</p>
                        <ul>
                            <li>âœ… <strong>Avantages</strong> : 99% moins de paramÃ¨tres, performance proche du full</li>
                            <li>âŒ <strong>InconvÃ©nients</strong> : plus complexe Ã  implÃ©menter</li>
                            <li>ğŸ¯ <strong>Usage</strong> : standard moderne, optimal</li>
                        </ul>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "LoRA : rÃ©volution mathÃ©matique dÃ©taillÃ©e",
            content: `
                        <p><strong>ğŸ§® LoRA exploite une propriÃ©tÃ© mathÃ©matique profonde :</strong></p>
                        
                        <p><strong>ğŸ’¡ Intuition clÃ© :</strong> Les changements nÃ©cessaires lors du fine-tuning ont une <strong>structure de faible rang</strong>. On n'a pas besoin de modifier toute la matrice, juste sa "direction principale" !</p>
                        
                        <p><strong>ğŸ“ DÃ©composition mathÃ©matique :</strong></p>
                        <p>Au lieu de stocker \\(\\Delta W \\in \\mathbb{R}^{d \\times d}\\) (dÂ² paramÃ¨tres), on stocke :</p>
                        <p>$$\\Delta W = A \\cdot B^T$$</p>
                        <p>OÃ¹ \\(A \\in \\mathbb{R}^{d \\times r}\\) et \\(B \\in \\mathbb{R}^{d \\times r}\\) avec \\(r \\ll d\\)</p>
                        
                        <p><strong>ğŸ”¢ Ã‰conomie de paramÃ¨tres :</strong></p>
                        <ul>
                            <li><strong>Matrice complÃ¨te</strong> : \\(d^2\\) paramÃ¨tres</li>
                            <li><strong>LoRA</strong> : \\(2dr\\) paramÃ¨tres</li>
                            <li><strong>Ratio</strong> : \\(\\frac{2dr}{d^2} = \\frac{2r}{d}\\)</li>
                        </ul>
                        
                        <p><strong>ğŸ“Š Exemple concret :</strong></p>
                        <p>Pour une matrice 4096Ã—4096 (typique dans GPT) avec r=16 :</p>
                        <ul>
                            <li>ğŸ”´ <strong>Full</strong> : 4096Â² = 16.8M paramÃ¨tres</li>
                            <li>ğŸŸ¢ <strong>LoRA</strong> : 2Ã—4096Ã—16 = 131k paramÃ¨tres</li>
                            <li>âš¡ <strong>Ã‰conomie</strong> : 128x moins de paramÃ¨tres !</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Propagation avant avec LoRA :</strong></p>
                        <p>$$y = (W + AB^T)x = Wx + AB^Tx = Wx + A(B^Tx)$$</p>
                        <p>On calcule d'abord \\(B^Tx\\), puis \\(A(\\cdot)\\), et on ajoute Ã  \\(Wx\\).</p>
                    `,
          },
          {
            type: "code",
            title: "ImplÃ©mentation LoRA from scratch",
            description: "CrÃ©ons une couche LoRA complÃ¨te :",
            code: `import numpy as np

class LoRALayer:
    def __init__(self, d_model, rank=16, alpha=32):
        """
        Couche LoRA (Low-Rank Adaptation)
        
        Args:
            d_model: dimension du modÃ¨le
            rank: rang de la dÃ©composition (r)
            alpha: facteur d'Ã©chelle
        """
        self.d_model = d_model
        self.rank = rank
        self.alpha = alpha
        self.scaling = alpha / rank
        
        # Initialisation des matrices LoRA
        # A: distribution normale, B: zÃ©ros (comme dans le papier original)
        self.A = np.random.normal(0, 0.02, (d_model, rank))
        self.B = np.zeros((d_model, rank))
        
        # Matrice originale (gelÃ©e)
        self.W_original = np.random.normal(0, 0.02, (d_model, d_model))
        
        print(f"ğŸ§  LoRA Layer crÃ©Ã©e:")
        print(f"   Dimension: {d_model}Ã—{d_model}")
        print(f"   Rang: {rank}")
        print(f"   ParamÃ¨tres originaux: {d_model**2:,}")
        print(f"   ParamÃ¨tres LoRA: {2*d_model*rank:,}")
        print(f"   Ã‰conomie: {d_model**2 / (2*d_model*rank):.1f}x moins")
    
    def forward(self, x):
        """Propagation avant avec LoRA"""
        # Calcul standard
        output_original = self.W_original @ x
        
        # Calcul LoRA: A @ (B^T @ x)
        temp = self.B.T @ x  # (rank, batch)
        delta_output = self.A @ temp  # (d_model, batch)
        
        # Combinaison avec facteur d'Ã©chelle
        output_final = output_original + self.scaling * delta_output
        
        return output_final, output_original, delta_output
    
    def count_parameters(self):
        """Compte les paramÃ¨tres entraÃ®nables"""
        return {
            'original_frozen': self.d_model ** 2,
            'lora_trainable': 2 * self.d_model * self.rank,
            'total': self.d_model ** 2 + 2 * self.d_model * self.rank,
            'reduction_factor': self.d_model ** 2 / (2 * self.d_model * self.rank)
        }

# Test de LoRA
print("ğŸ§ª TEST DE LORA")
print("=" * 30)

# CrÃ©ation d'une couche LoRA
lora = LoRALayer(d_model=512, rank=8, alpha=16)

# Test sur un batch de donnÃ©es
batch_size = 4
x_test = np.random.normal(0, 1, (512, batch_size))

# Propagation
output, original, delta = lora.forward(x_test)

print(f"\\nğŸ“Š RÃ‰SULTATS:")
print(f"Input shape: {x_test.shape}")
print(f"Output shape: {output.shape}")
print(f"Contribution LoRA moyenne: {np.mean(np.abs(delta)):.4f}")
print(f"Contribution originale moyenne: {np.mean(np.abs(original)):.4f}")

# Statistiques des paramÃ¨tres
stats = lora.count_parameters()
print(f"\\nğŸ“ˆ Ã‰CONOMIE DE PARAMÃˆTRES:")
for key, value in stats.items():
    if isinstance(value, float):
        print(f"{key}: {value:.1f}")
    else:
        print(f"{key}: {value:,}")`,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Calcul manuel LoRA sur matrice 3Ã—3",
            content: `
                        <p><strong>ğŸ“ Exemple concret :</strong> Adaptons une petite matrice avec LoRA</p>
                        
                        <p><strong>ğŸ¯ DonnÃ©es :</strong></p>
                        <ul>
                            <li>Matrice originale \\(W \\in \\mathbb{R}^{3 \\times 3}\\)</li>
                            <li>Rang LoRA : r = 2</li>
                            <li>Facteur d'Ã©chelle : Î± = 4</li>
                        </ul>
                        
                        <p><strong>ğŸ“Š Matrices :</strong></p>
                        <p>$$W = \\begin{bmatrix} 0.5 & 0.2 & 0.1 \\\\ 0.3 & 0.8 & 0.4 \\\\ 0.1 & 0.2 & 0.6 \\end{bmatrix}$$</p>
                        
                        <p>$$A = \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.1 \\\\ 0.2 & 0.3 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0.2 & 0.1 \\\\ 0.1 & 0.3 \\\\ 0.3 & 0.2 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ”¢ Calcul de Î”W = AB^T :</strong></p>
                        <p>$$AB^T = \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.1 \\\\ 0.2 & 0.3 \\end{bmatrix} \\begin{bmatrix} 0.2 & 0.1 & 0.3 \\\\ 0.1 & 0.3 & 0.2 \\end{bmatrix}$$</p>
                        
                        <p>$$= \\begin{bmatrix} 0.1Ã—0.2+0.2Ã—0.1 & 0.1Ã—0.1+0.2Ã—0.3 & 0.1Ã—0.3+0.2Ã—0.2 \\\\ 0.3Ã—0.2+0.1Ã—0.1 & 0.3Ã—0.1+0.1Ã—0.3 & 0.3Ã—0.3+0.1Ã—0.2 \\\\ 0.2Ã—0.2+0.3Ã—0.1 & 0.2Ã—0.1+0.3Ã—0.3 & 0.2Ã—0.3+0.3Ã—0.2 \\end{bmatrix}$$</p>
                        
                        <p>$$= \\begin{bmatrix} 0.04 & 0.07 & 0.07 \\\\ 0.07 & 0.06 & 0.11 \\\\ 0.07 & 0.11 & 0.12 \\end{bmatrix}$$</p>
                        
                        <p><strong>âš¡ Matrice finale avec scaling :</strong></p>
                        <p>$$W_{final} = W + \\frac{\\alpha}{r} \\Delta W = W + \\frac{4}{2} \\Delta W = W + 2\\Delta W$$</p>
                        
                        <p><strong>ğŸ“Š Ã‰conomie de paramÃ¨tres :</strong></p>
                        <ul>
                            <li>ğŸ”´ <strong>Full</strong> : 3Â² = 9 paramÃ¨tres</li>
                            <li>ğŸŸ¢ <strong>LoRA</strong> : 2Ã—3Ã—2 = 12 paramÃ¨tres (A et B)</li>
                            <li>ğŸ’¡ <strong>Paradoxe apparent</strong> : plus de paramÃ¨tres pour ce petit exemple !</li>
                            <li>ğŸ¯ <strong>RÃ©alitÃ©</strong> : LoRA brille sur grandes matrices (4096Ã—4096)</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice pratique : calcul LoRA complet",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Calculez l'Ã©conomie de paramÃ¨tres LoRA pour diffÃ©rentes tailles :</p>
                        
                        <p><strong>ğŸ“ Configurations Ã  analyser :</strong></p>
                        <ol>
                            <li>Matrice 1024Ã—1024, rang r=32</li>
                            <li>Matrice 4096Ã—4096, rang r=64</li>
                            <li>Matrice 8192Ã—8192, rang r=128</li>
                            <li>Pour chaque cas : calculez le ratio d'Ã©conomie et le nombre de paramÃ¨tres</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('lora-calculation-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="lora-calculation-exercise" style="display: none;">
                        <ol>
                            <li><strong>1024Ã—1024, r=32 :</strong><br>
                                â€¢ Full : 1024Â² = 1,048,576 paramÃ¨tres<br>
                                â€¢ LoRA : 2Ã—1024Ã—32 = 65,536 paramÃ¨tres<br>
                                â€¢ Ã‰conomie : 16x moins (94% de rÃ©duction)</li>
                            <li><strong>4096Ã—4096, r=64 :</strong><br>
                                â€¢ Full : 4096Â² = 16,777,216 paramÃ¨tres<br>
                                â€¢ LoRA : 2Ã—4096Ã—64 = 524,288 paramÃ¨tres<br>
                                â€¢ Ã‰conomie : 32x moins (97% de rÃ©duction)</li>
                            <li><strong>8192Ã—8192, r=128 :</strong><br>
                                â€¢ Full : 8192Â² = 67,108,864 paramÃ¨tres<br>
                                â€¢ LoRA : 2Ã—8192Ã—128 = 2,097,152 paramÃ¨tres<br>
                                â€¢ Ã‰conomie : 32x moins (97% de rÃ©duction)</li>
                        </ol>
                        <p><strong>ğŸ’¡ Observation :</strong> Plus la matrice est grande, plus LoRA est efficace !</p>
                        </div>
                    `,
          },
          {
            type: "code",
            title: "Fine-tuning pour le wolof : projet concret",
            description: "CrÃ©ons un systÃ¨me de fine-tuning pour le wolof :",
            code: `class WolofFineTuner:
    def __init__(self, base_model_size="7B"):
        """SystÃ¨me de fine-tuning pour modÃ¨les wolof"""
        self.base_model_size = base_model_size
        self.model_configs = {
            "1B": {"params": 1e9, "layers": 24, "d_model": 2048},
            "7B": {"params": 7e9, "layers": 32, "d_model": 4096}, 
            "13B": {"params": 13e9, "layers": 40, "d_model": 5120},
            "70B": {"params": 70e9, "layers": 80, "d_model": 8192}
        }
        
        self.config = self.model_configs[base_model_size]
        print(f"ğŸ¤– Configuration {base_model_size}:")
        print(f"   ParamÃ¨tres: {self.config['params']/1e9:.1f}B")
        print(f"   Couches: {self.config['layers']}")
        print(f"   Dimension: {self.config['d_model']}")
    
    def estimate_lora_params(self, rank=64, target_modules=["q", "k", "v", "o"]):
        """Estime les paramÃ¨tres LoRA nÃ©cessaires"""
        d_model = self.config['d_model']
        n_layers = self.config['layers']
        
        # ParamÃ¨tres par couche d'attention
        params_per_layer = len(target_modules) * 2 * d_model * rank
        
        # Total pour toutes les couches
        total_lora_params = n_layers * params_per_layer
        
        # Pourcentage du modÃ¨le original
        percentage = (total_lora_params / self.config['params']) * 100
        
        return {
            'lora_params': total_lora_params,
            'original_params': self.config['params'],
            'percentage': percentage,
            'reduction_factor': self.config['params'] / total_lora_params
        }
    
    def estimate_training_cost(self, dataset_size=10000, epochs=3):
        """Estime le coÃ»t d'entraÃ®nement"""
        # CoÃ»ts approximatifs (GPU H100)
        cost_per_hour = 2.5  # USD
        
        # Estimation temps basÃ©e sur la taille du modÃ¨le
        base_time_hours = {
            "1B": 2, "7B": 8, "13B": 16, "70B": 48
        }
        
        time_hours = base_time_hours[self.base_model_size] * epochs
        total_cost = time_hours * cost_per_hour
        
        return {
            'time_hours': time_hours,
            'cost_usd': total_cost,
            'cost_fcfa': total_cost * 600,  # Approximation 1 USD = 600 FCFA
            'dataset_size': dataset_size,
            'epochs': epochs
        }

# Test du systÃ¨me
print("ğŸ‡¸ğŸ‡³ FINE-TUNING POUR LE WOLOF")
print("=" * 40)

# Configuration pour modÃ¨le 7B
tuner = WolofFineTuner("7B")

# Estimation LoRA
lora_stats = tuner.estimate_lora_params(rank=64)
print(f"\\nğŸ“Š PARAMÃˆTRES LORA:")
print(f"ParamÃ¨tres LoRA: {lora_stats['lora_params']:,}")
print(f"ParamÃ¨tres originaux: {lora_stats['original_params']/1e9:.1f}B")
print(f"Pourcentage: {lora_stats['percentage']:.3f}%")
print(f"RÃ©duction: {lora_stats['reduction_factor']:.0f}x moins")

# Estimation coÃ»t
cost_stats = tuner.estimate_training_cost(dataset_size=50000, epochs=5)
print(f"\\nğŸ’° COÃ›T D'ENTRAÃNEMENT:")
print(f"Temps: {cost_stats['time_hours']} heures")
print(f"CoÃ»t: {cost_stats['cost_usd']}$ ({cost_stats['cost_fcfa']:,.0f} FCFA)")
print(f"Dataset: {cost_stats['dataset_size']:,} exemples wolof")`,
          },
          {
            type: "code",
            title: "Dataset wolof pour fine-tuning",
            description: "CrÃ©ons un dataset formatÃ© pour l'entraÃ®nement :",
            code: `# Dataset d'exemple pour fine-tuning wolof
dataset_wolof = [
    {
        "instruction": "Traduis en franÃ§ais",
        "input": "Nanga def?",
        "output": "Comment allez-vous ?"
    },
    {
        "instruction": "Traduis en franÃ§ais", 
        "input": "Maangi fi rekk",
        "output": "Je suis juste ici"
    },
    {
        "instruction": "RÃ©ponds en wolof",
        "input": "Quel temps fait-il ?",
        "output": "Ndaw bi dafa tang"
    },
    {
        "instruction": "Explique en wolof",
        "input": "Qu'est-ce que l'intelligence artificielle ?",
        "output": "Intelligence artificielle bi mooy xam-xam bu njÃ«kk ci ordinateur"
    },
    {
        "instruction": "Traduis en wolof",
        "input": "Bonjour, comment vous appelez-vous ?",
        "output": "Asalaam aleekum, naka nga tudd?"
    }
]

def formater_pour_entrainement(dataset):
    """Formate le dataset pour l'entraÃ®nement"""
    formatted_data = []
    
    for exemple in dataset:
        # Format Alpaca standard
        if exemple["input"]:
            prompt = f"### Instruction:\\n{exemple['instruction']}\\n\\n### Input:\\n{exemple['input']}\\n\\n### Response:\\n"
        else:
            prompt = f"### Instruction:\\n{exemple['instruction']}\\n\\n### Response:\\n"
        
        formatted_data.append({
            "prompt": prompt,
            "completion": exemple["output"],
            "full_text": prompt + exemple["output"]
        })
    
    return formatted_data

# Formatage du dataset
dataset_formate = formater_pour_entrainement(dataset_wolof)

print("ğŸ“š DATASET WOLOF FORMATÃ‰")
print("=" * 35)
print(f"Nombre d'exemples: {len(dataset_formate)}")
print()

# Affichage d'un exemple formatÃ©
print("ğŸ“ EXEMPLE FORMATÃ‰:")
print(dataset_formate[0]["full_text"])
print()

# Statistiques du dataset
total_chars = sum(len(ex["full_text"]) for ex in dataset_formate)
avg_length = total_chars / len(dataset_formate)

print(f"ğŸ“Š STATISTIQUES:")
print(f"CaractÃ¨res totaux: {total_chars:,}")
print(f"Longueur moyenne: {avg_length:.0f} caractÃ¨res")
print(f"Tokens estimÃ©s: {total_chars // 4:,} (approximation)")`,
          },
          {
            type: "code",
            title: "Ã‰valuateur de performance culturelle",
            description: "CrÃ©ons un systÃ¨me d'Ã©valuation spÃ©cialisÃ© :",
            code: `class EvaluateurCulturel:
    def __init__(self):
        """Ã‰valuateur spÃ©cialisÃ© pour IA culturellement adaptÃ©e"""
        self.metriques_culturelles = {
            "precision_linguistique": 0.0,
            "respect_cultural": 0.0, 
            "fluidite_naturelle": 0.0,
            "coherence_contextuelle": 0.0
        }
        
        # Expressions idiomatiques wolof
        self.expressions_test = [
            {"wolof": "Ku baax na", "sens": "Qui va bien", "contexte": "salutation"},
            {"wolof": "DÃ«gg nga", "sens": "C'est vrai", "contexte": "confirmation"},
            {"wolof": "Waaw, dÃ«gg na", "sens": "Oui, c'est exact", "contexte": "accord"},
            {"wolof": "DÃ©edÃ©et", "sens": "Doucement", "contexte": "patience"}
        ]
    
    def evaluer_traduction(self, modele_reponse, reference):
        """Ã‰value la qualitÃ© d'une traduction"""
        scores = {}
        
        # MÃ©trique 1: Exactitude lexicale (BLEU simplifiÃ©)
        mots_modele = set(modele_reponse.lower().split())
        mots_reference = set(reference.lower().split())
        
        if len(mots_reference) > 0:
            precision = len(mots_modele.intersection(mots_reference)) / len(mots_reference)
        else:
            precision = 0.0
        
        scores["precision_lexicale"] = precision
        
        # MÃ©trique 2: Longueur relative
        ratio_longueur = len(modele_reponse) / max(len(reference), 1)
        scores["ratio_longueur"] = min(ratio_longueur, 2.0)  # Cap Ã  2.0
        
        # MÃ©trique 3: PrÃ©sence de mots culturels
        mots_culturels = ["asalaam", "aleekum", "inshallah", "barakallahu", "teranga"]
        mots_culturels_detectes = sum(1 for mot in mots_culturels if mot in modele_reponse.lower())
        scores["richesse_culturelle"] = mots_culturels_detectes / len(mots_culturels)
        
        return scores
    
    def tester_expressions_idiomatiques(self):
        """Teste la comprÃ©hension des expressions wolof"""
        print("ğŸ­ TEST D'EXPRESSIONS IDIOMATIQUES")
        print("=" * 40)
        
        for i, expr in enumerate(self.expressions_test):
            # Simulation de rÃ©ponse de modÃ¨le fine-tunÃ©
            reponses_simulees = [
                "Cette personne va bien",
                "Oui, c'est la vÃ©ritÃ©", 
                "Exactement, je suis d'accord",
                "Il faut prendre son temps"
            ]
            
            print(f"Expression {i+1}: '{expr['wolof']}'")
            print(f"   Sens attendu: {expr['sens']}")
            print(f"   Contexte: {expr['contexte']}")
            print(f"   RÃ©ponse modÃ¨le: {reponses_simulees[i]}")
            
            # Ã‰valuation simple
            score = self.evaluer_traduction(reponses_simulees[i], expr['sens'])
            print(f"   Score: {score['precision_lexicale']:.2f}")
            print()
    
    def rapport_final(self, scores_globaux):
        """GÃ©nÃ¨re un rapport d'Ã©valuation final"""
        print("ğŸ“Š RAPPORT D'Ã‰VALUATION CULTURELLE")
        print("=" * 45)
        
        moyenne = sum(scores_globaux.values()) / len(scores_globaux)
        
        for metrique, score in scores_globaux.items():
            emoji = "ğŸŸ¢" if score > 0.8 else "ğŸŸ¡" if score > 0.6 else "ğŸ”´"
            print(f"{emoji} {metrique}: {score:.2f}")
        
        print(f"\\nğŸ¯ Score global: {moyenne:.2f}")
        
        if moyenne > 0.8:
            print("âœ… ModÃ¨le prÃªt pour production")
        elif moyenne > 0.6:
            print("âš ï¸ AmÃ©liorations nÃ©cessaires")
        else:
            print("âŒ Fine-tuning insuffisant")

# Test de l'Ã©valuateur
evaluateur = EvaluateurCulturel()
evaluateur.tester_expressions_idiomatiques()

# Simulation de scores finaux
scores_test = {
    "precision_linguistique": 0.85,
    "respect_cultural": 0.78,
    "fluidite_naturelle": 0.82,
    "coherence_contextuelle": 0.79
}

evaluateur.rapport_final(scores_test)`,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "StratÃ©gies de fine-tuning selon le contexte",
            content: `
                        <p><strong>ğŸ¯ Choisir la bonne stratÃ©gie selon vos contraintes :</strong></p>
                        
                        <table style="width: 100%; border-collapse: collapse; margin: 1rem 0;">
                            <tr style="background: #3498db; color: white;">
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Contexte</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">StratÃ©gie</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">CoÃ»t</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Performance</th>
                            </tr>
                            <tr>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸš€ <strong>Startup, prototype rapide</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">Feature Extraction</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸ’° TrÃ¨s faible</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">â­â­â­</td>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸ¢ <strong>Entreprise, budget moyen</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">LoRA</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸ’°ğŸ’° ModÃ©rÃ©</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">â­â­â­â­</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸ›ï¸ <strong>Gouvernement, mission critique</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">Full Fine-tuning</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸ’°ğŸ’°ğŸ’° Ã‰levÃ©</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">â­â­â­â­â­</td>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸ“ <strong>Recherche, expÃ©rimentation</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">Partial</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">ğŸ’°ğŸ’° Moyen</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">â­â­â­â­</td>
                            </tr>
                        </table>
                        
                        <p><strong>ğŸ”‘ Facteurs de dÃ©cision :</strong></p>
                        <ul>
                            <li>ğŸ’° <strong>Budget disponible</strong> : de 100$ Ã  100 000$</li>
                            <li>â° <strong>Urgence</strong> : prototype en 1 jour vs production en 6 mois</li>
                            <li>ğŸ“Š <strong>Taille du dataset</strong> : 1000 vs 1M exemples</li>
                            <li>ğŸ¯ <strong>Performance requise</strong> : dÃ©mo vs systÃ¨me critique</li>
                            <li>ğŸ”§ <strong>Expertise technique</strong> : Ã©quipe dÃ©butante vs experts</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Recommandation gÃ©nÃ©rale :</strong> Commencer par LoRA (meilleur rapport qualitÃ©/prix), puis Ã©voluer selon les besoins.</p>
                    `,
          },
          {
            type: "code",
            title: "Planificateur de projet fine-tuning",
            description: "CrÃ©ons un planificateur complet de projet :",
            code: `class PlanificateurFineTuning:
    def __init__(self):
        """Planificateur de projet fine-tuning"""
        self.phases = {
            "preparation": {"duree_jours": 7, "ressources": ["Data scientist", "Linguiste"]},
            "collecte_donnees": {"duree_jours": 14, "ressources": ["Annotateurs", "Traducteurs"]},
            "preprocessing": {"duree_jours": 5, "ressources": ["Data engineer"]},
            "fine_tuning": {"duree_jours": 3, "ressources": ["ML engineer", "GPU"]},
            "evaluation": {"duree_jours": 7, "ressources": ["Testeurs natifs", "Linguiste"]},
            "deploiement": {"duree_jours": 5, "ressources": ["DevOps", "Infrastructure"]}
        }
    
    def planifier_projet(self, nom_projet, langue_cible, taille_dataset):
        """Planifie un projet de fine-tuning complet"""
        print(f"ğŸ“‹ PLANIFICATION PROJET: {nom_projet}")
        print(f"ğŸ¯ Langue cible: {langue_cible}")
        print(f"ğŸ“Š Taille dataset: {taille_dataset:,} exemples")
        print("=" * 50)
        
        duree_totale = 0
        cout_total = 0
        
        for phase, details in self.phases.items():
            duree = details["duree_jours"]
            
            # Ajustement selon la taille du dataset
            if phase == "collecte_donnees" and taille_dataset > 10000:
                duree *= 2
            elif phase == "fine_tuning" and taille_dataset > 50000:
                duree *= 1.5
            
            duree_totale += duree
            
            # Estimation coÃ»t (approximatif)
            cout_phase = duree * len(details["ressources"]) * 50000  # 50k FCFA/jour/ressource
            cout_total += cout_phase
            
            print(f"ğŸ“… {phase.replace('_', ' ').title()}: {duree} jours")
            print(f"   Ressources: {', '.join(details['ressources'])}")
            print(f"   CoÃ»t estimÃ©: {cout_phase:,} FCFA")
            print()
        
        print(f"â° DURÃ‰E TOTALE: {duree_totale} jours ({duree_totale/7:.1f} semaines)")
        print(f"ğŸ’° COÃ›T TOTAL: {cout_total:,} FCFA ({cout_total/600:.0f}$)")
        
        return {
            "duree_jours": duree_totale,
            "cout_fcfa": cout_total,
            "phases": self.phases
        }
    
    def generer_timeline(self, plan):
        """GÃ©nÃ¨re une timeline visuelle"""
        print("\\nğŸ“… TIMELINE DU PROJET")
        print("=" * 30)
        
        jour_actuel = 0
        for phase, details in plan["phases"].items():
            duree = details["duree_jours"]
            debut = jour_actuel + 1
            fin = jour_actuel + duree
            
            # Barre de progression visuelle
            barre = "â–ˆ" * (duree // 2) + "â–‘" * max(0, 10 - duree // 2)
            
            print(f"Jour {debut:2d}-{fin:2d}: {phase.replace('_', ' ').title():15s} {barre}")
            jour_actuel += duree

# Test du planificateur
planificateur = PlanificateurFineTuning()

# Projet exemple: Assistant IA en wolof
plan = planificateur.planifier_projet(
    nom_projet="Assistant IA Wolof",
    langue_cible="Wolof",
    taille_dataset=25000
)

planificateur.generer_timeline(plan)`,
          },
          {
            type: "warning",
            icon: "âš ï¸",
            title: "DÃ©fis spÃ©cifiques aux langues africaines",
            content: `
                        <p><strong>ğŸŒ Le fine-tuning pour les langues africaines pose des dÃ©fis uniques :</strong></p>
                        
                        <p><strong>ğŸ”´ DÃ©fi 1 : RaretÃ© des donnÃ©es</strong></p>
                        <ul>
                            <li>ğŸ“Š <strong>Anglais</strong> : milliards de textes disponibles</li>
                            <li>ğŸ“‰ <strong>Wolof</strong> : quelques milliers de textes numÃ©risÃ©s</li>
                            <li>ğŸ”§ <strong>Solutions</strong> : augmentation de donnÃ©es, traduction automatique, collecte communautaire</li>
                        </ul>
                        
                        <p><strong>ğŸ”´ DÃ©fi 2 : DiversitÃ© dialectale</strong></p>
                        <ul>
                            <li>ğŸ—£ï¸ <strong>Wolof urbain</strong> (Dakar) vs <strong>wolof rural</strong> (Casamance)</li>
                            <li>ğŸ”§ <strong>Solutions</strong> : datasets multi-dialectaux, modÃ¨les adaptatifs</li>
                        </ul>
                        
                        <p><strong>ğŸ”´ DÃ©fi 3 : Code-switching</strong></p>
                        <ul>
                            <li>ğŸ’¬ <strong>RÃ©alitÃ©</strong> : "Nanga def? Ã‡a va bien?"</li>
                            <li>ğŸ”§ <strong>Solutions</strong> : modÃ¨les multilingues, dÃ©tection automatique</li>
                        </ul>
                        
                        <p><strong>ğŸ”´ DÃ©fi 4 : Contexte culturel</strong></p>
                        <ul>
                            <li>ğŸ­ <strong>Concepts uniques</strong> : "teranga", hiÃ©rarchie sociale, traditions</li>
                            <li>ğŸ”§ <strong>Solutions</strong> : datasets culturellement riches, Ã©valuation par natifs</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ OpportunitÃ©s :</strong></p>
                        <ul>
                            <li>ğŸŒŸ <strong>Impact social</strong> : dÃ©mocratiser l'IA en Afrique</li>
                            <li>ğŸ“š <strong>PrÃ©servation culturelle</strong> : numÃ©riser les langues</li>
                            <li>ğŸ¯ <strong>Innovation</strong> : techniques adaptÃ©es aux langues Ã  faibles ressources</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : conception de projets sÃ©nÃ©galais",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Concevez une stratÃ©gie de fine-tuning pour chaque projet sÃ©nÃ©galais :</p>
                        
                        <ol>
                            <li><strong>Assistant santÃ© en wolof</strong> : diagnostic de maladies tropicales</li>
                            <li><strong>Chatbot Ã©ducatif</strong> : aide aux devoirs en franÃ§ais/wolof</li>
                            <li><strong>Traducteur juridique</strong> : droit sÃ©nÃ©galais franÃ§ais â†” wolof</li>
                            <li><strong>Assistant agricole</strong> : conseils cultures selon climat sahÃ©lien</li>
                            <li><strong>Guide touristique IA</strong> : promotion patrimoine sÃ©nÃ©galais</li>
                        </ol>
                        
                        <p><strong>ğŸ“ Pour chaque projet, spÃ©cifiez :</strong></p>
                        <ul>
                            <li>Type de fine-tuning recommandÃ©</li>
                            <li>Taille de dataset nÃ©cessaire</li>
                            <li>Budget estimÃ©</li>
                            <li>DÃ©fis spÃ©cifiques</li>
                            <li>MÃ©triques d'Ã©valuation</li>
                        </ul>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('senegal-projects-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="senegal-projects-exercise" style="display: none;">
                        <ol>
                            <li><strong>Assistant santÃ© :</strong><br>
                                â€¢ StratÃ©gie : LoRA + donnÃ©es mÃ©dicales<br>
                                â€¢ Dataset : 15k consultations wolof/franÃ§ais<br>
                                â€¢ Budget : 5M FCFA<br>
                                â€¢ DÃ©fi : terminologie mÃ©dicale en wolof<br>
                                â€¢ MÃ©trique : prÃ©cision diagnostic + acceptation culturelle</li>
                            <li><strong>Chatbot Ã©ducatif :</strong><br>
                                â€¢ StratÃ©gie : Partial fine-tuning<br>
                                â€¢ Dataset : 30k Q&A pÃ©dagogiques<br>
                                â€¢ Budget : 3M FCFA<br>
                                â€¢ DÃ©fi : adaptation niveau scolaire<br>
                                â€¢ MÃ©trique : comprÃ©hension Ã©lÃ¨ves + engagement</li>
                            <li><strong>Traducteur juridique :</strong><br>
                                â€¢ StratÃ©gie : Full fine-tuning<br>
                                â€¢ Dataset : 50k documents juridiques<br>
                                â€¢ Budget : 15M FCFA<br>
                                â€¢ DÃ©fi : prÃ©cision terminologique critique<br>
                                â€¢ MÃ©trique : exactitude juridique + validation juristes</li>
                            <li><strong>Assistant agricole :</strong><br>
                                â€¢ StratÃ©gie : LoRA + donnÃ©es climatiques<br>
                                â€¢ Dataset : 20k conseils agricoles<br>
                                â€¢ Budget : 4M FCFA<br>
                                â€¢ DÃ©fi : variabilitÃ© climatique rÃ©gionale<br>
                                â€¢ MÃ©trique : adoption agriculteurs + impact rendements</li>
                            <li><strong>Guide touristique :</strong><br>
                                â€¢ StratÃ©gie : Feature extraction<br>
                                â€¢ Dataset : 10k descriptions patrimoine<br>
                                â€¢ Budget : 2M FCFA<br>
                                â€¢ DÃ©fi : richesse culturelle et authenticitÃ©<br>
                                â€¢ MÃ©trique : satisfaction touristes + exactitude historique</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "code",
            title: "Optimiseur d'hyperparamÃ¨tres",
            description: "CrÃ©ons un systÃ¨me d'optimisation automatique :",
            code: `class OptimiseurHyperparametres:
    def __init__(self):
        """Optimiseur d'hyperparamÃ¨tres pour fine-tuning"""
        self.hyperparams_ranges = {
            "learning_rate": [1e-5, 5e-5, 1e-4, 5e-4],
            "batch_size": [4, 8, 16, 32],
            "lora_rank": [8, 16, 32, 64],
            "lora_alpha": [16, 32, 64, 128],
            "epochs": [1, 2, 3, 5]
        }
        
        self.resultats = []
    
    def evaluer_configuration(self, config):
        """Simule l'Ã©valuation d'une configuration"""
        # Simulation basÃ©e sur des heuristiques rÃ©alistes
        
        # Learning rate optimal autour de 1e-4
        lr_score = 1.0 - abs(np.log10(config["learning_rate"]) + 4) / 2
        
        # Batch size optimal autour de 16
        bs_score = 1.0 - abs(config["batch_size"] - 16) / 16
        
        # Rank optimal autour de 32
        rank_score = 1.0 - abs(config["lora_rank"] - 32) / 32
        
        # Alpha/rank ratio optimal autour de 2
        ratio = config["lora_alpha"] / config["lora_rank"]
        ratio_score = 1.0 - abs(ratio - 2) / 2
        
        # Epochs optimal autour de 3
        epoch_score = 1.0 - abs(config["epochs"] - 3) / 3
        
        # Score global (moyenne pondÃ©rÃ©e)
        score = (lr_score * 0.3 + bs_score * 0.2 + rank_score * 0.2 + 
                ratio_score * 0.2 + epoch_score * 0.1)
        
        # Ajout de bruit rÃ©aliste
        score += np.random.normal(0, 0.05)
        score = np.clip(score, 0, 1)
        
        return score
    
    def recherche_grille(self, n_configs=20):
        """Recherche par grille sur un Ã©chantillon"""
        print("ğŸ” RECHERCHE D'HYPERPARAMÃˆTRES")
        print("=" * 40)
        
        # GÃ©nÃ©ration de configurations alÃ©atoires
        configs = []
        for _ in range(n_configs):
            config = {
                param: np.random.choice(values) 
                for param, values in self.hyperparams_ranges.items()
            }
            score = self.evaluer_configuration(config)
            configs.append((config, score))
        
        # Tri par score dÃ©croissant
        configs.sort(key=lambda x: x[1], reverse=True)
        
        print("ğŸ† TOP 5 CONFIGURATIONS:")
        print("-" * 60)
        
        for i, (config, score) in enumerate(configs[:5]):
            print(f"#{i+1} - Score: {score:.3f}")
            for param, value in config.items():
                print(f"   {param}: {value}")
            print()
        
        return configs[0]  # Meilleure configuration
    
    def estimer_cout_config(self, config):
        """Estime le coÃ»t d'une configuration"""
        # CoÃ»t basÃ© sur epochs, batch_size et learning_rate
        cout_base = 100000  # FCFA
        
        # Facteurs multiplicatifs
        facteur_epochs = config["epochs"]
        facteur_batch = 32 / config["batch_size"]  # Plus petit batch = plus d'itÃ©rations
        facteur_lr = 1.0  # Learning rate n'affecte pas le coÃ»t direct
        
        cout_total = cout_base * facteur_epochs * facteur_batch
        
        return {
            "cout_fcfa": cout_total,
            "cout_usd": cout_total / 600,
            "temps_heures": config["epochs"] * 8 * facteur_batch
        }

# Test de l'optimiseur
optimiseur = OptimiseurHyperparametres()

# Recherche de la meilleure configuration
meilleure_config, meilleur_score = optimiseur.recherche_grille(15)

print("ğŸ¯ CONFIGURATION OPTIMALE TROUVÃ‰E")
print("=" * 40)
print(f"Score: {meilleur_score:.3f}")

# Estimation du coÃ»t
cout_optimal = optimiseur.estimer_cout_config(meilleure_config)
print(f"\\nğŸ’° COÃ›T ESTIMÃ‰:")
print(f"Prix: {cout_optimal['cout_fcfa']:,.0f} FCFA ({cout_optimal['cout_usd']:.0f}$)")
print(f"Temps: {cout_optimal['temps_heures']:.0f} heures")`,
          },
          {
            type: "warning",
            icon: "âš ï¸",
            title: "L'avenir du fine-tuning : IA personnalisÃ©e pour tous",
            content: `
                        <p><strong>ğŸ”® Vision 2030 : DÃ©mocratisation totale de l'IA :</strong></p>
                        
                        <p><strong>ğŸš€ Tendances rÃ©volutionnaires :</strong></p>
                        <ul>
                            <li>ğŸ’° <strong>CoÃ»ts divisÃ©s par 1000</strong> : fine-tuning Ã  1$ au lieu de 1000$</li>
                            <li>â° <strong>Temps divisÃ© par 100</strong> : 1 heure au lieu de 1 semaine</li>
                            <li>ğŸ¯ <strong>Automatisation complÃ¨te</strong> : fine-tuning en un clic</li>
                            <li>ğŸ“± <strong>IA sur mobile</strong> : fine-tuning directement sur smartphone</li>
                        </ul>
                        
                        <p><strong>ğŸŒ Impact pour l'Afrique :</strong></p>
                        <ul>
                            <li>ğŸ—£ï¸ <strong>Toutes les langues africaines</strong> : 2000+ langues avec leur IA</li>
                            <li>ğŸ¥ <strong>SantÃ© personnalisÃ©e</strong> : IA adaptÃ©e Ã  chaque rÃ©gion</li>
                            <li>ğŸŒ¾ <strong>Agriculture intelligente</strong> : conseils ultra-localisÃ©s</li>
                            <li>ğŸ“š <strong>Ã‰ducation sur mesure</strong> : IA qui comprend chaque culture</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Techniques Ã©mergentes :</strong></p>
                        <ul>
                            <li>ğŸ§  <strong>Few-shot fine-tuning</strong> : adaptation avec 10 exemples</li>
                            <li>ğŸ”„ <strong>Continual learning</strong> : apprentissage sans oubli</li>
                            <li>ğŸ­ <strong>Persona fine-tuning</strong> : IA avec personnalitÃ©s culturelles</li>
                            <li>ğŸŒ <strong>Federated fine-tuning</strong> : apprentissage distribuÃ© respectueux</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Point clÃ© :</strong> Le fine-tuning transforme l'IA d'un outil gÃ©nÃ©raliste occidental en assistant personnalisÃ© qui comprend votre culture, votre langue, et vos besoins spÃ©cifiques.</p>
                        
                        <p><strong>ğŸ”® Prochaine Ã©tape :</strong> Prompt Engineering - l'art de communiquer efficacement avec ces IA fine-tunÃ©es !</p>
                    `,
          },
        ],
        quiz: {
          question:
            "ğŸ¤” Pourquoi LoRA est-il rÃ©volutionnaire pour le fine-tuning de gros modÃ¨les ?",
          options: [
            "A) Il est plus rapide Ã  entraÃ®ner",
            "B) Il rÃ©duit drastiquement le nombre de paramÃ¨tres Ã  entraÃ®ner",
            "C) Il donne de meilleurs rÃ©sultats",
            "D) Il ne nÃ©cessite pas de GPU",
          ],
          correct: 1,
          explanation:
            "LoRA rÃ©volutionne le fine-tuning en rÃ©duisant le nombre de paramÃ¨tres entraÃ®nables de 99% grÃ¢ce Ã  la dÃ©composition en matrices de faible rang. Au lieu d'entraÃ®ner 7 milliards de paramÃ¨tres, on n'en entraÃ®ne que quelques millions, tout en gardant des performances proches du fine-tuning complet.",
        },
        prevModule: "gpt-bert.html",
        nextModule: "prompt-engineering.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
