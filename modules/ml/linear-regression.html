<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>R√©gression Lin√©aire | IA4Ndada</title>

    <!-- MathJax pour les formules math√©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>ü§ñ Machine Learning</span>
          <span>‚Ä∫</span>
          <span>R√©gression Lin√©aire</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>üìà R√©gression Lin√©aire</h1>
      <p class="subtitle">Module 3.2 - Machine Learning</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajout√©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajout√© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>üéâ Checkpoint - R√©gression Lin√©aire</h3>
        <p>
          F√©licitations ! Vous comprenez maintenant le premier algorithme
          d'apprentissage automatique.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme compl√©t√©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="introduction.html" class="nav-link" id="prev-link"
          >‚Üê Module pr√©c√©dent : Introduction ML</a
        >
        <a href="classification.html" class="nav-link" id="next-link"
          >Module suivant : Classification ‚Üí</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module R√©gression Lin√©aire
      const moduleConfig = {
        id: "ml-linear-regression",
        title: "R√©gression Lin√©aire",
        category: "Machine Learning",
        objectives: [
          "Comprendre le probl√®me que r√©sout la r√©gression",
          "Construire une fonction de co√ªt depuis z√©ro",
          "D√©river math√©matiquement la solution optimale",
          "Comprendre pourquoi cette solution est unique",
          "Calculer manuellement sur un exemple concret",
        ],
        content: [
          {
            type: "concept",
            icon: "üí°",
            title: "Le probl√®me fondamental",
            content: `
                        <p><strong>Commen√ßons par un probl√®me concret :</strong></p>
                        
                        <p>Vous avez observ√© des donn√©es :</p>
                        <table style="margin: 1rem auto; text-align: center;">
                            <tr style="background: #3498db; color: white;">
                                <th style="padding: 0.5rem;">Heures d'√©tude (x)</th>
                                <th style="padding: 0.5rem;">Note obtenue (y)</th>
                            </tr>
                            <tr><td>1</td><td>5</td></tr>
                            <tr><td>2</td><td>7</td></tr>
                            <tr><td>3</td><td>8</td></tr>
                            <tr><td>4</td><td>10</td></tr>
                        </table>
                        
                        <p><strong>üéØ La question :</strong> Si quelqu'un √©tudie 2.5 heures, quelle note pr√©dire ?</p>
                        
                        <p><strong>üí° L'id√©e :</strong> Trouver une r√®gle math√©matique qui relie x et y.</p>
                        
                        <p><strong>üìê Le choix le plus simple :</strong> Une relation lin√©aire</p>
                        <p style="text-align: center;">$$y = ax + b$$</p>
                        
                        <p>O√π :</p>
                        <ul>
                            <li><strong>a</strong> = combien y augmente quand x augmente de 1</li>
                            <li><strong>b</strong> = valeur de y quand x = 0</li>
                        </ul>
                        
                        <p><strong>‚ùì Mais comment trouver les BONS a et b ?</strong></p>
                    `,
          },
          {
            type: "intuition",
            icon: "üß†",
            title: "Qu'est-ce qu'une \"bonne\" droite ?",
            content: `
                        <p><strong>Intuitivement, une bonne droite passe "pr√®s" de tous les points.</strong></p>
                        
                        <p><strong>üéØ Mais "pr√®s", √ßa veut dire quoi math√©matiquement ?</strong></p>
                        
                        <p>Pour chaque point \\(i\\), il y a une erreur :</p>
                        <ul>
                            <li><strong>Valeur r√©elle :</strong> \\(y_i\\)</li>
                            <li><strong>Valeur pr√©dite :</strong> \\(\\hat{y}_i = ax_i + b\\)</li>
                            <li><strong>Erreur :</strong> \\(e_i = y_i - \\hat{y}_i\\)</li>
                        </ul>
                        
                        <p><strong>üìä Mesurer l'erreur totale - 3 options :</strong></p>
                        
                        <div style="background: #ffebee; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>Option 1 : Somme des erreurs ?</strong><br>
                            $$\\sum_{i=1}^{n} e_i = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)$$
                            
                            ‚ùå <strong>Probl√®me :</strong> Les erreurs + et - s'annulent !<br>
                            Une droite tr√®s mauvaise pourrait avoir une erreur totale de 0.
                        </div>
                        
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>Option 2 : Somme des valeurs absolues ?</strong><br>
                            $$\\sum_{i=1}^{n} |e_i| = \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$
                            
                            ‚úì Pas d'annulation<br>
                            ‚ùå <strong>Probl√®me :</strong> Pas d√©rivable en 0 (voir <a href="../math/derivatives.html">Module 1.4</a>)
                        </div>
                        
                        <div style="background: #e8f5e9; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>Option 3 : Somme des carr√©s ‚úÖ</strong><br>
                            $$\\sum_{i=1}^{n} e_i^2 = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$
                            
                            ‚úì Pas d'annulation (carr√© toujours positif)<br>
                            ‚úì D√©rivable partout<br>
                            ‚úì P√©nalise plus les grandes erreurs<br>
                            ‚úì Solution math√©matique unique !
                        </div>
                    `,
          },
          {
            type: "mathematique",
            icon: "‚àë",
            title: "Construction de la fonction de co√ªt",
            content: `
                        <p><strong>D√©finissons formellement notre fonction de co√ªt :</strong></p>
                        
                        <div style="background: #f0f9ff; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>Fonction de co√ªt J(a, b) :</strong><br><br>
                            $$J(a, b) = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - (ax_i + b))^2$$
                            
                            <strong>Pourquoi chaque partie ?</strong><br>
                            ‚Ä¢ \\((y_i - (ax_i + b))^2\\) : erreur au carr√© pour le point i<br>
                            ‚Ä¢ \\(\\sum\\) : on additionne toutes les erreurs<br>
                            ‚Ä¢ \\(\\frac{1}{n}\\) : moyenne (ind√©pendant du nombre de points)<br>
                            ‚Ä¢ \\(\\frac{1}{2}\\) : simplifie les calculs de d√©riv√©e (dispara√Æt avec le 2 du carr√©)
                        </div>
                        
                        <p><strong>üéØ Notre objectif :</strong> Trouver \\(a^*\\) et \\(b^*\\) qui minimisent \\(J(a, b)\\).</p>
                        
                        <p><strong>üìê Rappel sur les minima (<a href="../math/derivatives.html">Module 1.4</a>) :</strong></p>
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            Pour une fonction d'une variable \\(f(x)\\), au minimum :<br>
                            ‚Ä¢ La d√©riv√©e \\(f'(x) = 0\\) (tangente horizontale)<br>
                            ‚Ä¢ La d√©riv√©e seconde \\(f''(x) > 0\\) (courbe en U)<br><br>
                            
                            Pour une fonction de deux variables \\(J(a, b)\\) (<a href="../math/gradients.html">Module 1.5</a>) :<br>
                            ‚Ä¢ Les d√©riv√©es partielles \\(\\frac{\\partial J}{\\partial a} = 0\\) et \\(\\frac{\\partial J}{\\partial b} = 0\\)<br>
                            ‚Ä¢ C'est le gradient \\(\\nabla J = [0, 0]\\)
                        </div>
                    `,
          },
          {
            type: "mathematique",
            icon: "‚àë",
            title: "Calcul des d√©riv√©es partielles",
            content: `
                        <p><strong>Trouvons o√π le gradient s'annule :</strong></p>
                        
                        <p><strong>üìê √âtape 1 : D√©riv√©e par rapport √† a</strong></p>
                        
                        <div style="background: #f0f9ff; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            Partons de : $$J(a, b) = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - ax_i - b)^2$$
                            
                            Appliquons la r√®gle de cha√Æne (<a href="../math/derivatives.html">Module 1.4</a>) :<br><br>
                            
                            $$\\frac{\\partial J}{\\partial a} = \\frac{1}{2n} \\sum_{i=1}^{n} 2(y_i - ax_i - b) \\cdot (-x_i)$$
                            
                            $$= -\\frac{1}{n} \\sum_{i=1}^{n} x_i(y_i - ax_i - b)$$
                        </div>
                        
                        <p><strong>üìê √âtape 2 : D√©riv√©e par rapport √† b</strong></p>
                        
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            De m√™me : $$\\frac{\\partial J}{\\partial b} = \\frac{1}{2n} \\sum_{i=1}^{n} 2(y_i - ax_i - b) \\cdot (-1)$$
                            
                            $$= -\\frac{1}{n} \\sum_{i=1}^{n} (y_i - ax_i - b)$$
                        </div>
                        
                        <p><strong>üìê √âtape 3 : Conditions d'optimalit√© (gradient = 0)</strong></p>
                        
                        <div style="background: #e8f5e9; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            Pour le minimum, on veut :<br><br>
                            
                            $$\\frac{\\partial J}{\\partial a} = 0 \\Rightarrow \\sum_{i=1}^{n} x_i(y_i - ax_i - b) = 0$$
                            
                            $$\\frac{\\partial J}{\\partial b} = 0 \\Rightarrow \\sum_{i=1}^{n} (y_i - ax_i - b) = 0$$
                            
                            C'est un syst√®me de 2 √©quations √† 2 inconnues !
                        </div>
                    `,
          },
          {
            type: "mathematique",
            icon: "‚àë",
            title: "R√©solution du syst√®me d'√©quations",
            content: `
                        <p><strong>R√©solvons ce syst√®me √©tape par √©tape :</strong></p>
                        
                        <p><strong>De la deuxi√®me √©quation :</strong></p>
                        <div style="background: #f0f9ff; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            $$\\sum_{i=1}^{n} (y_i - ax_i - b) = 0$$
                            
                            $$\\sum_{i=1}^{n} y_i - a\\sum_{i=1}^{n} x_i - nb = 0$$
                            
                            Divisons par n et introduisons les moyennes (<a href="../math/statistics.html">Module 1.7</a>) :<br>
                            $$\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i, \\quad \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$$
                            
                            On obtient : $$\\boxed{b = \\bar{y} - a\\bar{x}}$$
                            
                            <strong>üí° Insight :</strong> La droite passe par le point moyen \\((\\bar{x}, \\bar{y})\\) !
                        </div>
                        
                        <p><strong>De la premi√®re √©quation :</strong></p>
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            Substituons \\(b = \\bar{y} - a\\bar{x}\\) dans la premi√®re √©quation :<br><br>
                            
                            $$\\sum_{i=1}^{n} x_i(y_i - ax_i - \\bar{y} + a\\bar{x}) = 0$$
                            
                            R√©arrangeons :<br>
                            $$\\sum_{i=1}^{n} x_i(y_i - \\bar{y}) = a\\sum_{i=1}^{n} x_i(x_i - \\bar{x})$$
                            
                            Une astuce math√©matique (d√©veloppons et simplifions) :<br>
                            $$\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) = a\\sum_{i=1}^{n} (x_i - \\bar{x})^2$$
                        </div>
                        
                        <p><strong>La solution finale :</strong></p>
                        <div style="background: #e8f5e9; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            $$\\boxed{a = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}}$$
                            
                            <strong>üîç Reconnaissons ces quantit√©s (<a href="../math/statistics.html">Module 1.7</a>) :</strong><br><br>
                            
                            ‚Ä¢ Num√©rateur = n √ó Covariance(X, Y)<br>
                            ‚Ä¢ D√©nominateur = n √ó Variance(X)<br><br>
                            
                            Donc : $$a = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}$$
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "üí°",
            title: "Pourquoi cette formule a du sens",
            content: `
                        <p><strong>D√©cortiquons la formule de la pente :</strong></p>
                        
                        <p>$$a = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}$$</p>
                        
                        <p><strong>üìä La Covariance (<a href="../math/statistics.html">Module 1.7</a>) :</strong></p>
                        <div style="background: #f0f9ff; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            $$\\text{Cov}(X, Y) = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$$
                            
                            <strong>Intuition :</strong> Mesure si X et Y "bougent ensemble"<br>
                            ‚Ä¢ Si X‚Üë et Y‚Üë ensemble : produits positifs ‚Üí Cov > 0<br>
                            ‚Ä¢ Si X‚Üë mais Y‚Üì : produits n√©gatifs ‚Üí Cov < 0<br>
                            ‚Ä¢ Si pas de relation : produits mixtes ‚Üí Cov ‚âà 0
                        </div>
                        
                        <p><strong>üìä La Variance :</strong></p>
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            $$\\text{Var}(X) = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\bar{x})^2$$
                            
                            <strong>Intuition :</strong> Mesure l'√©talement de X<br>
                            ‚Ä¢ Grande variance : X tr√®s dispers√©<br>
                            ‚Ä¢ Petite variance : X concentr√©
                        </div>
                        
                        <p><strong>üéØ Le ratio Cov/Var :</strong></p>
                        <div style="background: #e8f5e9; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>Pourquoi diviser ?</strong><br><br>
                            
                            Imaginez X en m√®tres, puis convertissez en centim√®tres (√ó100) :<br>
                            ‚Ä¢ Cov ‚Üí 100 √ó Cov (un facteur de X)<br>
                            ‚Ä¢ Var ‚Üí 10000 √ó Var (X au carr√©)<br>
                            ‚Ä¢ Ratio ‚Üí (100√óCov)/(10000√óVar) = Cov/(100√óVar) = a/100<br><br>
                            
                            La pente s'ajuste automatiquement ! C'est une <strong>normalisation naturelle</strong>.
                        </div>
                    `,
          },
          {
            type: "exemple",
            icon: "üíª",
            title: "Application num√©rique compl√®te",
            content: `
                        <p><strong>Reprenons nos donn√©es initiales :</strong></p>
                        
                        <table style="margin: 1rem auto; text-align: center;">
                            <tr style="background: #3498db; color: white;">
                                <th style="padding: 0.5rem;">i</th>
                                <th style="padding: 0.5rem;">x_i (heures)</th>
                                <th style="padding: 0.5rem;">y_i (note)</th>
                            </tr>
                            <tr><td>1</td><td>1</td><td>5</td></tr>
                            <tr><td>2</td><td>2</td><td>7</td></tr>
                            <tr><td>3</td><td>3</td><td>8</td></tr>
                            <tr><td>4</td><td>4</td><td>10</td></tr>
                        </table>
                        
                        <p><strong>üìä √âtape 1 : Moyennes</strong></p>
                        <div style="background: #f0f9ff; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            $$\\bar{x} = \\frac{1+2+3+4}{4} = 2.5$$
                            $$\\bar{y} = \\frac{5+7+8+10}{4} = 7.5$$
                            
                            Point moyen : (2.5, 7.5)
                        </div>
                        
                        <p><strong>üìä √âtape 2 : Calcul de a</strong></p>
                        <table style="margin: 1rem auto; text-align: center; font-size: 0.9rem;">
                            <tr style="background: #3498db; color: white;">
                                <th>i</th>
                                <th>x_i - 2.5</th>
                                <th>y_i - 7.5</th>
                                <th>(x_i - 2.5)(y_i - 7.5)</th>
                                <th>(x_i - 2.5)¬≤</th>
                            </tr>
                            <tr><td>1</td><td>-1.5</td><td>-2.5</td><td style="background: yellow;">3.75</td><td>2.25</td></tr>
                            <tr><td>2</td><td>-0.5</td><td>-0.5</td><td style="background: yellow;">0.25</td><td>0.25</td></tr>
                            <tr><td>3</td><td>0.5</td><td>0.5</td><td style="background: yellow;">0.25</td><td>0.25</td></tr>
                            <tr><td>4</td><td>1.5</td><td>2.5</td><td style="background: yellow;">3.75</td><td>2.25</td></tr>
                            <tr style="font-weight: bold;"><td colspan="3">Sommes ‚Üí</td><td>8</td><td>5</td></tr>
                        </table>
                        
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            $$a = \\frac{8}{5} = 1.6$$
                            
                            <strong>Interpr√©tation :</strong> +1 heure d'√©tude ‚Üí +1.6 points
                        </div>
                        
                        <p><strong>üìä √âtape 3 : Calcul de b</strong></p>
                        <div style="background: #e8f5e9; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            $$b = \\bar{y} - a\\bar{x} = 7.5 - 1.6 \\times 2.5 = 7.5 - 4 = 3.5$$
                            
                            <strong>Interpr√©tation :</strong> Note de base (0 heure) = 3.5
                        </div>
                        
                        <p><strong>‚úÖ Mod√®le final :</strong></p>
                        <div style="background: #d1ecf1; padding: 1rem; border-radius: 4px; margin: 1rem 0; text-align: center; font-size: 1.2rem;">
                            <strong>Note = 1.6 √ó Heures + 3.5</strong>
                        </div>
                        
                        <p><strong>üéØ Pr√©diction pour 2.5 heures :</strong></p>
                        <div style="background: #d4edda; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            Note = 1.6 √ó 2.5 + 3.5 = 4 + 3.5 = <strong>7.5</strong><br>
                            (C'est exactement la moyenne ! Normal, c'est \\(\\bar{x}\\))
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "üí°",
            title: "Unicit√© de la solution",
            content: `
                        <p><strong>Pourquoi cette solution est-elle unique ?</strong></p>
                        
                        <p><strong>üîç G√©om√©triquement :</strong></p>
                        <div style="background: #f0f9ff; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            La fonction de co√ªt \\(J(a, b)\\) forme une surface en 3D :<br>
                            ‚Ä¢ Axes horizontaux : a et b<br>
                            ‚Ä¢ Axe vertical : erreur J<br><br>
                            
                            Cette surface est un <strong>parabolo√Øde</strong> (forme de bol).<br>
                            Un bol n'a qu'UN SEUL point le plus bas !
                        </div>
                        
                        <p><strong>üìê Math√©matiquement :</strong></p>
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            La matrice Hessienne (d√©riv√©es secondes) est :<br><br>
                            
                            $$H = \\begin{bmatrix} 
                            \\frac{\\partial^2 J}{\\partial a^2} & \\frac{\\partial^2 J}{\\partial a \\partial b} \\\\
                            \\frac{\\partial^2 J}{\\partial b \\partial a} & \\frac{\\partial^2 J}{\\partial b^2}
                            \\end{bmatrix} = \\frac{1}{n}\\begin{bmatrix} 
                            \\sum x_i^2 & \\sum x_i \\\\
                            \\sum x_i & n
                            \\end{bmatrix}$$<br>
                            
                            Cette matrice est <strong>d√©finie positive</strong> (sauf cas d√©g√©n√©r√©).<br>
                            ‚Üí Un seul minimum global !
                        </div>
                        
                        <p><strong>üéØ Cas d√©g√©n√©r√© :</strong></p>
                        <div style="background: #ffebee; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            Si tous les x_i sont identiques :<br>
                            ‚Ä¢ Variance(X) = 0<br>
                            ‚Ä¢ Division par 0 dans la formule !<br>
                            ‚Ä¢ G√©om√©triquement : tous les points align√©s verticalement<br>
                            ‚Ä¢ Infinit√© de droites possibles ‚Üí pas de solution unique
                        </div>
                    `,
          },
          {
            type: "warning",
            icon: "‚ö†Ô∏è",
            title: "Biais, Variance et limites",
            content: `
                        <p><strong>Comprendre les erreurs du mod√®le :</strong></p>
                        
                        <p><strong>1Ô∏è‚É£ Le Biais :</strong></p>
                        <div style="background: #f0f9ff; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>D√©finition :</strong> Erreur due √† des hypoth√®ses trop simples<br><br>
                            
                            Si la vraie relation est \\(y = x^2\\) mais on utilise \\(y = ax + b\\) :<br>
                            ‚Ä¢ M√™me avec ‚àû donn√©es parfaites<br>
                            ‚Ä¢ Notre droite ne pourra JAMAIS capturer la courbe<br>
                            ‚Ä¢ C'est un biais structurel du mod√®le
                        </div>
                        
                        <p><strong>2Ô∏è‚É£ La Variance :</strong></p>
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>D√©finition :</strong> Sensibilit√© aux donn√©es d'entra√Ænement<br><br>
                            
                            Avec peu de donn√©es bruit√©es :<br>
                            ‚Ä¢ Changer 1 point change la droite<br>
                            ‚Ä¢ Diff√©rents √©chantillons ‚Üí diff√©rentes droites<br>
                            ‚Ä¢ Plus de donn√©es ‚Üí variance r√©duite
                        </div>
                        
                        <p><strong>‚öñÔ∏è Trade-off pour la r√©gression lin√©aire :</strong></p>
                        <div style="background: #e8f5e9; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            ‚Ä¢ <strong>Biais :</strong> Potentiellement √©lev√© (mod√®le simple)<br>
                            ‚Ä¢ <strong>Variance :</strong> Faible (seulement 2 param√®tres)<br>
                            ‚Ä¢ <strong>Robuste</strong> mais peut √™tre trop simpliste<br><br>
                            
                            C'est souvent un bon point de d√©part !
                        </div>
                        
                        <p><strong>‚ö†Ô∏è Hypoth√®ses importantes :</strong></p>
                        <ul>
                            <li>Relation lin√©aire entre X et Y</li>
                            <li>Erreurs ind√©pendantes et identiquement distribu√©es</li>
                            <li>Variance constante des erreurs (homosc√©dasticit√©)</li>
                            <li>Pas de colin√©arit√© parfaite (pour r√©gression multiple)</li>
                        </ul>
                    `,
          },
        ],
        quiz: {
          question:
            "ü§î Que se passe-t-il si tous les points sont parfaitement align√©s sur une droite ?",
          options: [
            "A) La r√©gression √©choue",
            "B) a = ‚àû et b = 0",
            "C) L'erreur J = 0 et la solution est exacte",
            "D) Il y a une infinit√© de solutions",
          ],
          correct: 2,
          explanation:
            "Si les points sont parfaitement align√©s, la r√©gression trouve LA droite qui passe exactement par tous les points. L'erreur J = 0 (aucune erreur !), et les formules donnent les param√®tres exacts de cette droite.",
        },
        prevModule: "introduction.html",
        nextModule: "classification.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
