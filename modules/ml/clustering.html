<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Clustering | IA4Ndada</title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>ü§ñ Machine Learning</span>
          <span>‚Ä∫</span>
          <span>Clustering</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div class="progress-fill" id="progress-fill" style="width: 0%"></div>
          </div>
        </div>
      </div>
    </nav>

    <div class="container">
      <h1>üîç Clustering</h1>
      <p class="subtitle">Module 3.4 - D√©couvrir des groupes sans labels</p>

      <div id="pyodide-status" class="pyodide-status">
        <span class="status-loading">‚è≥ Chargement de Python...</span>
      </div>

      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list"></ul>
      </div>

      <div id="module-content"></div>

      <div class="checkpoint">
        <h3>üéâ Checkpoint - Clustering</h3>
        <p>Vous ma√Ætrisez l'apprentissage non-supervis√© avec K-Means !</p>
        <button class="checkpoint-btn" id="checkpoint-btn" onclick="completeCheckpoint()" disabled>
          Valider le module
        </button>
      </div>

      <div class="module-nav">
        <a href="classification.html" class="nav-link">‚Üê Classification</a>
        <a href="validation.html" class="nav-link">Validation ‚Üí</a>
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      const moduleConfig = {
        id: "ml-clustering",
        title: "Clustering",
        objectives: [
          "Comprendre l'apprentissage non-supervis√©",
          "Ma√Ætriser l'algorithme K-Means",
          "Choisir le bon nombre de clusters (m√©thode du coude)",
          "Conna√Ætre les limites et alternatives",
        ],
        content: [
          // Section 1: Introduction
          {
            type: "concept",
            icon: "üîç",
            title: "Apprentissage non-supervis√©",
            content: `
              <p>Contrairement √† la classification, le clustering n'a <strong>pas de labels</strong> :</p>

              <table style="width: 100%; border-collapse: collapse; margin: 1rem 0;">
                <tr style="background: #f0f0f0;">
                  <th style="padding: 0.5rem; border: 1px solid #ddd;">Supervis√©</th>
                  <th style="padding: 0.5rem; border: 1px solid #ddd;">Non-supervis√©</th>
                </tr>
                <tr>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;">On sait la r√©ponse</td>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;">On d√©couvre des patterns</td>
                </tr>
                <tr>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;">Spam/pas spam (donn√©)</td>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;">Groupes de clients (√† d√©couvrir)</td>
                </tr>
              </table>

              <p><strong>Applications du clustering :</strong></p>
              <ul>
                <li>üë• Segmentation de clients</li>
                <li>üõí Recommandation de produits</li>
                <li>üì∞ Regroupement de documents</li>
                <li>üñºÔ∏è Compression d'images</li>
                <li>üî¨ Analyse g√©nomique</li>
              </ul>
            `,
          },
          {
            type: "quiz",
            title: "V√©rification - Type d'apprentissage",
            question: "Une entreprise veut regrouper ses clients selon leurs habitudes d'achat, SANS cat√©gories pr√©d√©finies. C'est :",
            options: [
              "Classification supervis√©e",
              "R√©gression",
              "Clustering (non-supervis√©)",
              "Apprentissage par renforcement",
            ],
            correctAnswer: 2,
            explanation: "Pas de labels pr√©d√©finis ‚Üí non-supervis√©. On d√©couvre naturellement les groupes de clients similaires. C'est du clustering.",
          },
          // Section 2: K-Means
          {
            type: "concept",
            icon: "üìä",
            title: "L'algorithme K-Means",
            content: `
              <p>K-Means est l'algorithme de clustering le plus populaire.</p>

              <p><strong>Id√©e :</strong> Trouver K points (centro√Ødes) qui minimisent la distance des donn√©es √† leur centro√Øde le plus proche.</p>

              <p><strong>Algorithme :</strong></p>
              <ol>
                <li><strong>Initialiser</strong> K centro√Ødes al√©atoirement</li>
                <li><strong>Assigner</strong> chaque point au centro√Øde le plus proche</li>
                <li><strong>Recalculer</strong> les centro√Ødes (moyenne des points assign√©s)</li>
                <li><strong>R√©p√©ter</strong> 2-3 jusqu'√† convergence</li>
              </ol>

              <p><strong>Fonction objectif (inertie) :</strong></p>
              <p style="text-align: center; background: #e3f2fd; padding: 1rem; border-radius: 8px;">
                $$J = \\sum_{i=1}^{n} \\min_{k} ||x_i - \\mu_k||^2$$
              </p>
              <p>O√π Œº<sub>k</sub> est le centro√Øde du cluster k.</p>
            `,
          },
          {
            type: "exercise",
            title: "Calcul de distance",
            exerciseType: "numeric",
            content: `
              <p>Deux points : A(2, 3) et B(5, 7)</p>
              <p>Calculez la distance euclidienne entre A et B :</p>
              <p style="text-align: center;">$$d = \\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}$$</p>
            `,
            correctAnswer: 5,
            tolerance: 0.01,
            hint: "d = ‚àö[(5-2)¬≤ + (7-3)¬≤] = ‚àö[9 + 16] = ‚àö25",
            explanation: "d = ‚àö(3¬≤ + 4¬≤) = ‚àö(9+16) = ‚àö25 = 5. C'est le triangle 3-4-5 !",
          },
          {
            type: "code",
            title: "K-Means from scratch",
            description: "Impl√©mentons K-Means pas √† pas :",
            code: `import numpy as np
import matplotlib.pyplot as plt

# G√©n√©rer des donn√©es avec 3 clusters
np.random.seed(42)
n_points = 60

# 3 groupes de clients
groupe1 = np.random.randn(20, 2) + [0, 0]      # Clients √©conomes
groupe2 = np.random.randn(20, 2) + [5, 5]      # Clients premium
groupe3 = np.random.randn(20, 2) + [0, 5]      # Clients occasionnels

X = np.vstack([groupe1, groupe2, groupe3])

print("üìä CLUSTERING K-MEANS")
print(f"Donn√©es : {len(X)} clients √† regrouper")

def kmeans(X, K, max_iters=100):
    """K-Means from scratch"""
    n = len(X)

    # 1. Initialiser les centro√Ødes al√©atoirement
    idx = np.random.choice(n, K, replace=False)
    centroids = X[idx].copy()

    for iteration in range(max_iters):
        # 2. Assigner chaque point au centro√Øde le plus proche
        distances = np.zeros((n, K))
        for k in range(K):
            distances[:, k] = np.sum((X - centroids[k])**2, axis=1)
        labels = np.argmin(distances, axis=1)

        # 3. Recalculer les centro√Ødes
        new_centroids = np.zeros((K, X.shape[1]))
        for k in range(K):
            if np.sum(labels == k) > 0:
                new_centroids[k] = X[labels == k].mean(axis=0)
            else:
                new_centroids[k] = centroids[k]

        # V√©rifier convergence
        if np.allclose(centroids, new_centroids):
            print(f"Convergence apr√®s {iteration+1} it√©rations")
            break
        centroids = new_centroids

    # Calculer l'inertie
    inertia = sum(np.sum((X[labels==k] - centroids[k])**2) for k in range(K))

    return labels, centroids, inertia

# Ex√©cuter K-Means avec K=3
labels, centroids, inertia = kmeans(X, K=3)
print(f"Inertie finale: {inertia:.2f}")

# Visualisation
plt.figure(figsize=(10, 6))
colors = ['red', 'blue', 'green']
for k in range(3):
    mask = labels == k
    plt.scatter(X[mask, 0], X[mask, 1], c=colors[k], label=f'Cluster {k+1}', alpha=0.6)
plt.scatter(centroids[:, 0], centroids[:, 1], c='black', marker='X', s=200, label='Centro√Ødes')
plt.xlabel('Feature 1 (ex: d√©penses)')
plt.ylabel('Feature 2 (ex: fr√©quence)')
plt.title('Segmentation Clients par K-Means (K=3)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

print(f"\\nüìä R√âPARTITION :")
for k in range(3):
    print(f"Cluster {k+1}: {np.sum(labels==k)} clients")`,
          },
          {
            type: "quiz",
            title: "Quiz - K-Means",
            question: "Apr√®s une it√©ration de K-Means, que fait-on exactement pour recalculer un centro√Øde ?",
            options: [
              "On prend le point le plus central du cluster",
              "On calcule la moyenne de tous les points assign√©s √† ce cluster",
              "On choisit un nouveau point au hasard",
              "On d√©place le centro√Øde vers le point le plus √©loign√©",
            ],
            correctAnswer: 1,
            explanation: "Le nouveau centro√Øde est la MOYENNE (barycentre) des points assign√©s au cluster. C'est ce qui minimise la somme des distances au carr√© dans le cluster.",
          },
          // Section 3: Choix de K
          {
            type: "concept",
            icon: "üìà",
            title: "M√©thode du coude (Elbow Method)",
            content: `
              <p><strong>Probl√®me :</strong> Comment choisir K (nombre de clusters) ?</p>

              <p><strong>M√©thode du coude :</strong></p>
              <ol>
                <li>Ex√©cuter K-Means pour K = 1, 2, 3, ..., 10</li>
                <li>Noter l'inertie pour chaque K</li>
                <li>Tracer inertie en fonction de K</li>
                <li>Chercher le "coude" dans la courbe</li>
              </ol>

              <p><strong>Intuition :</strong></p>
              <ul>
                <li>K=1 : un seul cluster, inertie maximale</li>
                <li>K‚Üë : inertie diminue (plus de clusters = plus proche)</li>
                <li>Au-del√† d'un certain K : diminution marginale</li>
                <li>Le "coude" = bon compromis</li>
              </ul>

              <p style="background: #fff3e0; padding: 1rem; border-radius: 8px;">
                <strong>‚ö†Ô∏è Attention :</strong> Le coude n'est pas toujours √©vident. Utiliser aussi la connaissance m√©tier !
              </p>
            `,
          },
          {
            type: "exercise",
            title: "Interpr√©tation du coude",
            exerciseType: "mcq",
            content: `
              <p>Vous tracez l'inertie pour K = 1 √† 10 et observez :</p>
              <ul>
                <li>K=1 : inertie = 1000</li>
                <li>K=2 : inertie = 500</li>
                <li>K=3 : inertie = 200</li>
                <li>K=4 : inertie = 180</li>
                <li>K=5 : inertie = 170</li>
              </ul>
              <p><strong>Quel K choisir selon la m√©thode du coude ?</strong></p>
            `,
            options: [
              "K=2 (plus grande diminution)",
              "K=3 (coude visible, diminution forte puis faible)",
              "K=5 (inertie la plus basse)",
              "K=1 (le plus simple)",
            ],
            correctAnswer: 1,
            explanation: "Le coude est √† K=3. Entre K=2 et K=3, on gagne 300 (500‚Üí200). Entre K=3 et K=4, on ne gagne que 20 (200‚Üí180). La diminution marginale devient faible apr√®s K=3.",
          },
          // Section 4: Code m√©thode du coude
          {
            type: "code",
            title: "Visualiser la m√©thode du coude",
            description: "Trouvons le bon K :",
            code: `# M√©thode du coude
inerties = []
K_range = range(1, 8)

for K in K_range:
    _, _, inertia = kmeans(X, K)
    inerties.append(inertia)
    print(f"K={K}: inertie = {inertia:.1f}")

# Visualisation
plt.figure(figsize=(10, 5))
plt.plot(K_range, inerties, 'bo-', linewidth=2, markersize=10)
plt.xlabel('Nombre de clusters (K)')
plt.ylabel('Inertie')
plt.title('M√©thode du Coude')
plt.grid(True, alpha=0.3)

# Marquer le coude
plt.axvline(x=3, color='red', linestyle='--', alpha=0.7, label='Coude sugg√©r√©')
plt.legend()
plt.show()

print("\\nüí° Le coude est visible √† K=3")
print("C'est coh√©rent car on a g√©n√©r√© 3 groupes !")`,
          },
          {
            type: "exercise-code",
            title: "Calculez l'inertie d'un cluster",
            content: `
              <p>L'inertie d'un cluster est la somme des distances au carr√© entre chaque point et le centro√Øde.</p>
              <p>Compl√©tez le code :</p>
            `,
            starterCode: `import numpy as np

# Donn√©es d'un cluster
points = np.array([[1, 2], [2, 3], [3, 2], [2, 1]])
centroid = np.array([2, 2])

# TODO: Calculer l'inertie
# Pour chaque point, calculer (distance au centro√Øde)¬≤

inertia = 0
for point in points:
    distance_squared = np.sum((point - centroid) ** 2)
    inertia += distance_squared

print(f"Points du cluster: {len(points)}")
print(f"Centro√Øde: {centroid}")
print(f"Inertie: {inertia}")`,
            solution: `import numpy as np

points = np.array([[1, 2], [2, 3], [3, 2], [2, 1]])
centroid = np.array([2, 2])

inertia = np.sum((points - centroid) ** 2)
print(f"Inertie: {inertia}")`,
            expectedOutput: "Inertie:",
          },
          // Section 5: Limites
          {
            type: "concept",
            icon: "‚ö†Ô∏è",
            title: "Limites de K-Means",
            content: `
              <p><strong>K-Means a des limites importantes :</strong></p>

              <p><strong>1. K doit √™tre fix√© √† l'avance</strong></p>
              <p>On ne d√©couvre pas automatiquement le nombre de clusters.</p>

              <p><strong>2. Clusters sph√©riques</strong></p>
              <p>K-Means suppose des clusters "ronds". Ne fonctionne pas bien avec des formes allong√©es ou complexes.</p>

              <p><strong>3. Sensibilit√© √† l'initialisation</strong></p>
              <p>Diff√©rentes initialisations peuvent donner diff√©rents r√©sultats. Solution : K-Means++ ou plusieurs runs.</p>

              <p><strong>4. Sensibilit√© aux outliers</strong></p>
              <p>Un point aberrant peut d√©caler un centro√Øde.</p>

              <p><strong>Alternatives :</strong></p>
              <ul>
                <li><strong>DBSCAN</strong> : pas besoin de K, d√©tecte les outliers</li>
                <li><strong>Hierarchical</strong> : cr√©e un dendrogramme</li>
                <li><strong>GMM</strong> : clusters de formes flexibles</li>
              </ul>
            `,
          },
          {
            type: "quiz",
            title: "Quiz final - Clustering",
            question: "Vous avez des donn√©es de clients avec des outliers importants (achats exceptionnels). Quel algorithme serait pr√©f√©rable ?",
            options: [
              "K-Means (le plus populaire)",
              "DBSCAN (g√®re les outliers naturellement)",
              "R√©gression lin√©aire",
              "Classification supervis√©e",
            ],
            correctAnswer: 1,
            explanation: "DBSCAN ne force pas chaque point dans un cluster. Les outliers sont automatiquement identifi√©s comme 'bruit' et n'affectent pas les clusters. K-Means serait perturb√© par ces outliers.",
          },
        ],
        prevModule: "classification.html",
        nextModule: "validation.html",
      };

      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
