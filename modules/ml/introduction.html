<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction au Machine Learning | IA4Ndada</title>

    <!-- MathJax pour les formules mathématiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">🏠 Accueil</a>
          <span>›</span>
          <span>🤖 Machine Learning</span>
          <span>›</span>
          <span>Introduction</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>🤖 Introduction au Machine Learning</h1>
      <p class="subtitle">Module 3.1 - Apprentissage Automatique</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>🎯 Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajoutés dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajouté dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>🎉 Checkpoint - Introduction ML</h3>
        <p>
          Félicitations ! Vous comprenez maintenant les fondements conceptuels
          du Machine Learning.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme complété
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="../python/algorithms.html" class="nav-link" id="prev-link"
          >← Module précédent : Algorithmes</a
        >
        <a href="linear-regression.html" class="nav-link" id="next-link"
          >Module suivant : Régression Linéaire →</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Introduction ML
      const moduleConfig = {
        id: "ml-introduction",
        title: "Introduction au Machine Learning",
        category: "Machine Learning",
        objectives: [
          "Comprendre ce qu'est vraiment le Machine Learning",
          "Distinguer les 3 types d'apprentissage automatique",
          "Maîtriser les concepts de biais et variance",
          "Comprendre les différents types d'erreurs en ML",
        ],
        content: [
          {
            type: "concept",
            icon: "💡",
            title: "Qu'est-ce que le Machine Learning ?",
            content: `
                        <p>Le <strong>Machine Learning</strong> est l'art d'enseigner aux ordinateurs à <strong>apprendre des patterns</strong> dans les données, plutôt que de programmer explicitement chaque règle.</p>
                        
                        <p><strong>🔑 Révolution conceptuelle :</strong></p>
                        <ul>
                            <li>🖥️ <strong>Programmation classique</strong> : "Si température > 30°C, alors porter des vêtements légers"</li>
                            <li>🤖 <strong>Machine Learning</strong> : "Voici 10 000 exemples de températures et vêtements portés. Trouve le pattern !"</li>
                        </ul>
                        
                        <p><strong>🧠 Analogie de l'apprentissage humain :</strong></p>
                        <p>Un enfant apprend à reconnaître un chien en voyant des centaines de chiens différents. Il développe intuitivement le concept de "chien" sans qu'on lui explique les règles précises.</p>
                        
                        <p><strong>🎯 Trois paradigmes d'apprentissage :</strong></p>
                        <ul>
                            <li>📚 <strong>Supervisé</strong> : apprendre avec un professeur (exemples étiquetés)</li>
                            <li>🔍 <strong>Non-supervisé</strong> : découvrir des patterns cachés (pas d'étiquettes)</li>
                            <li>🎮 <strong>Par renforcement</strong> : apprendre par essai-erreur avec récompenses</li>
                        </ul>
                    `,
          },
          {
            type: "intuition",
            icon: "🧠",
            title: "Les trois types d'apprentissage expliqués simplement",
            content: `
                        <p><strong>🎓 Apprentissage Supervisé :</strong></p>
                        <p>Comme un étudiant avec un professeur qui corrige ses copies. On montre à l'algorithme des exemples avec les bonnes réponses.</p>
                        <p><strong>Exemple :</strong> "Voici 1000 emails. Ceux-ci sont des spams, ceux-là ne le sont pas. Maintenant, classe ce nouvel email !"</p>
                        
                        <p><strong>🔍 Apprentissage Non-Supervisé :</strong></p>
                        <p>Comme un explorateur qui découvre des territoires inconnus. L'algorithme trouve des groupes ou patterns sans qu'on lui dise quoi chercher.</p>
                        <p><strong>Exemple :</strong> "Voici les habitudes d'achat de 10 000 clients. Trouve des groupes de clients similaires !"</p>
                        
                        <p><strong>🎮 Apprentissage par Renforcement :</strong></p>
                        <p>Comme apprendre à jouer aux échecs : on essaie des coups, on gagne ou perd, et on s'améliore progressivement.</p>
                        <p><strong>Exemple :</strong> "Apprends à conduire une voiture autonome en essayant, en recevant des récompenses pour les bons comportements et des pénalités pour les mauvais."</p>
                    `,
          },
          {
            type: "concept",
            icon: "💡",
            title: "Le biais et la variance : concepts fondamentaux",
            content: `
                        <p><strong>🎯 Biais et variance</strong> sont deux sources d'erreur fondamentales en ML. Comprendre cette distinction est crucial pour créer de bons modèles.</p>
                        
                        <p><strong>🎯 Le Biais :</strong></p>
                        <p>Le <strong>biais</strong> mesure à quel point nos prédictions sont systématiquement éloignées de la vérité, même avec beaucoup de données.</p>
                        <p><strong>Analogie :</strong> Un archer qui vise toujours 10cm à droite de la cible. Ses tirs sont cohérents mais systématiquement décalés.</p>
                        
                        <p><strong>📊 La Variance :</strong></p>
                        <p>La <strong>variance</strong> mesure à quel point nos prédictions changent quand on change légèrement les données d'entraînement.</p>
                        <p><strong>Analogie :</strong> Un archer dont les flèches sont dispersées partout autour de la cible. Parfois proche, parfois loin, très imprévisible.</p>
                        
                        <p><strong>⚖️ Le compromis biais-variance :</strong></p>
                        <ul>
                            <li>🎯 <strong>Biais élevé, variance faible</strong> : modèle trop simple (sous-apprentissage)</li>
                            <li>🎯 <strong>Biais faible, variance élevée</strong> : modèle trop complexe (surapprentissage)</li>
                            <li>🎯 <strong>Objectif</strong> : équilibre optimal entre les deux</li>
                        </ul>
                    `,
          },
          {
            type: "mathematique",
            icon: "∑",
            title: "Formalisation mathématique du biais-variance",
            content: `
                        <p><strong>📐 Décomposition mathématique de l'erreur :</strong></p>
                        <p>Pour un modèle \\(\\hat{f}(x)\\) qui prédit une valeur \\(y\\), l'erreur totale se décompose en :</p>
                        
                        <p>$$\\text{Erreur} = \\text{Biais}^2 + \\text{Variance} + \\text{Bruit}$$</p>
                        
                        <p><strong>🔍 Détail de chaque composante :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>• Biais² :</strong> $$\\text{Biais}^2 = (E[\\hat{f}(x)] - f(x))^2$$</li>
                            <li style="margin-top: 0.5rem"><strong>• Variance :</strong> $$\\text{Variance} = E[(\\hat{f}(x) - E[\\hat{f}(x)])^2]$$</li>
                            <li style="margin-top: 0.5rem"><strong>• Bruit :</strong> $$\\text{Bruit} = E[(y - f(x))^2]$$</li>
                        </ul>
                        
                        <p><strong>🔑 Interprétation :</strong></p>
                        <ul>
                            <li>\\(f(x)\\) = vraie fonction (inconnue)</li>
                            <li>\\(\\hat{f}(x)\\) = notre modèle</li>
                            <li>\\(E[\\cdot]\\) = espérance (moyenne sur tous les datasets possibles)</li>
                            <li>Le <strong>bruit</strong> est irréductible (erreur inhérente aux données)</li>
                        </ul>
                        
                        <p><strong>🎯 Objectif d'optimisation :</strong></p>
                        <p>Minimiser \\(\\text{Biais}^2 + \\text{Variance}\\) car le bruit est incompressible.</p>
                    `,
          },
          {
            type: "concept",
            icon: "💡",
            title: "Types d'erreurs en Machine Learning",
            content: `
                        <p><strong>🎯 En ML, il existe plusieurs types d'erreurs qu'il faut comprendre :</strong></p>
                        
                        <p><strong>📊 1. Erreur d'entraînement (Training Error) :</strong></p>
                        <p>Performance du modèle sur les données qu'il a vues pendant l'apprentissage.</p>
                        <p><strong>Analogie :</strong> Notes d'un étudiant sur les exercices qu'il a déjà résolus en classe.</p>
                        
                        <p><strong>🧪 2. Erreur de validation (Validation Error) :</strong></p>
                        <p>Performance sur des données non vues, utilisées pour ajuster le modèle.</p>
                        <p><strong>Analogie :</strong> Notes sur des exercices similaires mais nouveaux pour vérifier la compréhension.</p>
                        
                        <p><strong>🎯 3. Erreur de test (Test Error) :</strong></p>
                        <p>Performance finale sur des données complètement nouvelles, jamais utilisées.</p>
                        <p><strong>Analogie :</strong> Note à l'examen final sur des sujets totalement inédits.</p>
                        
                        <p><strong>⚠️ Problèmes courants :</strong></p>
                        <ul>
                            <li>🔴 <strong>Surapprentissage</strong> : excellent en entraînement, mauvais en test</li>
                            <li>🔵 <strong>Sous-apprentissage</strong> : mauvais partout, modèle trop simple</li>
                            <li>🟡 <strong>Fuite de données</strong> : information du futur dans les données d'entraînement</li>
                        </ul>
                    `,
          },
          {
            type: "mathematique",
            icon: "∑",
            title: "Métriques d'évaluation mathématiques",
            content: `
                        <p><strong>📏 Comment mesurer la performance d'un modèle ?</strong></p>
                        
                        <p><strong>🔢 Pour la régression (prédire des nombres) :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>• Erreur Quadratique Moyenne (MSE) :</strong> $$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$</li>
                            <li style="margin-top: 1rem"><strong>• Erreur Absolue Moyenne (MAE) :</strong> $$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$</li>
                            <li style="margin-top: 1rem"><strong>• Coefficient de détermination (R²) :</strong> $$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$</li>
                        </ul>
                        
                        <p><strong>🎯 Pour la classification (prédire des catégories) :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>• Précision :</strong> $$\\text{Précision} = \\frac{\\text{Vrais Positifs}}{\\text{Vrais Positifs + Faux Positifs}}$$</li>
                            <li style="margin-top: 1rem"><strong>• Rappel :</strong> $$\\text{Rappel} = \\frac{\\text{Vrais Positifs}}{\\text{Vrais Positifs + Faux Négatifs}}$$</li>
                            <li style="margin-top: 1rem"><strong>• F1-Score :</strong> $$F1 = 2 \\times \\frac{\\text{Précision} \\times \\text{Rappel}}{\\text{Précision} + \\text{Rappel}}$$</li>
                        </ul>
                        
                        <p><strong>🔑 Interprétation :</strong></p>
                        <ul>
                            <li><strong>MSE</strong> : pénalise fortement les grosses erreurs</li>
                            <li><strong>MAE</strong> : traite toutes les erreurs équitablement</li>
                            <li><strong>R²</strong> : pourcentage de variance expliquée (0 = mauvais, 1 = parfait)</li>
                        </ul>
                    `,
          },
          {
            type: "concept",
            icon: "💡",
            title: "Surapprentissage et sous-apprentissage",
            content: `
                        <p><strong>🎯 Deux problèmes opposés mais également dangereux :</strong></p>
                        
                        <p><strong>📈 Surapprentissage (Overfitting) :</strong></p>
                        <p>Le modèle mémorise les données d'entraînement au lieu d'apprendre les vrais patterns.</p>
                        <p><strong>Analogie :</strong> Un étudiant qui apprend par cœur les réponses aux exercices du livre, mais ne comprend pas les concepts. Il échoue sur de nouveaux problèmes.</p>
                        <p><strong>Symptômes :</strong></p>
                        <ul>
                            <li>✅ Excellente performance sur les données d'entraînement</li>
                            <li>❌ Mauvaise performance sur de nouvelles données</li>
                            <li>📊 Grand écart entre erreur d'entraînement et erreur de test</li>
                        </ul>
                        
                        <p><strong>📉 Sous-apprentissage (Underfitting) :</strong></p>
                        <p>Le modèle est trop simple pour capturer les vrais patterns dans les données.</p>
                        <p><strong>Analogie :</strong> Essayer d'expliquer l'économie sénégalaise avec une seule variable. C'est trop simpliste.</p>
                        <p><strong>Symptômes :</strong></p>
                        <ul>
                            <li>❌ Mauvaise performance sur les données d'entraînement</li>
                            <li>❌ Mauvaise performance sur de nouvelles données</li>
                            <li>📊 Erreurs élevées partout</li>
                        </ul>
                        
                        <p><strong>⚖️ L'équilibre parfait :</strong></p>
                        <p>Un bon modèle capture les vrais patterns sans mémoriser le bruit. C'est l'art du Machine Learning !</p>
                    `,
          },
          {
            type: "mathematique",
            icon: "∑",
            title: "Courbes d'apprentissage et diagnostic",
            content: `
                        <p><strong>📈 Les courbes d'apprentissage révèlent la santé de votre modèle :</strong></p>
                        
                        <p><strong>🔍 Diagnostic par les courbes :</strong></p>
                        
                        <p><strong>1️⃣ Modèle équilibré (idéal) :</strong></p>
                        <ul>
                            <li>Erreur d'entraînement et de validation convergent vers une valeur faible</li>
                            <li>Écart raisonnable entre les deux courbes</li>
                        </ul>
                        
                        <p><strong>2️⃣ Surapprentissage :</strong></p>
                        <ul>
                            <li>Erreur d'entraînement continue de diminuer</li>
                            <li>Erreur de validation augmente ou stagne</li>
                            <li>Grand écart entre les deux courbes</li>
                        </ul>
                        
                        <p><strong>3️⃣ Sous-apprentissage :</strong></p>
                        <ul>
                            <li>Les deux erreurs restent élevées</li>
                            <li>Courbes plates, pas d'amélioration</li>
                            <li>Écart faible mais performances médiocres</li>
                        </ul>
                        
                        <p><strong>🔧 Solutions :</strong></p>
                        <ul>
                            <li><strong>Surapprentissage</strong> → Régularisation, plus de données, modèle plus simple</li>
                            <li><strong>Sous-apprentissage</strong> → Modèle plus complexe, plus de features, moins de régularisation</li>
                        </ul>
                    `,
          },
          {
            type: "concept",
            icon: "💡",
            title: "Validation croisée : tester la robustesse",
            content: `
                        <p><strong>🔄 La validation croisée</strong> teste si votre modèle fonctionne bien sur différents échantillons de données.</p>
                        
                        <p><strong>🎯 Principe de base :</strong></p>
                        <p>Au lieu de diviser une seule fois en train/test, on fait plusieurs divisions différentes et on moyenne les résultats.</p>
                        
                        <p><strong>📊 Validation croisée k-fold :</strong></p>
                        <ol>
                            <li>Diviser les données en k parties égales</li>
                            <li>Utiliser k-1 parties pour l'entraînement, 1 partie pour le test</li>
                            <li>Répéter k fois en changeant la partie de test</li>
                            <li>Moyenner les k résultats obtenus</li>
                        </ol>
                        
                        <p><strong>💡 Avantages :</strong></p>
                        <ul>
                            <li>🎯 <strong>Robustesse</strong> : résultat moins dépendant d'une division particulière</li>
                            <li>📊 <strong>Utilisation optimale</strong> : toutes les données servent à la fois pour train et test</li>
                            <li>📈 <strong>Estimation fiable</strong> : variance de la performance</li>
                        </ul>
                        
                        <p><strong>⚠️ Inconvénients :</strong></p>
                        <ul>
                            <li>⏰ <strong>Temps de calcul</strong> : k fois plus long</li>
                            <li>💾 <strong>Mémoire</strong> : stockage de k modèles</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "💻",
            title: "Exemple simple : prédiction de prix",
            description:
              "Implémentons un modèle simple pour comprendre les concepts :",
            code: `import numpy as np

# Données simulées : prix du mil au Sénégal
# Variables : mois (1-12), stock (tonnes), prix (FCFA/kg)
np.random.seed(42)

mois = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
stock = np.array([5000, 4500, 4000, 3500, 3000, 2500, 2000, 2200, 2800, 3500, 4200, 4800])
prix_reel = np.array([450, 460, 480, 520, 580, 650, 720, 680, 600, 520, 480, 460])

print("📊 DONNÉES : PRIX DU MIL AU SÉNÉGAL")
print("Mois | Stock (t) | Prix (FCFA/kg)")
print("-" * 35)
for i in range(12):
    print(f"{mois[i]:4d} | {stock[i]:8d} | {prix_reel[i]:6d}")

# Modèle linéaire simple : prix = a * stock + b
def entrainer_modele_lineaire(x, y):
    """Régression linéaire simple par moindres carrés"""
    n = len(x)
    x_mean = np.mean(x)
    y_mean = np.mean(y)
    
    # Calcul des coefficients
    numerateur = np.sum((x - x_mean) * (y - y_mean))
    denominateur = np.sum((x - x_mean) ** 2)
    a = numerateur / denominateur  # Pente
    b = y_mean - a * x_mean        # Ordonnée à l'origine
    
    return a, b

# Entraînement
a, b = entrainer_modele_lineaire(stock, prix_reel)
print(f"\\n🤖 MODÈLE ENTRAÎNÉ")
print(f"Équation: prix = {a:.4f} * stock + {b:.1f}")
print(f"Interprétation: {abs(a):.4f} FCFA de baisse par tonne de stock supplémentaire")

# Prédictions
prix_predit = a * stock + b

# Évaluation
mse = np.mean((prix_reel - prix_predit) ** 2)
mae = np.mean(np.abs(prix_reel - prix_predit))
r2 = 1 - np.sum((prix_reel - prix_predit) ** 2) / np.sum((prix_reel - np.mean(prix_reel)) ** 2)

print(f"\\n📊 ÉVALUATION")
print(f"MSE: {mse:.1f}")
print(f"MAE: {mae:.1f} FCFA/kg")
print(f"R²: {r2:.3f} ({r2*100:.1f}% de variance expliquée)")`,
          },
          {
            type: "warning",
            icon: "⚠️",
            title: "Points clés à retenir",
            content: `
                        <p><strong>🧠 Concepts fondamentaux du Machine Learning :</strong></p>
                        
                        <p><strong>🎯 1. Apprentissage = Généralisation :</strong></p>
                        <p>L'objectif n'est pas de mémoriser les données d'entraînement, mais de découvrir des patterns qui fonctionnent sur de nouvelles données.</p>
                        
                        <p><strong>⚖️ 2. Compromis biais-variance :</strong></p>
                        <p>Il faut trouver le bon équilibre entre un modèle trop simple (biais élevé) et trop complexe (variance élevée).</p>
                        
                        <p><strong>📊 3. Validation rigoureuse :</strong></p>
                        <p>Toujours séparer entraînement/validation/test. Ne jamais optimiser sur les données de test !</p>
                        
                        <p><strong>🔍 4. Comprendre avant d'optimiser :</strong></p>
                        <p>Analyser les données, visualiser les distributions, comprendre le problème métier avant de choisir l'algorithme.</p>
                        
                        <p><strong>💡 5. Simplicité d'abord :</strong></p>
                        <p>Commencer par des modèles simples (régression linéaire) avant d'essayer des modèles complexes (deep learning).</p>
                        
                        <p><strong>🔮 Prochaine étape :</strong></p>
                        <p>Maintenant que vous maîtrisez les concepts, nous allons plonger dans la <strong>régression linéaire</strong> - le premier algorithme ML à maîtriser absolument !</p>
                    `,
          },
        ],
        quiz: {
          question:
            "🤔 Un modèle a une erreur d'entraînement de 2% et une erreur de test de 15%. Quel est le problème ?",
          options: [
            "A) Sous-apprentissage - le modèle est trop simple",
            "B) Surapprentissage - le modèle mémorise les données d'entraînement",
            "C) Le modèle est parfait",
            "D) Il faut plus de données d'entraînement",
          ],
          correct: 1,
          explanation:
            "Grand écart entre erreur d'entraînement (2%) et erreur de test (15%) = surapprentissage classique. Le modèle a mémorisé les données d'entraînement au lieu d'apprendre les vrais patterns généralisables.",
        },
        prevModule: "../python/algorithms.html",
        nextModule: "linear-regression.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
