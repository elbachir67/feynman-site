<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction au Machine Learning | IA4Ndada</title>

    <!-- MathJax pour les formules math√©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>ü§ñ Machine Learning</span>
          <span>‚Ä∫</span>
          <span>Introduction</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div class="progress-fill" id="progress-fill" style="width: 0%"></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>ü§ñ Introduction au Machine Learning</h1>
      <p class="subtitle">Module 3.1 - Qu'est-ce que l'apprentissage automatique ?</p>

      <!-- Statut Pyodide -->
      <div id="pyodide-status" class="pyodide-status">
        <span class="status-loading">‚è≥ Chargement de Python...</span>
      </div>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list"></ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content"></div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>üéâ Checkpoint - Introduction ML</h3>
        <p>Vous ma√Ætrisez maintenant les fondements du Machine Learning !</p>
        <button class="checkpoint-btn" id="checkpoint-btn" onclick="completeCheckpoint()" disabled>
          Valider le module
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="../math/maximum-likelihood.html" class="nav-link" id="prev-link">‚Üê Maximum de vraisemblance</a>
        <a href="linear-regression.html" class="nav-link" id="next-link">R√©gression Lin√©aire ‚Üí</a>
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      const moduleConfig = {
        id: "ml-introduction",
        title: "Introduction au Machine Learning",
        objectives: [
          "Comprendre ce qu'est vraiment le Machine Learning",
          "Distinguer les 3 types d'apprentissage",
          "Ma√Ætriser le compromis biais-variance",
          "Reconna√Ætre surapprentissage et sous-apprentissage",
        ],
        content: [
          // Section 1: C'est quoi le ML ?
          {
            type: "concept",
            icon: "üí°",
            title: "Qu'est-ce que le Machine Learning ?",
            content: `
              <p>Le <strong>Machine Learning</strong> (ML) est l'art de faire apprendre des patterns aux ordinateurs <strong>√† partir de donn√©es</strong>, plut√¥t que de programmer explicitement chaque r√®gle.</p>

              <p><strong>üîë La r√©volution :</strong></p>
              <table style="width:100%; border-collapse: collapse; margin: 1rem 0;">
                <tr style="background: #f0f0f0;">
                  <th style="padding: 0.5rem; border: 1px solid #ddd;">Approche</th>
                  <th style="padding: 0.5rem; border: 1px solid #ddd;">M√©thode</th>
                </tr>
                <tr>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;"><strong>Programmation classique</strong></td>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;">R√®gles + Donn√©es ‚Üí R√©sultat</td>
                </tr>
                <tr>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;"><strong>Machine Learning</strong></td>
                  <td style="padding: 0.5rem; border: 1px solid #ddd;">Donn√©es + R√©sultats ‚Üí R√®gles (mod√®le)</td>
                </tr>
              </table>

              <p><strong>Exemple concret :</strong></p>
              <ul>
                <li>üñ•Ô∏è <strong>Classique</strong> : "Si email contient 'gratuit' ET majuscules > 50%, alors spam"</li>
                <li>ü§ñ <strong>ML</strong> : "Voici 10 000 emails √©tiquet√©s spam/pas spam. Trouve les patterns toi-m√™me !"</li>
              </ul>
            `,
          },
          {
            type: "quiz",
            title: "V√©rification - D√©finition du ML",
            question: "Quelle est la diff√©rence fondamentale entre programmation classique et Machine Learning ?",
            options: [
              "Le ML est plus rapide que la programmation classique",
              "En ML, on d√©duit les r√®gles √† partir des donn√©es, pas l'inverse",
              "Le ML ne n√©cessite pas de donn√©es",
              "La programmation classique est obsol√®te",
            ],
            correctAnswer: 1,
            explanation: "En programmation classique, on √©crit les r√®gles explicitement. En ML, on fournit des donn√©es et des r√©sultats attendus, et l'algorithme d√©couvre les r√®gles (patterns) automatiquement.",
          },
          // Section 2: Les 3 types d'apprentissage
          {
            type: "concept",
            icon: "üìö",
            title: "Les trois types d'apprentissage",
            content: `
              <p><strong>1Ô∏è‚É£ Apprentissage Supervis√©</strong> (avec professeur)</p>
              <p>On fournit des exemples avec les r√©ponses correctes (labels).</p>
              <ul>
                <li>üìß Classification d'emails : spam ou pas spam</li>
                <li>üè† Pr√©diction de prix immobilier</li>
                <li>üè• Diagnostic m√©dical √† partir de sympt√¥mes</li>
              </ul>

              <p><strong>2Ô∏è‚É£ Apprentissage Non-Supervis√©</strong> (explorateur)</p>
              <p>Pas de labels. L'algorithme d√©couvre des structures cach√©es.</p>
              <ul>
                <li>üë• Segmentation de clients (groupes similaires)</li>
                <li>üõí Recommandations de produits</li>
                <li>üìâ D√©tection d'anomalies</li>
              </ul>

              <p><strong>3Ô∏è‚É£ Apprentissage par Renforcement</strong> (joueur)</p>
              <p>L'agent apprend par essai-erreur avec des r√©compenses/punitions.</p>
              <ul>
                <li>üéÆ IA pour jeux vid√©o (AlphaGo)</li>
                <li>üöó Voitures autonomes</li>
                <li>ü§ñ Robots qui apprennent √† marcher</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            title: "Classification des probl√®mes ML",
            exerciseType: "mcq",
            content: `
              <p>Une banque veut d√©tecter automatiquement les transactions frauduleuses. Elle dispose d'un historique de transactions √©tiquet√©es "fraude" ou "l√©gitime".</p>
              <p><strong>Quel type d'apprentissage utiliser ?</strong></p>
            `,
            options: [
              "Apprentissage non-supervis√© (clustering)",
              "Apprentissage par renforcement",
              "Apprentissage supervis√© (classification)",
              "Aucun ML n√©cessaire, r√®gles simples suffisent",
            ],
            correctAnswer: 2,
            explanation: "C'est de l'apprentissage supervis√© car on a des exemples √©tiquet√©s (fraude/l√©gitime). Plus pr√©cis√©ment, c'est une classification binaire. Le mod√®le apprendra les patterns des fraudes pass√©es pour d√©tecter les nouvelles.",
          },
          // Section 3: Biais et Variance
          {
            type: "concept",
            icon: "üéØ",
            title: "Le compromis biais-variance",
            content: `
              <p>En ML, l'erreur de pr√©diction vient de deux sources principales :</p>

              <p><strong>üéØ Le Biais</strong></p>
              <p>Erreur due √† des hypoth√®ses trop simplistes du mod√®le.</p>
              <p><em>Analogie :</em> Un archer qui vise toujours 10cm √† droite. Consistent mais syst√©matiquement faux.</p>

              <p><strong>üìä La Variance</strong></p>
              <p>Erreur due √† une sensibilit√© excessive aux donn√©es d'entra√Ænement.</p>
              <p><em>Analogie :</em> Un archer dont les fl√®ches sont dispers√©es partout. Impr√©visible.</p>

              <p><strong>‚öñÔ∏è Le dilemme :</strong></p>
              <ul>
                <li>Mod√®le simple ‚Üí Biais √©lev√©, variance faible</li>
                <li>Mod√®le complexe ‚Üí Biais faible, variance √©lev√©e</li>
                <li>üéØ Objectif : trouver le sweet spot !</li>
              </ul>
            `,
          },
          {
            type: "mathematique",
            icon: "‚àë",
            title: "Formalisation math√©matique",
            content: `
              <p>L'erreur totale de pr√©diction se d√©compose :</p>

              <p style="text-align: center; font-size: 1.2em; margin: 1rem 0;">
                $$\\text{Erreur} = \\text{Biais}^2 + \\text{Variance} + \\text{Bruit irr√©ductible}$$
              </p>

              <p>Pour un mod√®le \\(\\hat{f}\\) pr√©disant la vraie fonction \\(f\\) :</p>

              <ul>
                <li><strong>Biais¬≤</strong> : \\((E[\\hat{f}(x)] - f(x))^2\\) ‚Äî √©cart moyen de nos pr√©dictions</li>
                <li><strong>Variance</strong> : \\(E[(\\hat{f}(x) - E[\\hat{f}(x)])^2]\\) ‚Äî dispersion des pr√©dictions</li>
                <li><strong>Bruit</strong> : erreur inh√©rente aux donn√©es, impossible √† r√©duire</li>
              </ul>

              <p><strong>üîë Implication :</strong> On ne peut pas minimiser les deux simultan√©ment. Il faut trouver un √©quilibre.</p>
            `,
          },
          {
            type: "quiz",
            title: "Quiz - Biais vs Variance",
            question: "Un mod√®le de r√©gression lin√©aire simple (une droite) pour pr√©dire des donn√©es qui suivent une courbe complexe aura :",
            options: [
              "Biais faible, variance faible",
              "Biais √©lev√©, variance faible",
              "Biais faible, variance √©lev√©e",
              "Biais √©lev√©, variance √©lev√©e",
            ],
            correctAnswer: 1,
            explanation: "Une droite est trop simple pour capturer une courbe complexe ‚Üí biais √©lev√© (syst√©matiquement √† c√¥t√©). Mais comme c'est un mod√®le simple avec peu de param√®tres, il est stable ‚Üí variance faible.",
          },
          // Section 4: Overfitting vs Underfitting
          {
            type: "concept",
            icon: "‚ö†Ô∏è",
            title: "Surapprentissage vs Sous-apprentissage",
            content: `
              <p><strong>üìà Surapprentissage (Overfitting)</strong></p>
              <p>Le mod√®le m√©morise les donn√©es au lieu d'apprendre les patterns.</p>
              <ul>
                <li>‚úÖ Excellent sur donn√©es d'entra√Ænement</li>
                <li>‚ùå Mauvais sur nouvelles donn√©es</li>
                <li>üîç Sympt√¥me : grand √©cart train/test</li>
              </ul>
              <p><em>Analogie :</em> √âtudiant qui apprend par c≈ìur les exercices du livre mais √©choue √† l'examen sur des probl√®mes diff√©rents.</p>

              <p><strong>üìâ Sous-apprentissage (Underfitting)</strong></p>
              <p>Le mod√®le est trop simple pour capturer les patterns.</p>
              <ul>
                <li>‚ùå Mauvais sur donn√©es d'entra√Ænement</li>
                <li>‚ùå Mauvais sur nouvelles donn√©es</li>
                <li>üîç Sympt√¥me : erreurs √©lev√©es partout</li>
              </ul>
              <p><em>Analogie :</em> Essayer d'expliquer l'√©conomie mondiale avec une seule variable.</p>
            `,
          },
          {
            type: "code",
            title: "Visualisation : Overfitting vs Underfitting",
            description: "Observons les trois cas sur un jeu de donn√©es simple :",
            code: `import numpy as np
import matplotlib.pyplot as plt

# Donn√©es : fonction sinuso√Ødale avec bruit
np.random.seed(42)
X = np.linspace(0, 10, 20)
y_true = np.sin(X)
y = y_true + np.random.normal(0, 0.3, len(X))

# Cr√©er des mod√®les de complexit√© variable
X_plot = np.linspace(0, 10, 100)

fig, axes = plt.subplots(1, 3, figsize=(12, 4))

# 1. Underfitting (degr√© 1 - droite)
coeffs1 = np.polyfit(X, y, 1)
y_pred1 = np.polyval(coeffs1, X_plot)
axes[0].scatter(X, y, c='blue', label='Donn√©es')
axes[0].plot(X_plot, y_pred1, 'r-', linewidth=2, label='Mod√®le')
axes[0].plot(X_plot, np.sin(X_plot), 'g--', alpha=0.5, label='Vraie fonction')
axes[0].set_title('UNDERFITTING\\n(Mod√®le trop simple)', fontsize=11)
axes[0].legend(fontsize=8)

# 2. Bon √©quilibre (degr√© 4)
coeffs4 = np.polyfit(X, y, 4)
y_pred4 = np.polyval(coeffs4, X_plot)
axes[1].scatter(X, y, c='blue', label='Donn√©es')
axes[1].plot(X_plot, y_pred4, 'r-', linewidth=2, label='Mod√®le')
axes[1].plot(X_plot, np.sin(X_plot), 'g--', alpha=0.5, label='Vraie fonction')
axes[1].set_title('BON √âQUILIBRE\\n(Complexit√© adapt√©e)', fontsize=11)
axes[1].legend(fontsize=8)

# 3. Overfitting (degr√© 15)
coeffs15 = np.polyfit(X, y, 15)
y_pred15 = np.polyval(coeffs15, X_plot)
axes[2].scatter(X, y, c='blue', label='Donn√©es')
axes[2].plot(X_plot, y_pred15, 'r-', linewidth=2, label='Mod√®le')
axes[2].plot(X_plot, np.sin(X_plot), 'g--', alpha=0.5, label='Vraie fonction')
axes[2].set_title('OVERFITTING\\n(Mod√®le trop complexe)', fontsize=11)
axes[2].set_ylim(-2, 2)
axes[2].legend(fontsize=8)

plt.tight_layout()
plt.show()

print("üìä ANALYSE:")
print("‚Ä¢ UNDERFITTING: La droite ne capture pas la forme sinuso√Ødale")
print("‚Ä¢ BON √âQUILIBRE: Le mod√®le suit la tendance sans le bruit")
print("‚Ä¢ OVERFITTING: Le mod√®le passe par tous les points, y compris le bruit!")`,
          },
          {
            type: "exercise",
            title: "Diagnostic d'un mod√®le",
            exerciseType: "mcq",
            content: `
              <p>Vous entra√Ænez un mod√®le et observez :</p>
              <ul>
                <li>Erreur sur donn√©es d'entra√Ænement : <strong>2%</strong></li>
                <li>Erreur sur donn√©es de test : <strong>25%</strong></li>
              </ul>
              <p><strong>Quel est le probl√®me et que faire ?</strong></p>
            `,
            options: [
              "Sous-apprentissage ‚Üí utiliser un mod√®le plus complexe",
              "Surapprentissage ‚Üí r√©gulariser ou simplifier le mod√®le",
              "Le mod√®le est parfait, continuer ainsi",
              "Probl√®me de donn√©es ‚Üí collecter plus de donn√©es de test",
            ],
            correctAnswer: 1,
            explanation: "Grand √©cart (2% vs 25%) = surapprentissage classique. Le mod√®le m√©morise l'entra√Ænement. Solutions : r√©gularisation (L1/L2), r√©duire la complexit√©, augmenter les donn√©es d'entra√Ænement, ou utiliser le dropout.",
          },
          // Section 5: M√©triques
          {
            type: "mathematique",
            icon: "üìä",
            title: "M√©triques d'√©valuation",
            content: `
              <p><strong>Pour la r√©gression</strong> (pr√©dire des nombres) :</p>

              <p><strong>MSE</strong> (Mean Squared Error) :</p>
              <p style="text-align: center;">$$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$</p>
              <p>P√©nalise fortement les grandes erreurs (√† cause du carr√©).</p>

              <p><strong>MAE</strong> (Mean Absolute Error) :</p>
              <p style="text-align: center;">$$MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$</p>
              <p>Toutes les erreurs ont le m√™me poids.</p>

              <p><strong>R¬≤</strong> (Coefficient de d√©termination) :</p>
              <p style="text-align: center;">$$R^2 = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}$$</p>
              <p>Proportion de variance expliqu√©e. R¬≤ = 1 parfait, R¬≤ = 0 aussi bon que la moyenne.</p>
            `,
          },
          {
            type: "exercise",
            title: "Calcul de MSE",
            exerciseType: "numeric",
            content: `
              <p>Un mod√®le pr√©dit les valeurs suivantes :</p>
              <table style="border-collapse: collapse; margin: 1rem 0;">
                <tr style="background: #f0f0f0;">
                  <th style="padding: 0.5rem; border: 1px solid #ddd;">R√©el (y)</th>
                  <th style="padding: 0.5rem; border: 1px solid #ddd;">Pr√©dit (≈∑)</th>
                </tr>
                <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">10</td><td style="padding: 0.5rem; border: 1px solid #ddd;">12</td></tr>
                <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">20</td><td style="padding: 0.5rem; border: 1px solid #ddd;">18</td></tr>
                <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">30</td><td style="padding: 0.5rem; border: 1px solid #ddd;">31</td></tr>
                <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">40</td><td style="padding: 0.5rem; border: 1px solid #ddd;">37</td></tr>
              </table>
              <p><strong>Calculez le MSE</strong> (Mean Squared Error)</p>
            `,
            correctAnswer: 7.5,
            tolerance: 0.1,
            hint: "MSE = moyenne des (y - ≈∑)¬≤. Erreurs : (10-12)¬≤=4, (20-18)¬≤=4, (30-31)¬≤=1, (40-37)¬≤=9",
            explanation: "MSE = (4 + 4 + 1 + 9) / 4 = 18 / 4 = 7.5",
          },
          // Section 6: Validation crois√©e
          {
            type: "concept",
            icon: "üîÑ",
            title: "Validation crois√©e (Cross-Validation)",
            content: `
              <p>Comment savoir si notre mod√®le g√©n√©ralisera bien sur de nouvelles donn√©es ?</p>

              <p><strong>‚ùå Probl√®me du split simple :</strong></p>
              <p>Si on divise 80% train / 20% test une seule fois, le r√©sultat d√©pend du hasard de la division.</p>

              <p><strong>‚úÖ Solution : K-Fold Cross-Validation</strong></p>
              <ol>
                <li>Diviser les donn√©es en K parties √©gales (ex: K=5)</li>
                <li>Pour chaque partie i :</li>
                <ul>
                  <li>Utiliser partie i comme test</li>
                  <li>Utiliser les K-1 autres parties comme entra√Ænement</li>
                  <li>Mesurer la performance</li>
                </ul>
                <li>Moyenner les K scores obtenus</li>
              </ol>

              <p><strong>üí° Avantages :</strong></p>
              <ul>
                <li>Chaque donn√©e sert une fois pour le test</li>
                <li>Estimation plus robuste de la performance</li>
                <li>On obtient aussi l'√©cart-type (stabilit√© du mod√®le)</li>
              </ul>
            `,
          },
          {
            type: "exercise-code",
            title: "Impl√©mentez une validation crois√©e simple",
            content: `
              <p>Compl√©tez le code pour impl√©menter une validation crois√©e 5-fold :</p>
              <ul>
                <li>Divisez les donn√©es en 5 parties</li>
                <li>Pour chaque fold, calculez le MSE</li>
                <li>Retournez la moyenne des MSE</li>
              </ul>
            `,
            starterCode: `import numpy as np

# Donn√©es
np.random.seed(42)
X = np.random.rand(100) * 10
y = 2 * X + 1 + np.random.randn(100) * 2  # y = 2x + 1 + bruit

def cross_validation_mse(X, y, k=5):
    """Validation crois√©e k-fold pour r√©gression lin√©aire simple"""
    n = len(X)
    fold_size = n // k
    mse_scores = []

    for i in range(k):
        # Indices pour ce fold
        test_start = i * fold_size
        test_end = test_start + fold_size

        # TODO: S√©parer train et test
        X_test = X[test_start:test_end]
        y_test = y[test_start:test_end]
        X_train = np.concatenate([X[:test_start], X[test_end:]])
        y_train = np.concatenate([y[:test_start], y[test_end:]])

        # TODO: Entra√Æner r√©gression lin√©aire (y = ax + b)
        # Formule: a = cov(X,y)/var(X), b = mean(y) - a*mean(X)
        a = np.cov(X_train, y_train)[0,1] / np.var(X_train)
        b = np.mean(y_train) - a * np.mean(X_train)

        # TODO: Pr√©dire et calculer MSE
        y_pred = a * X_test + b
        mse = np.mean((y_test - y_pred) ** 2)
        mse_scores.append(mse)

    return np.mean(mse_scores), np.std(mse_scores)

# Ex√©cuter
mean_mse, std_mse = cross_validation_mse(X, y, k=5)
print(f"MSE moyen: {mean_mse:.2f} (+/- {std_mse:.2f})")
print(f"\\nInterpr√©tation:")
print(f"‚Ä¢ Le mod√®le a une erreur moyenne de ~{mean_mse:.1f}")
print(f"‚Ä¢ L'√©cart-type de {std_mse:.1f} indique la stabilit√©")`,
            solution: `import numpy as np

# Donn√©es
np.random.seed(42)
X = np.random.rand(100) * 10
y = 2 * X + 1 + np.random.randn(100) * 2

def cross_validation_mse(X, y, k=5):
    n = len(X)
    fold_size = n // k
    mse_scores = []

    for i in range(k):
        test_start = i * fold_size
        test_end = test_start + fold_size

        X_test = X[test_start:test_end]
        y_test = y[test_start:test_end]
        X_train = np.concatenate([X[:test_start], X[test_end:]])
        y_train = np.concatenate([y[:test_start], y[test_end:]])

        a = np.cov(X_train, y_train)[0,1] / np.var(X_train)
        b = np.mean(y_train) - a * np.mean(X_train)

        y_pred = a * X_test + b
        mse = np.mean((y_test - y_pred) ** 2)
        mse_scores.append(mse)

    return np.mean(mse_scores), np.std(mse_scores)

mean_mse, std_mse = cross_validation_mse(X, y, k=5)
print(f"MSE moyen: {mean_mse:.2f} (+/- {std_mse:.2f})")`,
            expectedOutput: "MSE moyen:",
          },
          // Section 7: Pipeline ML
          {
            type: "concept",
            icon: "üîß",
            title: "Pipeline d'un projet ML",
            content: `
              <p>Un projet ML suit g√©n√©ralement ces √©tapes :</p>

              <p><strong>1Ô∏è‚É£ Comprendre le probl√®me</strong></p>
              <ul>
                <li>Quel est l'objectif m√©tier ?</li>
                <li>Quelles m√©triques importent ?</li>
                <li>R√©gression ou classification ?</li>
              </ul>

              <p><strong>2Ô∏è‚É£ Collecter et explorer les donn√©es</strong></p>
              <ul>
                <li>Analyse exploratoire (EDA)</li>
                <li>Visualisations</li>
                <li>Statistiques descriptives</li>
              </ul>

              <p><strong>3Ô∏è‚É£ Pr√©parer les donn√©es</strong></p>
              <ul>
                <li>Nettoyage (valeurs manquantes, outliers)</li>
                <li>Feature engineering</li>
                <li>Normalisation/standardisation</li>
              </ul>

              <p><strong>4Ô∏è‚É£ Mod√©lisation</strong></p>
              <ul>
                <li>Commencer simple (baseline)</li>
                <li>Essayer plusieurs algorithmes</li>
                <li>Optimiser les hyperparam√®tres</li>
              </ul>

              <p><strong>5Ô∏è‚É£ √âvaluation et d√©ploiement</strong></p>
              <ul>
                <li>Validation crois√©e</li>
                <li>Test final</li>
                <li>Mise en production</li>
              </ul>
            `,
          },
          {
            type: "quiz",
            title: "Quiz final - Concepts ML",
            question: "Vous d√©veloppez un mod√®le pour pr√©dire si un client va r√©silier son abonnement. Apr√®s entra√Ænement, votre mod√®le a 95% de pr√©cision sur le train mais 60% sur le test. Que devez-vous faire ?",
            options: [
              "C√©l√©brer ! 95% c'est excellent",
              "Ajouter plus de features pour am√©liorer le test",
              "R√©gulariser le mod√®le ou r√©duire sa complexit√©",
              "Collecter plus de donn√©es de test",
            ],
            correctAnswer: 2,
            explanation: "95% train vs 60% test = surapprentissage √©vident. Le mod√®le m√©morise. Solutions : r√©gularisation (L1, L2, dropout), mod√®le plus simple, early stopping, ou data augmentation.",
          },
        ],
        prevModule: "../math/maximum-likelihood.html",
        nextModule: "linear-regression.html",
      };

      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
