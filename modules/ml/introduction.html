<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction au Machine Learning | IA4Ndada</title>

    <!-- MathJax pour les formules mathÃ©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">ğŸ  Accueil</a>
          <span>â€º</span>
          <span>ğŸ¤– Machine Learning</span>
          <span>â€º</span>
          <span>Introduction</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>ğŸ¤– Introduction au Machine Learning</h1>
      <p class="subtitle">Module 3.1 - Apprentissage Automatique</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>ğŸ¯ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajoutÃ©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajoutÃ© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>ğŸ‰ Checkpoint - Introduction ML</h3>
        <p>
          FÃ©licitations ! Vous comprenez maintenant les fondements conceptuels
          du Machine Learning.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme complÃ©tÃ©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="../python/algorithms.html" class="nav-link" id="prev-link"
          >â† Module prÃ©cÃ©dent : Algorithmes</a
        >
        <a href="linear-regression.html" class="nav-link" id="next-link"
          >Module suivant : RÃ©gression LinÃ©aire â†’</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Introduction ML
      const moduleConfig = {
        id: "ml-introduction",
        title: "Introduction au Machine Learning",
        category: "Machine Learning",
        objectives: [
          "Comprendre ce qu'est vraiment le Machine Learning",
          "Distinguer les 3 types d'apprentissage automatique",
          "MaÃ®triser les concepts de biais et variance",
          "Comprendre les diffÃ©rents types d'erreurs en ML",
        ],
        content: [
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Qu'est-ce que le Machine Learning ?",
            content: `
                        <p>Le <strong>Machine Learning</strong> est l'art d'enseigner aux ordinateurs Ã  <strong>apprendre des patterns</strong> dans les donnÃ©es, plutÃ´t que de programmer explicitement chaque rÃ¨gle.</p>
                        
                        <p><strong>ğŸ”‘ RÃ©volution conceptuelle :</strong></p>
                        <ul>
                            <li>ğŸ–¥ï¸ <strong>Programmation classique</strong> : "Si tempÃ©rature > 30Â°C, alors porter des vÃªtements lÃ©gers"</li>
                            <li>ğŸ¤– <strong>Machine Learning</strong> : "Voici 10 000 exemples de tempÃ©ratures et vÃªtements portÃ©s. Trouve le pattern !"</li>
                        </ul>
                        
                        <p><strong>ğŸ§  Analogie de l'apprentissage humain :</strong></p>
                        <p>Un enfant apprend Ã  reconnaÃ®tre un chien en voyant des centaines de chiens diffÃ©rents. Il dÃ©veloppe intuitivement le concept de "chien" sans qu'on lui explique les rÃ¨gles prÃ©cises.</p>
                        
                        <p><strong>ğŸ¯ Trois paradigmes d'apprentissage :</strong></p>
                        <ul>
                            <li>ğŸ“š <strong>SupervisÃ©</strong> : apprendre avec un professeur (exemples Ã©tiquetÃ©s)</li>
                            <li>ğŸ” <strong>Non-supervisÃ©</strong> : dÃ©couvrir des patterns cachÃ©s (pas d'Ã©tiquettes)</li>
                            <li>ğŸ® <strong>Par renforcement</strong> : apprendre par essai-erreur avec rÃ©compenses</li>
                        </ul>
                    `,
          },
          {
            type: "intuition",
            icon: "ğŸ§ ",
            title: "Les trois types d'apprentissage expliquÃ©s simplement",
            content: `
                        <p><strong>ğŸ“ Apprentissage SupervisÃ© :</strong></p>
                        <p>Comme un Ã©tudiant avec un professeur qui corrige ses copies. On montre Ã  l'algorithme des exemples avec les bonnes rÃ©ponses.</p>
                        <p><strong>Exemple :</strong> "Voici 1000 emails. Ceux-ci sont des spams, ceux-lÃ  ne le sont pas. Maintenant, classe ce nouvel email !"</p>
                        
                        <p><strong>ğŸ” Apprentissage Non-SupervisÃ© :</strong></p>
                        <p>Comme un explorateur qui dÃ©couvre des territoires inconnus. L'algorithme trouve des groupes ou patterns sans qu'on lui dise quoi chercher.</p>
                        <p><strong>Exemple :</strong> "Voici les habitudes d'achat de 10 000 clients. Trouve des groupes de clients similaires !"</p>
                        
                        <p><strong>ğŸ® Apprentissage par Renforcement :</strong></p>
                        <p>Comme apprendre Ã  jouer aux Ã©checs : on essaie des coups, on gagne ou perd, et on s'amÃ©liore progressivement.</p>
                        <p><strong>Exemple :</strong> "Apprends Ã  conduire une voiture autonome en essayant, en recevant des rÃ©compenses pour les bons comportements et des pÃ©nalitÃ©s pour les mauvais."</p>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Le biais et la variance : concepts fondamentaux",
            content: `
                        <p><strong>ğŸ¯ Biais et variance</strong> sont deux sources d'erreur fondamentales en ML. Comprendre cette distinction est crucial pour crÃ©er de bons modÃ¨les.</p>
                        
                        <p><strong>ğŸ¯ Le Biais :</strong></p>
                        <p>Le <strong>biais</strong> mesure Ã  quel point nos prÃ©dictions sont systÃ©matiquement Ã©loignÃ©es de la vÃ©ritÃ©, mÃªme avec beaucoup de donnÃ©es.</p>
                        <p><strong>Analogie :</strong> Un archer qui vise toujours 10cm Ã  droite de la cible. Ses tirs sont cohÃ©rents mais systÃ©matiquement dÃ©calÃ©s.</p>
                        
                        <p><strong>ğŸ“Š La Variance :</strong></p>
                        <p>La <strong>variance</strong> mesure Ã  quel point nos prÃ©dictions changent quand on change lÃ©gÃ¨rement les donnÃ©es d'entraÃ®nement.</p>
                        <p><strong>Analogie :</strong> Un archer dont les flÃ¨ches sont dispersÃ©es partout autour de la cible. Parfois proche, parfois loin, trÃ¨s imprÃ©visible.</p>
                        
                        <p><strong>âš–ï¸ Le compromis biais-variance :</strong></p>
                        <ul>
                            <li>ğŸ¯ <strong>Biais Ã©levÃ©, variance faible</strong> : modÃ¨le trop simple (sous-apprentissage)</li>
                            <li>ğŸ¯ <strong>Biais faible, variance Ã©levÃ©e</strong> : modÃ¨le trop complexe (surapprentissage)</li>
                            <li>ğŸ¯ <strong>Objectif</strong> : Ã©quilibre optimal entre les deux</li>
                        </ul>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Formalisation mathÃ©matique du biais-variance",
            content: `
                        <p><strong>ğŸ“ DÃ©composition mathÃ©matique de l'erreur :</strong></p>
                        <p>Pour un modÃ¨le \\(\\hat{f}(x)\\) qui prÃ©dit une valeur \\(y\\), l'erreur totale se dÃ©compose en :</p>
                        
                        <p>$$\\text{Erreur} = \\text{Biais}^2 + \\text{Variance} + \\text{Bruit}$$</p>
                        
                        <p><strong>ğŸ” DÃ©tail de chaque composante :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ BiaisÂ² :</strong> $$\\text{Biais}^2 = (E[\\hat{f}(x)] - f(x))^2$$</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Variance :</strong> $$\\text{Variance} = E[(\\hat{f}(x) - E[\\hat{f}(x)])^2]$$</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Bruit :</strong> $$\\text{Bruit} = E[(y - f(x))^2]$$</li>
                        </ul>
                        
                        <p><strong>ğŸ”‘ InterprÃ©tation :</strong></p>
                        <ul>
                            <li>\\(f(x)\\) = vraie fonction (inconnue)</li>
                            <li>\\(\\hat{f}(x)\\) = notre modÃ¨le</li>
                            <li>\\(E[\\cdot]\\) = espÃ©rance (moyenne sur tous les datasets possibles)</li>
                            <li>Le <strong>bruit</strong> est irrÃ©ductible (erreur inhÃ©rente aux donnÃ©es)</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Objectif d'optimisation :</strong></p>
                        <p>Minimiser \\(\\text{Biais}^2 + \\text{Variance}\\) car le bruit est incompressible.</p>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Types d'erreurs en Machine Learning",
            content: `
                        <p><strong>ğŸ¯ En ML, il existe plusieurs types d'erreurs qu'il faut comprendre :</strong></p>
                        
                        <p><strong>ğŸ“Š 1. Erreur d'entraÃ®nement (Training Error) :</strong></p>
                        <p>Performance du modÃ¨le sur les donnÃ©es qu'il a vues pendant l'apprentissage.</p>
                        <p><strong>Analogie :</strong> Notes d'un Ã©tudiant sur les exercices qu'il a dÃ©jÃ  rÃ©solus en classe.</p>
                        
                        <p><strong>ğŸ§ª 2. Erreur de validation (Validation Error) :</strong></p>
                        <p>Performance sur des donnÃ©es non vues, utilisÃ©es pour ajuster le modÃ¨le.</p>
                        <p><strong>Analogie :</strong> Notes sur des exercices similaires mais nouveaux pour vÃ©rifier la comprÃ©hension.</p>
                        
                        <p><strong>ğŸ¯ 3. Erreur de test (Test Error) :</strong></p>
                        <p>Performance finale sur des donnÃ©es complÃ¨tement nouvelles, jamais utilisÃ©es.</p>
                        <p><strong>Analogie :</strong> Note Ã  l'examen final sur des sujets totalement inÃ©dits.</p>
                        
                        <p><strong>âš ï¸ ProblÃ¨mes courants :</strong></p>
                        <ul>
                            <li>ğŸ”´ <strong>Surapprentissage</strong> : excellent en entraÃ®nement, mauvais en test</li>
                            <li>ğŸ”µ <strong>Sous-apprentissage</strong> : mauvais partout, modÃ¨le trop simple</li>
                            <li>ğŸŸ¡ <strong>Fuite de donnÃ©es</strong> : information du futur dans les donnÃ©es d'entraÃ®nement</li>
                        </ul>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "MÃ©triques d'Ã©valuation mathÃ©matiques",
            content: `
                        <p><strong>ğŸ“ Comment mesurer la performance d'un modÃ¨le ?</strong></p>
                        
                        <p><strong>ğŸ”¢ Pour la rÃ©gression (prÃ©dire des nombres) :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ Erreur Quadratique Moyenne (MSE) :</strong> $$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$</li>
                            <li style="margin-top: 1rem"><strong>â€¢ Erreur Absolue Moyenne (MAE) :</strong> $$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$</li>
                            <li style="margin-top: 1rem"><strong>â€¢ Coefficient de dÃ©termination (RÂ²) :</strong> $$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Pour la classification (prÃ©dire des catÃ©gories) :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ PrÃ©cision :</strong> $$\\text{PrÃ©cision} = \\frac{\\text{Vrais Positifs}}{\\text{Vrais Positifs + Faux Positifs}}$$</li>
                            <li style="margin-top: 1rem"><strong>â€¢ Rappel :</strong> $$\\text{Rappel} = \\frac{\\text{Vrais Positifs}}{\\text{Vrais Positifs + Faux NÃ©gatifs}}$$</li>
                            <li style="margin-top: 1rem"><strong>â€¢ F1-Score :</strong> $$F1 = 2 \\times \\frac{\\text{PrÃ©cision} \\times \\text{Rappel}}{\\text{PrÃ©cision} + \\text{Rappel}}$$</li>
                        </ul>
                        
                        <p><strong>ğŸ”‘ InterprÃ©tation :</strong></p>
                        <ul>
                            <li><strong>MSE</strong> : pÃ©nalise fortement les grosses erreurs</li>
                            <li><strong>MAE</strong> : traite toutes les erreurs Ã©quitablement</li>
                            <li><strong>RÂ²</strong> : pourcentage de variance expliquÃ©e (0 = mauvais, 1 = parfait)</li>
                        </ul>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Surapprentissage et sous-apprentissage",
            content: `
                        <p><strong>ğŸ¯ Deux problÃ¨mes opposÃ©s mais Ã©galement dangereux :</strong></p>
                        
                        <p><strong>ğŸ“ˆ Surapprentissage (Overfitting) :</strong></p>
                        <p>Le modÃ¨le mÃ©morise les donnÃ©es d'entraÃ®nement au lieu d'apprendre les vrais patterns.</p>
                        <p><strong>Analogie :</strong> Un Ã©tudiant qui apprend par cÅ“ur les rÃ©ponses aux exercices du livre, mais ne comprend pas les concepts. Il Ã©choue sur de nouveaux problÃ¨mes.</p>
                        <p><strong>SymptÃ´mes :</strong></p>
                        <ul>
                            <li>âœ… Excellente performance sur les donnÃ©es d'entraÃ®nement</li>
                            <li>âŒ Mauvaise performance sur de nouvelles donnÃ©es</li>
                            <li>ğŸ“Š Grand Ã©cart entre erreur d'entraÃ®nement et erreur de test</li>
                        </ul>
                        
                        <p><strong>ğŸ“‰ Sous-apprentissage (Underfitting) :</strong></p>
                        <p>Le modÃ¨le est trop simple pour capturer les vrais patterns dans les donnÃ©es.</p>
                        <p><strong>Analogie :</strong> Essayer d'expliquer l'Ã©conomie sÃ©nÃ©galaise avec une seule variable. C'est trop simpliste.</p>
                        <p><strong>SymptÃ´mes :</strong></p>
                        <ul>
                            <li>âŒ Mauvaise performance sur les donnÃ©es d'entraÃ®nement</li>
                            <li>âŒ Mauvaise performance sur de nouvelles donnÃ©es</li>
                            <li>ğŸ“Š Erreurs Ã©levÃ©es partout</li>
                        </ul>
                        
                        <p><strong>âš–ï¸ L'Ã©quilibre parfait :</strong></p>
                        <p>Un bon modÃ¨le capture les vrais patterns sans mÃ©moriser le bruit. C'est l'art du Machine Learning !</p>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Courbes d'apprentissage et diagnostic",
            content: `
                        <p><strong>ğŸ“ˆ Les courbes d'apprentissage rÃ©vÃ¨lent la santÃ© de votre modÃ¨le :</strong></p>
                        
                        <p><strong>ğŸ” Diagnostic par les courbes :</strong></p>
                        
                        <p><strong>1ï¸âƒ£ ModÃ¨le Ã©quilibrÃ© (idÃ©al) :</strong></p>
                        <ul>
                            <li>Erreur d'entraÃ®nement et de validation convergent vers une valeur faible</li>
                            <li>Ã‰cart raisonnable entre les deux courbes</li>
                        </ul>
                        
                        <p><strong>2ï¸âƒ£ Surapprentissage :</strong></p>
                        <ul>
                            <li>Erreur d'entraÃ®nement continue de diminuer</li>
                            <li>Erreur de validation augmente ou stagne</li>
                            <li>Grand Ã©cart entre les deux courbes</li>
                        </ul>
                        
                        <p><strong>3ï¸âƒ£ Sous-apprentissage :</strong></p>
                        <ul>
                            <li>Les deux erreurs restent Ã©levÃ©es</li>
                            <li>Courbes plates, pas d'amÃ©lioration</li>
                            <li>Ã‰cart faible mais performances mÃ©diocres</li>
                        </ul>
                        
                        <p><strong>ğŸ”§ Solutions :</strong></p>
                        <ul>
                            <li><strong>Surapprentissage</strong> â†’ RÃ©gularisation, plus de donnÃ©es, modÃ¨le plus simple</li>
                            <li><strong>Sous-apprentissage</strong> â†’ ModÃ¨le plus complexe, plus de features, moins de rÃ©gularisation</li>
                        </ul>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Validation croisÃ©e : tester la robustesse",
            content: `
                        <p><strong>ğŸ”„ La validation croisÃ©e</strong> teste si votre modÃ¨le fonctionne bien sur diffÃ©rents Ã©chantillons de donnÃ©es.</p>
                        
                        <p><strong>ğŸ¯ Principe de base :</strong></p>
                        <p>Au lieu de diviser une seule fois en train/test, on fait plusieurs divisions diffÃ©rentes et on moyenne les rÃ©sultats.</p>
                        
                        <p><strong>ğŸ“Š Validation croisÃ©e k-fold :</strong></p>
                        <ol>
                            <li>Diviser les donnÃ©es en k parties Ã©gales</li>
                            <li>Utiliser k-1 parties pour l'entraÃ®nement, 1 partie pour le test</li>
                            <li>RÃ©pÃ©ter k fois en changeant la partie de test</li>
                            <li>Moyenner les k rÃ©sultats obtenus</li>
                        </ol>
                        
                        <p><strong>ğŸ’¡ Avantages :</strong></p>
                        <ul>
                            <li>ğŸ¯ <strong>Robustesse</strong> : rÃ©sultat moins dÃ©pendant d'une division particuliÃ¨re</li>
                            <li>ğŸ“Š <strong>Utilisation optimale</strong> : toutes les donnÃ©es servent Ã  la fois pour train et test</li>
                            <li>ğŸ“ˆ <strong>Estimation fiable</strong> : variance de la performance</li>
                        </ul>
                        
                        <p><strong>âš ï¸ InconvÃ©nients :</strong></p>
                        <ul>
                            <li>â° <strong>Temps de calcul</strong> : k fois plus long</li>
                            <li>ğŸ’¾ <strong>MÃ©moire</strong> : stockage de k modÃ¨les</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exemple simple : prÃ©diction de prix",
            description:
              "ImplÃ©mentons un modÃ¨le simple pour comprendre les concepts :",
            code: `import numpy as np

# DonnÃ©es simulÃ©es : prix du mil au SÃ©nÃ©gal
# Variables : mois (1-12), stock (tonnes), prix (FCFA/kg)
np.random.seed(42)

mois = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
stock = np.array([5000, 4500, 4000, 3500, 3000, 2500, 2000, 2200, 2800, 3500, 4200, 4800])
prix_reel = np.array([450, 460, 480, 520, 580, 650, 720, 680, 600, 520, 480, 460])

print("ğŸ“Š DONNÃ‰ES : PRIX DU MIL AU SÃ‰NÃ‰GAL")
print("Mois | Stock (t) | Prix (FCFA/kg)")
print("-" * 35)
for i in range(12):
    print(f"{mois[i]:4d} | {stock[i]:8d} | {prix_reel[i]:6d}")

# ModÃ¨le linÃ©aire simple : prix = a * stock + b
def entrainer_modele_lineaire(x, y):
    """RÃ©gression linÃ©aire simple par moindres carrÃ©s"""
    n = len(x)
    x_mean = np.mean(x)
    y_mean = np.mean(y)
    
    # Calcul des coefficients
    numerateur = np.sum((x - x_mean) * (y - y_mean))
    denominateur = np.sum((x - x_mean) ** 2)
    a = numerateur / denominateur  # Pente
    b = y_mean - a * x_mean        # OrdonnÃ©e Ã  l'origine
    
    return a, b

# EntraÃ®nement
a, b = entrainer_modele_lineaire(stock, prix_reel)
print(f"\\nğŸ¤– MODÃˆLE ENTRAÃNÃ‰")
print(f"Ã‰quation: prix = {a:.4f} * stock + {b:.1f}")
print(f"InterprÃ©tation: {abs(a):.4f} FCFA de baisse par tonne de stock supplÃ©mentaire")

# PrÃ©dictions
prix_predit = a * stock + b

# Ã‰valuation
mse = np.mean((prix_reel - prix_predit) ** 2)
mae = np.mean(np.abs(prix_reel - prix_predit))
r2 = 1 - np.sum((prix_reel - prix_predit) ** 2) / np.sum((prix_reel - np.mean(prix_reel)) ** 2)

print(f"\\nğŸ“Š Ã‰VALUATION")
print(f"MSE: {mse:.1f}")
print(f"MAE: {mae:.1f} FCFA/kg")
print(f"RÂ²: {r2:.3f} ({r2*100:.1f}% de variance expliquÃ©e)")`,
          },
          {
            type: "warning",
            icon: "âš ï¸",
            title: "Points clÃ©s Ã  retenir",
            content: `
                        <p><strong>ğŸ§  Concepts fondamentaux du Machine Learning :</strong></p>
                        
                        <p><strong>ğŸ¯ 1. Apprentissage = GÃ©nÃ©ralisation :</strong></p>
                        <p>L'objectif n'est pas de mÃ©moriser les donnÃ©es d'entraÃ®nement, mais de dÃ©couvrir des patterns qui fonctionnent sur de nouvelles donnÃ©es.</p>
                        
                        <p><strong>âš–ï¸ 2. Compromis biais-variance :</strong></p>
                        <p>Il faut trouver le bon Ã©quilibre entre un modÃ¨le trop simple (biais Ã©levÃ©) et trop complexe (variance Ã©levÃ©e).</p>
                        
                        <p><strong>ğŸ“Š 3. Validation rigoureuse :</strong></p>
                        <p>Toujours sÃ©parer entraÃ®nement/validation/test. Ne jamais optimiser sur les donnÃ©es de test !</p>
                        
                        <p><strong>ğŸ” 4. Comprendre avant d'optimiser :</strong></p>
                        <p>Analyser les donnÃ©es, visualiser les distributions, comprendre le problÃ¨me mÃ©tier avant de choisir l'algorithme.</p>
                        
                        <p><strong>ğŸ’¡ 5. SimplicitÃ© d'abord :</strong></p>
                        <p>Commencer par des modÃ¨les simples (rÃ©gression linÃ©aire) avant d'essayer des modÃ¨les complexes (deep learning).</p>
                        
                        <p><strong>ğŸ”® Prochaine Ã©tape :</strong></p>
                        <p>Maintenant que vous maÃ®trisez les concepts, nous allons plonger dans la <strong>rÃ©gression linÃ©aire</strong> - le premier algorithme ML Ã  maÃ®triser absolument !</p>
                    `,
          },
        ],
        quiz: {
          question:
            "ğŸ¤” Un modÃ¨le a une erreur d'entraÃ®nement de 2% et une erreur de test de 15%. Quel est le problÃ¨me ?",
          options: [
            "A) Sous-apprentissage - le modÃ¨le est trop simple",
            "B) Surapprentissage - le modÃ¨le mÃ©morise les donnÃ©es d'entraÃ®nement",
            "C) Le modÃ¨le est parfait",
            "D) Il faut plus de donnÃ©es d'entraÃ®nement",
          ],
          correct: 1,
          explanation:
            "Grand Ã©cart entre erreur d'entraÃ®nement (2%) et erreur de test (15%) = surapprentissage classique. Le modÃ¨le a mÃ©morisÃ© les donnÃ©es d'entraÃ®nement au lieu d'apprendre les vrais patterns gÃ©nÃ©ralisables.",
        },
        prevModule: "../python/algorithms.html",
        nextModule: "linear-regression.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
