<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Validation en Machine Learning | IA4Ndada</title>

    <!-- MathJax pour les formules mathÃ©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">ğŸ  Accueil</a>
          <span>â€º</span>
          <span>ğŸ¤– Machine Learning</span>
          <span>â€º</span>
          <span>Validation</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>âœ… Validation en Machine Learning</h1>
      <p class="subtitle">Module 3.5 - L'art d'Ã©valuer un modÃ¨le</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>ğŸ¯ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajoutÃ©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajoutÃ© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>ğŸ‰ Checkpoint - Validation</h3>
        <p>
          FÃ©licitations ! Vous savez maintenant Ã©valuer rigoureusement vos
          modÃ¨les ML et Ã©viter les piÃ¨ges de l'overfitting.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme complÃ©tÃ©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="clustering.html" class="nav-link" id="prev-link"
          >â† Module prÃ©cÃ©dent : Clustering</a
        >
        <a href="../dl/perceptron.html" class="nav-link" id="next-link"
          >Module suivant : Perceptron â†’</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Validation
      const moduleConfig = {
        id: "ml-validation",
        title: "Validation en Machine Learning",
        category: "Machine Learning",
        objectives: [
          "Comprendre pourquoi la validation est critique en ML",
          "MaÃ®triser le split train/validation/test rigoureusement",
          "Calculer manuellement la validation croisÃ©e k-fold",
          "DÃ©tecter et diagnostiquer overfitting vs underfitting",
          "Appliquer les bonnes pratiques de validation en production",
        ],
        content: [
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Le piÃ¨ge fondamental du Machine Learning",
            content: `
                        <p>Le Machine Learning cache un <strong>piÃ¨ge mortel</strong> : un modÃ¨le peut avoir <strong>100% de prÃ©cision</strong> sur vos donnÃ©es d'entraÃ®nement... et Ãªtre <strong>complÃ¨tement inutile</strong> en production !</p>
                        
                        <p><strong>ğŸ”‘ Le paradoxe central :</strong></p>
                        <p>Plus un modÃ¨le est complexe, plus il peut <strong>mÃ©moriser</strong> les donnÃ©es au lieu de <strong>comprendre</strong> les vrais patterns. C'est la diffÃ©rence entre un perroquet qui rÃ©pÃ¨te et un humain qui comprend.</p>
                        
                        <p><strong>ğŸ¯ L'objectif ultime du ML :</strong></p>
                        <p>CrÃ©er un modÃ¨le qui <strong>gÃ©nÃ©ralise</strong> bien sur des donnÃ©es qu'il n'a <strong>jamais vues</strong>. C'est exactement comme un Ã©tudiant qui doit rÃ©ussir un examen sur des exercices inÃ©dits.</p>
                        
                        <p><strong>ğŸ’¡ La validation est l'outil scientifique qui nous permet de :</strong></p>
                        <ul>
                            <li>âœ… <strong>Mesurer la vraie performance</strong> (pas l'illusion)</li>
                            <li>ğŸ” <strong>DÃ©tecter les problÃ¨mes cachÃ©s</strong> (overfitting, data leakage)</li>
                            <li>âš–ï¸ <strong>Ã‰quilibrer complexitÃ© et gÃ©nÃ©ralisation</strong></li>
                            <li>ğŸ¯ <strong>Choisir le meilleur modÃ¨le</strong> objectivement</li>
                            <li>ğŸ“Š <strong>Quantifier l'incertitude</strong> des prÃ©dictions</li>
                        </ul>
                        
                        <p><strong>ğŸ¤– Applications critiques :</strong></p>
                        <ul>
                            <li>ğŸ¥ <strong>Diagnostic mÃ©dical</strong> : Ã©viter les faux diagnostics</li>
                            <li>ğŸš— <strong>Voitures autonomes</strong> : sÃ©curitÃ© des passagers</li>
                            <li>ğŸ’° <strong>Finance</strong> : prÃ©dictions de risque fiables</li>
                            <li>ğŸ¯ <strong>Recommandations</strong> : Ã©viter les suggestions inappropriÃ©es</li>
                        </ul>
                    `,
          },
          {
            type: "intuition",
            icon: "ğŸ§ ",
            title: "L'analogie de l'examen scolaire",
            content: `
                        <p>Imaginez <strong>trois types d'Ã©tudiants</strong> face Ã  un examen de mathÃ©matiques :</p>
                        
                        <p><strong>ğŸ“š L'Ã©tudiant "Overfitting" (surapprentissage) :</strong></p>
                        <ul>
                            <li>ğŸ”– <strong>StratÃ©gie</strong> : mÃ©morise par cÅ“ur toutes les solutions du livre d'exercices</li>
                            <li>ğŸ’¯ <strong>Performance train</strong> : rÃ©sout parfaitement tous les exercices dÃ©jÃ  vus</li>
                            <li>âŒ <strong>Performance test</strong> : Ã©choue lamentablement face Ã  un exercice lÃ©gÃ¨rement diffÃ©rent</li>
                            <li>ğŸ§  <strong>ProblÃ¨me</strong> : mÃ©morisation sans comprÃ©hension des concepts</li>
                        </ul>
                        
                        <p><strong>ğŸ˜´ L'Ã©tudiant "Underfitting" (sous-apprentissage) :</strong></p>
                        <ul>
                            <li>ğŸ“– <strong>StratÃ©gie</strong> : n'a pas assez Ã©tudiÃ© ou utilisÃ© une mÃ©thode trop simpliste</li>
                            <li>âŒ <strong>Performance train</strong> : Ã©choue mÃªme sur les exercices simples du cours</li>
                            <li>âŒ <strong>Performance test</strong> : Ã©choue aussi sur l'examen</li>
                            <li>ğŸ§  <strong>ProblÃ¨me</strong> : modÃ¨le mental trop simple pour capturer la complexitÃ©</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ L'Ã©tudiant "Optimal" :</strong></p>
                        <ul>
                            <li>ğŸ§  <strong>StratÃ©gie</strong> : comprend les concepts fondamentaux et s'entraÃ®ne sur des exercices variÃ©s</li>
                            <li>âœ… <strong>Performance train</strong> : rÃ©sout correctement les exercices connus</li>
                            <li>âœ… <strong>Performance test</strong> : s'adapte aux nouveaux exercices en appliquant les concepts</li>
                            <li>ğŸ¯ <strong>SuccÃ¨s</strong> : gÃ©nÃ©ralisation des connaissances</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ C'est exactement ce qu'on cherche en ML :</strong></p>
                        <p>Un modÃ¨le qui <strong>comprend les patterns</strong> au lieu de <strong>mÃ©moriser les exemples</strong> !</p>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Train/Validation/Test : la trinitÃ© sacrÃ©e",
            content: `
                        <p>La division des donnÃ©es en <strong>trois ensembles distincts et disjoints</strong> est le fondement de toute validation rigoureuse :</p>
                        
                        <p><strong>ğŸ“ Formalisation mathÃ©matique :</strong></p>
                        <p>$$\\mathcal{D} = \\mathcal{D}_{train} \\cup \\mathcal{D}_{val} \\cup \\mathcal{D}_{test}$$</p>
                        <p>avec $$\\mathcal{D}_{train} \\cap \\mathcal{D}_{val} \\cap \\mathcal{D}_{test} = \\emptyset$$</p>
                        
                        <p><strong>ğŸ¯ Proportions classiques :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ Train (60-70%) :</strong> $$|\\mathcal{D}_{train}| \\approx 0.6 \\times |\\mathcal{D}|$$</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Validation (15-20%) :</strong> $$|\\mathcal{D}_{val}| \\approx 0.2 \\times |\\mathcal{D}|$$</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Test (15-20%) :</strong> $$|\\mathcal{D}_{test}| \\approx 0.2 \\times |\\mathcal{D}|$$</li>
                        </ul>
                        
                        <p><strong>ğŸ”‘ RÃ´les distincts et sacrÃ©s :</strong></p>
                        <ul>
                            <li>ğŸ“š <strong>Train</strong> : apprentissage des paramÃ¨tres \\(\\theta\\) du modÃ¨le</li>
                            <li>ğŸ” <strong>Validation</strong> : choix des hyperparamÃ¨tres et architecture</li>
                            <li>ğŸ¯ <strong>Test</strong> : Ã©valuation finale <strong>non biaisÃ©e</strong> (une seule fois !)</li>
                        </ul>
                        
                        <p><strong>âš ï¸ Le principe fondamental inviolable :</strong></p>
                        <div style="background: #ffebee; padding: 1rem; border-left: 4px solid #f44336; margin: 1rem 0;">
                            <strong>Le test set est SACRÃ‰ !</strong><br>
                            On ne le touche qu'<strong>UNE SEULE FOIS</strong> Ã  la toute fin, aprÃ¨s avoir finalisÃ© complÃ¨tement le modÃ¨le.
                        </div>
                        
                        <p><strong>ğŸ“Š Diagnostic mathÃ©matique :</strong></p>
                        <p>Si \\(\\mathcal{L}_{train}\\), \\(\\mathcal{L}_{val}\\), \\(\\mathcal{L}_{test}\\) sont les erreurs sur chaque ensemble :</p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ Overfitting :</strong> $$\\mathcal{L}_{train} \\ll \\mathcal{L}_{val} \\approx \\mathcal{L}_{test}$$</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Underfitting :</strong> $$\\mathcal{L}_{train} \\approx \\mathcal{L}_{val} \\approx \\mathcal{L}_{test}$$ (toutes Ã©levÃ©es)</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Optimal :</strong> $$\\mathcal{L}_{train} \\approx \\mathcal{L}_{val} \\approx \\mathcal{L}_{test}$$ (toutes faibles)</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice pratique : split manuel",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Vous avez un dataset de 1000 exemples de prÃ©diction de salaires au SÃ©nÃ©gal. Effectuez un split rigoureux.</p>
                        
                        <p><strong>ğŸ“ DonnÃ©es :</strong></p>
                        <ul>
                            <li>1000 profils : [Ã¢ge, Ã©ducation, expÃ©rience, rÃ©gion] â†’ salaire</li>
                            <li>RÃ©partition gÃ©ographique : 40% Dakar, 30% autres rÃ©gions, 30% rural</li>
                            <li>RÃ©partition sectorielle : 50% privÃ©, 30% public, 20% informel</li>
                        </ul>
                        
                        <p><strong>ğŸ“‹ Questions :</strong></p>
                        <ol>
                            <li>Combien d'exemples dans chaque ensemble (60/20/20) ?</li>
                            <li>Faut-il faire un split alÃ©atoire simple ?</li>
                            <li>Comment prÃ©server les proportions gÃ©ographiques ?</li>
                            <li>Quel ordre pour le split ?</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('split-exercise-solution')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="split-exercise-solution" style="display: none;">
                        <ol>
                            <li><strong>RÃ©partition :</strong>
                                <br>â€¢ Train : 600 exemples (60%)
                                <br>â€¢ Validation : 200 exemples (20%)
                                <br>â€¢ Test : 200 exemples (20%)</li>
                            <li><strong>Split stratifiÃ© obligatoire :</strong>
                                <br>âŒ Split alÃ©atoire simple risque de dÃ©sÃ©quilibrer les rÃ©gions/secteurs
                                <br>âœ… Split stratifiÃ© prÃ©serve les proportions dans chaque ensemble</li>
                            <li><strong>Proportions Ã  prÃ©server :</strong>
                                <br>â€¢ Chaque ensemble doit avoir ~40% Dakar, 30% autres, 30% rural
                                <br>â€¢ Et ~50% privÃ©, 30% public, 20% informel</li>
                            <li><strong>Ordre crucial :</strong>
                                <br>1. D'abord sÃ©parer le test set (et ne plus y toucher !)
                                <br>2. Puis diviser le reste en train/validation
                                <br>3. Toute exploration/preprocessing sur train+val uniquement</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title:
              "Validation croisÃ©e : utiliser 100% des donnÃ©es intelligemment",
            content: `
                        <p>La <strong>validation croisÃ©e k-fold</strong> est une technique mathÃ©matiquement Ã©lÃ©gante qui utilise <strong>toutes les donnÃ©es</strong> pour l'entraÃ®nement ET la validation, sans jamais "tricher".</p>
                        
                        <p><strong>ğŸ”„ Le principe gÃ©nial :</strong></p>
                        <p>Au lieu de "gaspiller" 20% des donnÃ©es pour la validation, on fait k expÃ©riences oÃ¹ chaque partie sert une fois de validation et k-1 fois d'entraÃ®nement.</p>
                        
                        <p><strong>ğŸ“ Algorithme mathÃ©matique :</strong></p>
                        <ol>
                            <li><strong>Partition :</strong> $$\\mathcal{D} = \\bigcup_{i=1}^{k} F_i$$ avec $$F_i \\cap F_j = \\emptyset$$ et $$|F_i| \\approx \\frac{|\\mathcal{D}|}{k}$$</li>
                            <li><strong>Pour chaque fold i :</strong>
                                <ul>
                                    <li>$$\\mathcal{D}_{val}^{(i)} = F_i$$</li>
                                    <li>$$\\mathcal{D}_{train}^{(i)} = \\bigcup_{j \\neq i} F_j$$</li>
                                    <li>EntraÃ®ner $$h_i$$ sur $$\\mathcal{D}_{train}^{(i)}$$</li>
                                    <li>Calculer $$e_i = \\text{Erreur}(h_i, \\mathcal{D}_{val}^{(i)})$$</li>
                                </ul>
                            </li>
                            <li><strong>Score final :</strong> $$\\text{CV}_k = \\frac{1}{k} \\sum_{i=1}^{k} e_i$$</li>
                        </ol>
                        
                        <p><strong>ğŸ“Š Estimation de la variance :</strong></p>
                        <p>$$\\text{Var}(\\text{CV}_k) = \\frac{1}{k(k-1)} \\sum_{i=1}^{k} (e_i - \\text{CV}_k)^2$$</p>
                        
                        <p><strong>ğŸ’¡ Avantages mathÃ©matiques :</strong></p>
                        <ul>
                            <li>âœ… <strong>Utilisation optimale</strong> : 100% des donnÃ©es exploitÃ©es</li>
                            <li>ğŸ“Š <strong>Estimation robuste</strong> : moyenne de k expÃ©riences indÃ©pendantes</li>
                            <li>ğŸ“ˆ <strong>Mesure de variance</strong> : quantifie la stabilitÃ© du modÃ¨le</li>
                            <li>ğŸ¯ <strong>RÃ©duction du biais</strong> : moins dÃ©pendant d'une division particuliÃ¨re</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Calcul manuel de validation croisÃ©e 5-fold",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Effectuons une validation croisÃ©e 5-fold manuelle sur un petit dataset de prÃ©diction de revenus.</p>
                        
                        <p><strong>ğŸ“Š Dataset :</strong> 10 personnes avec [AnnÃ©es d'Ã©tudes, Salaire en milliers FCFA]</p>
                        <table style="margin: 1rem auto; border-collapse: collapse; text-align: center;">
                            <tr style="background: #3498db; color: white;">
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">ID</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Ã‰tudes</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Salaire</th>
                            </tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">1</td><td style="padding: 0.5rem; border: 1px solid #ddd;">12</td><td style="padding: 0.5rem; border: 1px solid #ddd;">300</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">2</td><td style="padding: 0.5rem; border: 1px solid #ddd;">16</td><td style="padding: 0.5rem; border: 1px solid #ddd;">450</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">3</td><td style="padding: 0.5rem; border: 1px solid #ddd;">14</td><td style="padding: 0.5rem; border: 1px solid #ddd;">380</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">4</td><td style="padding: 0.5rem; border: 1px solid #ddd;">18</td><td style="padding: 0.5rem; border: 1px solid #ddd;">520</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">5</td><td style="padding: 0.5rem; border: 1px solid #ddd;">10</td><td style="padding: 0.5rem; border: 1px solid #ddd;">250</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">6</td><td style="padding: 0.5rem; border: 1px solid #ddd;">15</td><td style="padding: 0.5rem; border: 1px solid #ddd;">400</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">7</td><td style="padding: 0.5rem; border: 1px solid #ddd;">13</td><td style="padding: 0.5rem; border: 1px solid #ddd;">350</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">8</td><td style="padding: 0.5rem; border: 1px solid #ddd;">17</td><td style="padding: 0.5rem; border: 1px solid #ddd;">480</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">9</td><td style="padding: 0.5rem; border: 1px solid #ddd;">11</td><td style="padding: 0.5rem; border: 1px solid #ddd;">280</td></tr>
                            <tr><td style="padding: 0.5rem; border: 1px solid #ddd;">10</td><td style="padding: 0.5rem; border: 1px solid #ddd;">19</td><td style="padding: 0.5rem; border: 1px solid #ddd;">550</td></tr>
                        </table>
                        
                        <p><strong>ğŸ“ Effectuez la validation croisÃ©e 5-fold :</strong></p>
                        <ol>
                            <li>Divisez en 5 folds de 2 exemples chacun</li>
                            <li>Pour chaque fold, calculez la rÃ©gression linÃ©aire sur les 8 autres</li>
                            <li>Testez sur les 2 exemples du fold</li>
                            <li>Calculez l'erreur MSE pour chaque fold</li>
                            <li>Moyennez les 5 erreurs</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('cv-manual-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="cv-manual-exercise" style="display: none;">
                        <p><strong>Division en folds :</strong></p>
                        <ul>
                            <li>Fold 1 : {1, 2} â†’ Test sur (12,300) et (16,450)</li>
                            <li>Fold 2 : {3, 4} â†’ Test sur (14,380) et (18,520)</li>
                            <li>Fold 3 : {5, 6} â†’ Test sur (10,250) et (15,400)</li>
                            <li>Fold 4 : {7, 8} â†’ Test sur (13,350) et (17,480)</li>
                            <li>Fold 5 : {9, 10} â†’ Test sur (11,280) et (19,550)</li>
                        </ul>
                        
                        <p><strong>Calculs (rÃ©gression y = ax + b) :</strong></p>
                        <p>Pour chaque fold, on trouve a â‰ˆ 25-30 et b â‰ˆ -50 Ã  0</p>
                        <p>Erreurs typiques : MSE entre 500 et 2000 par fold</p>
                        <p><strong>Score CV final :</strong> ~1200 (moyenne des 5 MSE)</p>
                        </div>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Le dilemme biais-variance : dÃ©composition mathÃ©matique",
            content: `
                        <p>L'erreur totale d'un modÃ¨le se <strong>dÃ©compose mathÃ©matiquement</strong> en trois composantes indÃ©pendantes :</p>
                        
                        <p><strong>ğŸ“ La dÃ©composition fondamentale :</strong></p>
                        <p>$$\\mathbb{E}[(y - \\hat{f}(x))^2] = \\text{Biais}^2[\\hat{f}(x)] + \\text{Var}[\\hat{f}(x)] + \\sigma^2$$</p>
                        
                        <p><strong>ğŸ” DÃ©tail de chaque composante :</strong></p>
                        
                        <p><strong>1ï¸âƒ£ BiaisÂ² (erreur systÃ©matique) :</strong></p>
                        <p>$$\\text{Biais}^2[\\hat{f}(x)] = (\\mathbb{E}[\\hat{f}(x)] - f(x))^2$$</p>
                        <ul>
                            <li>Erreur due aux <strong>hypothÃ¨ses simplificatrices</strong> du modÃ¨le</li>
                            <li>Exemple : utiliser une droite pour des donnÃ©es paraboliques</li>
                            <li>Cause l'<strong>underfitting</strong> (modÃ¨le trop simple)</li>
                        </ul>
                        
                        <p><strong>2ï¸âƒ£ Variance (sensibilitÃ© aux donnÃ©es) :</strong></p>
                        <p>$$\\text{Var}[\\hat{f}(x)] = \\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^2]$$</p>
                        <ul>
                            <li>SensibilitÃ© du modÃ¨le aux <strong>fluctuations</strong> dans les donnÃ©es d'entraÃ®nement</li>
                            <li>Exemple : modÃ¨le qui change drastiquement avec quelques points diffÃ©rents</li>
                            <li>Cause l'<strong>overfitting</strong> (modÃ¨le trop complexe)</li>
                        </ul>
                        
                        <p><strong>3ï¸âƒ£ Bruit irrÃ©ductible :</strong></p>
                        <p>$$\\sigma^2 = \\mathbb{E}[(y - f(x))^2]$$</p>
                        <ul>
                            <li>Erreur intrinsÃ¨que aux donnÃ©es (mesures imprÃ©cises, alÃ©atoire)</li>
                            <li>Incompressible par dÃ©finition</li>
                        </ul>
                        
                        <p><strong>âš–ï¸ Le trade-off fondamental :</strong></p>
                        <p>$$\\text{Biais} \\downarrow \\Rightarrow \\text{Variance} \\uparrow \\quad \\text{et vice-versa}$$</p>
                        <p>L'art du ML est de trouver l'Ã©quilibre optimal qui minimise $$\\text{Biais}^2 + \\text{Variance}$$</p>
                    `,
          },
          {
            type: "intuition",
            icon: "ğŸ§ ",
            title:
              "DÃ©tecter overfitting et underfitting : les signaux d'alarme",
            content: `
                        <p><strong>ğŸ” Comment diagnostiquer chaque problÃ¨me avec prÃ©cision ?</strong></p>
                        
                        <p><strong>ğŸ”´ OVERFITTING - Signaux d'alarme :</strong></p>
                        <ul>
                            <li>ğŸ“ˆ <strong>Erreur train trÃ¨s faible</strong> (< 5% pour classification, RÂ² > 0.95 pour rÃ©gression)</li>
                            <li>ğŸ“‰ <strong>Erreur validation beaucoup plus Ã©levÃ©e</strong> (> 20% ou RÂ² < 0.7)</li>
                            <li>ğŸ“Š <strong>Ã‰cart train/validation qui grandit</strong> avec la complexitÃ© du modÃ¨le</li>
                            <li>ğŸ¢ <strong>Courbes d'apprentissage divergentes</strong> : train descend, validation monte</li>
                            <li>âš ï¸ <strong>RÃ¨gle pratique :</strong> Si $$\\frac{\\text{Erreur}_{val}}{\\text{Erreur}_{train}} > 1.5$$ â†’ probable overfitting</li>
                        </ul>
                        
                        <p><strong>ğŸŸ¡ UNDERFITTING - Signaux d'alarme :</strong></p>
                        <ul>
                            <li>âŒ <strong>Erreurs train ET validation Ã©levÃ©es</strong> (> 15% ou RÂ² < 0.6)</li>
                            <li>ğŸ“Š <strong>Petit Ã©cart train/validation</strong> mais performances mÃ©diocres</li>
                            <li>ğŸ“‰ <strong>Courbes plates</strong> : pas d'amÃ©lioration mÃªme avec plus d'epochs</li>
                            <li>ğŸ”„ <strong>Stagnation rapide</strong> : convergence prÃ©maturÃ©e</li>
                        </ul>
                        
                        <p><strong>ğŸŸ¢ MODÃˆLE OPTIMAL - Signaux positifs :</strong></p>
                        <ul>
                            <li>âœ… <strong>Erreurs train et validation faibles</strong> (< 10% ou RÂ² > 0.8)</li>
                            <li>ğŸ“Š <strong>Petit Ã©cart train/validation</strong> (< 5% de diffÃ©rence)</li>
                            <li>ğŸ“ˆ <strong>Courbes convergentes</strong> : se rapprochent vers une valeur stable</li>
                            <li>ğŸ¯ <strong>Performance stable</strong> sur nouveaux Ã©chantillons</li>
                        </ul>
                        
                        <p><strong>ğŸ”§ Solutions par problÃ¨me :</strong></p>
                        <ul>
                            <li><strong>Overfitting</strong> â†’ RÃ©gularisation (L1/L2), dropout, early stopping, plus de donnÃ©es</li>
                            <li><strong>Underfitting</strong> â†’ ModÃ¨le plus complexe, plus de features, moins de rÃ©gularisation</li>
                        </ul>
                    `,
          },
          {
            type: "code",
            title: "ImplÃ©mentation validation croisÃ©e from scratch",
            description: "ImplÃ©mentons la validation croisÃ©e manuellement :",
            code: `import numpy as np
import matplotlib.pyplot as plt

class ValidationCroisee:
    """ImplÃ©mentation manuelle de la validation croisÃ©e"""
    
    def __init__(self, k=5):
        self.k = k
        self.scores = []
        self.models = []
    
    def split_kfold(self, X, y):
        """Divise les donnÃ©es en k folds"""
        n = len(X)
        indices = np.arange(n)
        np.random.shuffle(indices)  # MÃ©lange alÃ©atoire
        
        fold_size = n // self.k
        folds = []
        
        for i in range(self.k):
            start = i * fold_size
            end = start + fold_size if i < self.k - 1 else n
            test_indices = indices[start:end]
            train_indices = np.concatenate([indices[:start], indices[end:]])
            folds.append((train_indices, test_indices))
        
        return folds
    
    def regression_lineaire(self, X_train, y_train):
        """RÃ©gression linÃ©aire simple : y = ax + b"""
        # Ajout de la colonne de biais (intercept)
        X_with_bias = np.column_stack([np.ones(len(X_train)), X_train])
        
        # Solution analytique : Î¸ = (X^T X)^(-1) X^T y
        theta = np.linalg.inv(X_with_bias.T @ X_with_bias) @ X_with_bias.T @ y_train
        return theta
    
    def predict(self, X_test, theta):
        """PrÃ©diction avec le modÃ¨le linÃ©aire"""
        X_with_bias = np.column_stack([np.ones(len(X_test)), X_test])
        return X_with_bias @ theta
    
    def mse(self, y_true, y_pred):
        """Erreur quadratique moyenne"""
        return np.mean((y_true - y_pred) ** 2)
    
    def cross_validate(self, X, y):
        """Effectue la validation croisÃ©e complÃ¨te"""
        folds = self.split_kfold(X, y)
        
        print(f"ğŸ”„ VALIDATION CROISÃ‰E {self.k}-FOLD")
        print("=" * 50)
        
        for i, (train_idx, test_idx) in enumerate(folds):
            # Division train/test pour ce fold
            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]
            
            # EntraÃ®nement
            theta = self.regression_lineaire(X_train, y_train)
            self.models.append(theta)
            
            # PrÃ©diction et Ã©valuation
            y_pred = self.predict(X_test, theta)
            score = self.mse(y_test, y_pred)
            self.scores.append(score)
            
            print(f"Fold {i+1}:")
            print(f"  Train: {len(X_train)} exemples, Test: {len(X_test)} exemples")
            print(f"  ModÃ¨le: y = {theta[1]:.2f}x + {theta[0]:.1f}")
            print(f"  MSE: {score:.1f}")
            print()
        
        # Statistiques finales
        mean_score = np.mean(self.scores)
        std_score = np.std(self.scores)
        
        print(f"ğŸ“Š RÃ‰SULTATS FINAUX:")
        print(f"MSE moyen: {mean_score:.1f} Â± {std_score:.1f}")
        print(f"Scores individuels: {[round(s, 1) for s in self.scores]}")
        
        return mean_score, std_score

# Test avec donnÃ©es sÃ©nÃ©galaises : annÃ©es d'Ã©tudes vs salaire
np.random.seed(42)
etudes = np.array([12, 16, 14, 18, 10, 15, 13, 17, 11, 19])
salaires = np.array([300, 450, 380, 520, 250, 400, 350, 480, 280, 550])

print("ğŸ“š DATASET: Ã‰TUDES vs SALAIRE (SÃ©nÃ©gal)")
print("AnnÃ©es d'Ã©tudes:", etudes)
print("Salaires (milliers FCFA):", salaires)
print()

# Validation croisÃ©e
cv = ValidationCroisee(k=5)
mean_mse, std_mse = cv.cross_validate(etudes.reshape(-1, 1), salaires)`,
          },
          {
            type: "code",
            title: "Visualisation des rÃ©sultats",
            description: "Visualisons les rÃ©sultats de la validation croisÃ©e :",
            code: `# Visualisation des folds et modÃ¨les
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Graphique 1: DonnÃ©es et modÃ¨les de chaque fold
ax1.scatter(etudes, salaires, c='red', s=100, alpha=0.7, label='DonnÃ©es rÃ©elles')

# Ligne pour chaque modÃ¨le de fold
x_range = np.linspace(etudes.min(), etudes.max(), 100)
for i, theta in enumerate(cv.models):
    y_pred_range = theta[0] + theta[1] * x_range
    ax1.plot(x_range, y_pred_range, alpha=0.5, label=f'ModÃ¨le Fold {i+1}')

ax1.set_xlabel('AnnÃ©es d\\'Ã©tudes')
ax1.set_ylabel('Salaire (milliers FCFA)')
ax1.set_title('ModÃ¨les de chaque Fold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Graphique 2: Distribution des scores MSE
ax2.bar(range(1, len(cv.scores) + 1), cv.scores, 
        color=['lightblue', 'lightgreen', 'lightyellow', 'lightcoral', 'lightpink'])
ax2.axhline(y=mean_mse, color='red', linestyle='--', linewidth=2, 
           label=f'Moyenne: {mean_mse:.1f}')
ax2.set_xlabel('Fold')
ax2.set_ylabel('MSE')
ax2.set_title('Scores par Fold')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"ğŸ“Š Analyse terminÃ©e !")
print(f"StabilitÃ© du modÃ¨le: {'Bonne' if std_mse < mean_mse * 0.3 else 'Ã€ amÃ©liorer'}")`,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Validation temporelle : le cas particulier crucial",
            content: `
                        <p><strong>â° Les donnÃ©es temporelles ont leurs propres rÃ¨gles sacrÃ©es !</strong></p>
                        
                        <p><strong>âŒ L'erreur fatale (data leakage temporel) :</strong></p>
                        <p>Utiliser des donnÃ©es du <strong>futur</strong> pour prÃ©dire le <strong>passÃ©</strong> = triche involontaire qui fausse complÃ¨tement l'Ã©valuation !</p>
                        
                        <p><strong>ğŸ¯ Exemple concret :</strong></p>
                        <p>PrÃ©dire le cours du FCFA en janvier 2024 en utilisant des donnÃ©es de mars 2024 â†’ rÃ©sultats artificiellement excellents mais inutiles en production.</p>
                        
                        <p><strong>âœ… La bonne approche (Time Series Split) :</strong></p>
                        <ul>
                            <li>ğŸ“… <strong>Train</strong> : donnÃ©es historiques (ex: jan-juin 2023)</li>
                            <li>ğŸ” <strong>Validation</strong> : pÃ©riode suivante (juillet-aoÃ»t 2023)</li>
                            <li>ğŸ¯ <strong>Test</strong> : futur proche (septembre-octobre 2023)</li>
                        </ul>
                        
                        <p><strong>ğŸ”„ Techniques spÃ©cialisÃ©es :</strong></p>
                        
                        <p><strong>1. Walk-Forward Validation :</strong></p>
                        <ul>
                            <li>FenÃªtre glissante dans le temps</li>
                            <li>Train sur [t-n, t], test sur [t+1, t+k]</li>
                            <li>Avance d'une pÃ©riode et rÃ©pÃ¨te</li>
                        </ul>
                        
                        <p><strong>2. Expanding Window :</strong></p>
                        <ul>
                            <li>Train grandit progressivement : [0, t], [0, t+1], [0, t+2]...</li>
                            <li>Test toujours sur la pÃ©riode suivante</li>
                            <li>Simule l'accumulation de donnÃ©es en production</li>
                        </ul>
                        
                        <p><strong>3. Time Series Cross-Validation :</strong></p>
                        <ul>
                            <li>K-fold adaptÃ© au temporel</li>
                            <li>Chaque fold respecte l'ordre chronologique</li>
                            <li>Gaps entre train et test pour Ã©viter le leakage</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ RÃ¨gle d'or temporelle :</strong></p>
                        <div style="background: #fff3cd; padding: 1rem; border-left: 4px solid #ffc107; margin: 1rem 0;">
                            <strong>Toujours respecter l'ordre chronologique :</strong><br>
                            PassÃ© â†’ PrÃ©sent â†’ Futur<br>
                            Jamais l'inverse !
                        </div>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : validation temporelle manuelle",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Vous devez prÃ©dire les ventes mensuelles d'un magasin dakarois. Voici 12 mois de donnÃ©es :</p>
                        
                        <table style="margin: 1rem auto; border-collapse: collapse; text-align: center;">
                            <tr style="background: #3498db; color: white;">
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Mois</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Jan</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">FÃ©v</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Mar</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Avr</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Mai</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Jun</th>
                            </tr>
                            <tr>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;"><strong>Ventes</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">45</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">48</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">52</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">55</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">58</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">62</td>
                            </tr>
                        </table>
                        
                        <table style="margin: 1rem auto; border-collapse: collapse; text-align: center;">
                            <tr style="background: #3498db; color: white;">
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Mois</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Jul</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">AoÃ»</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Sep</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Oct</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Nov</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">DÃ©c</th>
                            </tr>
                            <tr>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;"><strong>Ventes</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">65</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">68</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">64</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">60</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">55</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd;">50</td>
                            </tr>
                        </table>
                        
                        <p><strong>ğŸ“ Effectuez une validation temporelle :</strong></p>
                        <ol>
                            <li>Divisez en : Train (Jan-AoÃ»t), Validation (Sep-Oct), Test (Nov-DÃ©c)</li>
                            <li>EntraÃ®nez un modÃ¨le linÃ©aire sur Train</li>
                            <li>Ã‰valuez sur Validation pour ajuster</li>
                            <li>Test final sur Nov-DÃ©c</li>
                            <li>Calculez les erreurs pour chaque ensemble</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('temporal-validation-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="temporal-validation-exercise" style="display: none;">
                        <p><strong>Division temporelle :</strong></p>
                        <ul>
                            <li><strong>Train :</strong> Jan-AoÃ»t (mois 1-8) â†’ ventes [45,48,52,55,58,62,65,68]</li>
                            <li><strong>Validation :</strong> Sep-Oct (mois 9-10) â†’ ventes [64,60]</li>
                            <li><strong>Test :</strong> Nov-DÃ©c (mois 11-12) â†’ ventes [55,50]</li>
                        </ul>
                        
                        <p><strong>ModÃ¨le linÃ©aire (y = ax + b) :</strong></p>
                        <p>Sur train : a â‰ˆ 3.1, b â‰ˆ 42.5 â†’ y = 3.1x + 42.5</p>
                        
                        <p><strong>PrÃ©dictions :</strong></p>
                        <ul>
                            <li>Sep (mois 9) : 3.1Ã—9 + 42.5 = 70.4 (rÃ©el: 64) â†’ erreur: 6.4</li>
                            <li>Oct (mois 10) : 3.1Ã—10 + 42.5 = 73.5 (rÃ©el: 60) â†’ erreur: 13.5</li>
                        </ul>
                        
                        <p><strong>Diagnostic :</strong> Le modÃ¨le linÃ©aire ne capture pas la saisonnalitÃ© (baisse fin d'annÃ©e)</p>
                        </div>
                    `,
          },
          {
            type: "code",
            title: "DÃ©tection automatique d'overfitting",
            description: "CrÃ©ons un systÃ¨me de dÃ©tection automatique :",
            code: `def detecter_overfitting(train_scores, val_scores, seuil_ratio=1.5, seuil_ecart=0.1):
    """
    DÃ©tecte automatiquement l'overfitting selon plusieurs critÃ¨res
    """
    print("ğŸ” DIAGNOSTIC AUTOMATIQUE D'OVERFITTING")
    print("=" * 45)
    
    # CritÃ¨re 1: Ratio des erreurs
    ratio_erreurs = val_scores[-1] / train_scores[-1] if train_scores[-1] > 0 else float('inf')
    overfitting_ratio = ratio_erreurs > seuil_ratio
    
    # CritÃ¨re 2: Ã‰cart absolu
    ecart_absolu = val_scores[-1] - train_scores[-1]
    overfitting_ecart = ecart_absolu > seuil_ecart
    
    # CritÃ¨re 3: Tendance divergente (5 derniers points)
    if len(train_scores) >= 5:
        train_trend = np.mean(np.diff(train_scores[-5:]))  # Pente moyenne
        val_trend = np.mean(np.diff(val_scores[-5:]))
        overfitting_trend = train_trend < -0.01 and val_trend > 0.01
    else:
        overfitting_trend = False
    
    print(f"ğŸ“Š Erreur train finale: {train_scores[-1]:.3f}")
    print(f"ğŸ“Š Erreur validation finale: {val_scores[-1]:.3f}")
    print(f"ğŸ“ˆ Ratio val/train: {ratio_erreurs:.2f} (seuil: {seuil_ratio})")
    print(f"ğŸ“‰ Ã‰cart absolu: {ecart_absolu:.3f} (seuil: {seuil_ecart})")
    
    # Diagnostic final
    nb_criteres = sum([overfitting_ratio, overfitting_ecart, overfitting_trend])
    
    if nb_criteres >= 2:
        diagnostic = "ğŸ”´ OVERFITTING DÃ‰TECTÃ‰"
        recommandations = [
            "â€¢ RÃ©duire la complexitÃ© du modÃ¨le",
            "â€¢ Ajouter de la rÃ©gularisation (L1/L2)",
            "â€¢ Augmenter les donnÃ©es d'entraÃ®nement",
            "â€¢ Early stopping sur validation"
        ]
    elif nb_criteres == 1:
        diagnostic = "ğŸŸ¡ OVERFITTING POSSIBLE"
        recommandations = [
            "â€¢ Surveiller l'Ã©volution",
            "â€¢ Tester avec plus de donnÃ©es",
            "â€¢ Validation croisÃ©e pour confirmer"
        ]
    else:
        diagnostic = "ğŸŸ¢ MODÃˆLE SAIN"
        recommandations = [
            "â€¢ ModÃ¨le bien Ã©quilibrÃ©",
            "â€¢ Peut essayer lÃ©gÃ¨rement plus de complexitÃ©",
            "â€¢ PrÃªt pour la production"
        ]
    
    print(f"\\n{diagnostic}")
    print("\\nğŸ”§ Recommandations:")
    for rec in recommandations:
        print(f"   {rec}")
    
    return diagnostic, nb_criteres

# Test avec donnÃ©es simulÃ©es d'overfitting
epochs = np.arange(1, 21)
train_loss = 0.5 * np.exp(-0.3 * epochs) + 0.02  # DÃ©croÃ®t exponentiellement
val_loss = 0.3 * np.exp(-0.1 * epochs) + 0.15 + 0.01 * epochs  # Remonte aprÃ¨s un moment

print("ğŸ§ª TEST SUR DONNÃ‰ES SIMULÃ‰ES")
diagnostic, severite = detecter_overfitting(train_loss, val_loss)

# Visualisation
plt.figure(figsize=(12, 6))
plt.plot(epochs, train_loss, 'b-o', label='Train Loss', linewidth=2)
plt.plot(epochs, val_loss, 'r-s', label='Validation Loss', linewidth=2)
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Courbes d\\'apprentissage - DÃ©tection Overfitting')
plt.legend()
plt.grid(True, alpha=0.3)

# Zone d'overfitting
overfitting_start = np.argmin(val_loss)
plt.axvline(x=overfitting_start + 1, color='orange', linestyle='--', 
           label=f'DÃ©but overfitting (epoch {overfitting_start + 1})')
plt.legend()
plt.show()

print(f"\\nâš ï¸ Overfitting dÃ©tectÃ© Ã  partir de l'epoch {overfitting_start + 1}")`,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "MÃ©triques d'Ã©valuation : choisir les bonnes armes",
            content: `
                        <p><strong>ğŸ“ Le choix de la mÃ©trique dÃ©termine le succÃ¨s de votre projet !</strong></p>
                        
                        <p><strong>ğŸ”¢ Pour la RÃ‰GRESSION :</strong></p>
                        
                        <p><strong>1. Mean Squared Error (MSE) :</strong></p>
                        <p>$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$</p>
                        <ul>
                            <li>âœ… <strong>Avantages</strong> : diffÃ©rentiable, pÃ©nalise fortement les grosses erreurs</li>
                            <li>âŒ <strong>InconvÃ©nients</strong> : sensible aux outliers, unitÃ© au carrÃ©</li>
                            <li>ğŸ¯ <strong>Usage</strong> : optimisation, quand les grosses erreurs sont critiques</li>
                        </ul>
                        
                        <p><strong>2. Mean Absolute Error (MAE) :</strong></p>
                        <p>$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$</p>
                        <ul>
                            <li>âœ… <strong>Avantages</strong> : robuste aux outliers, mÃªme unitÃ© que y</li>
                            <li>âŒ <strong>InconvÃ©nients</strong> : non diffÃ©rentiable en 0</li>
                            <li>ğŸ¯ <strong>Usage</strong> : donnÃ©es avec outliers, interprÃ©tation business</li>
                        </ul>
                        
                        <p><strong>3. Coefficient de dÃ©termination (RÂ²) :</strong></p>
                        <p>$$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} = 1 - \\frac{\\text{MSE}}{\\text{Var}(y)}$$</p>
                        <ul>
                            <li>âœ… <strong>Avantages</strong> : normalisÃ© [0,1], proportion de variance expliquÃ©e</li>
                            <li>âŒ <strong>InconvÃ©nients</strong> : peut Ãªtre nÃ©gatif si trÃ¨s mauvais modÃ¨le</li>
                            <li>ğŸ¯ <strong>Usage</strong> : comparaison de modÃ¨les, communication</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Pour la CLASSIFICATION :</strong></p>
                        
                        <p><strong>Matrice de confusion :</strong></p>
                        <p>$$\\begin{bmatrix} \\text{VP} & \\text{FN} \\\\ \\text{FP} & \\text{VN} \\end{bmatrix}$$</p>
                        
                        <p><strong>MÃ©triques dÃ©rivÃ©es :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ PrÃ©cision :</strong> $$\\text{Precision} = \\frac{\\text{VP}}{\\text{VP + FP}}$$ (parmi les positifs prÃ©dits, combien sont vrais ?)</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Rappel :</strong> $$\\text{Recall} = \\frac{\\text{VP}}{\\text{VP + FN}}$$ (parmi les vrais positifs, combien sont dÃ©tectÃ©s ?)</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ F1-Score :</strong> $$F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$ (moyenne harmonique)</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Accuracy :</strong> $$\\text{Accuracy} = \\frac{\\text{VP + VN}}{\\text{VP + VN + FP + FN}}$$ (âš ï¸ trompeur si classes dÃ©sÃ©quilibrÃ©es)</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : calcul manuel de mÃ©triques",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Un modÃ¨le de dÃ©tection de spam sur emails sÃ©nÃ©galais donne cette matrice de confusion :</p>
                        
                        <table style="margin: 1rem auto; border-collapse: collapse; text-align: center;">
                            <tr style="background: #f8f9fa;">
                                <th style="padding: 0.8rem; border: 1px solid #ddd;"></th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;" colspan="2">PrÃ©diction</th>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">RÃ©alitÃ©</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Spam</th>
                                <th style="padding: 0.8rem; border: 1px solid #ddd;">Normal</th>
                            </tr>
                            <tr>
                                <td style="padding: 0.5rem; border: 1px solid #ddd; background: #f8f9fa;"><strong>Spam</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd; background: #d4edda;">85</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd; background: #f8d7da;">15</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.5rem; border: 1px solid #ddd; background: #f8f9fa;"><strong>Normal</strong></td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd; background: #f8d7da;">10</td>
                                <td style="padding: 0.5rem; border: 1px solid #ddd; background: #d4edda;">890</td>
                            </tr>
                        </table>
                        
                        <p><strong>ğŸ“ Calculez :</strong></p>
                        <ol>
                            <li>PrÃ©cision pour la classe "Spam"</li>
                            <li>Rappel pour la classe "Spam"</li>
                            <li>F1-Score pour la classe "Spam"</li>
                            <li>Accuracy globale</li>
                            <li>Ce modÃ¨le est-il bon pour filtrer les spams ?</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('metrics-calculation-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="metrics-calculation-exercise" style="display: none;">
                        <p><strong>Identification des valeurs :</strong></p>
                        <ul>
                            <li>VP (Vrais Positifs) = 85 (spams correctement dÃ©tectÃ©s)</li>
                            <li>FN (Faux NÃ©gatifs) = 15 (spams ratÃ©s)</li>
                            <li>FP (Faux Positifs) = 10 (emails normaux classÃ©s spam)</li>
                            <li>VN (Vrais NÃ©gatifs) = 890 (emails normaux bien classÃ©s)</li>
                        </ul>
                        
                        <p><strong>Calculs :</strong></p>
                        <ol>
                            <li><strong>PrÃ©cision :</strong> 85/(85+10) = 85/95 = 0.895 (89.5%)</li>
                            <li><strong>Rappel :</strong> 85/(85+15) = 85/100 = 0.85 (85%)</li>
                            <li><strong>F1-Score :</strong> 2Ã—(0.895Ã—0.85)/(0.895+0.85) = 0.872 (87.2%)</li>
                            <li><strong>Accuracy :</strong> (85+890)/(85+15+10+890) = 975/1000 = 0.975 (97.5%)</li>
                            <li><strong>Ã‰valuation :</strong> Excellent modÃ¨le ! 89.5% des emails classÃ©s spam sont vraiment des spams, et 85% des vrais spams sont dÃ©tectÃ©s.</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "code",
            title: "Validation complÃ¨te avec dÃ©tection d'overfitting",
            description: "ImplÃ©mentons un pipeline de validation complet :",
            code: `import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score

# GÃ©nÃ©ration de donnÃ©es rÃ©alistes : prix immobilier Dakar
np.random.seed(42)
n_samples = 200

# Variables : surface (mÂ²), distance centre (km), Ã¢ge (annÃ©es)
surface = np.random.uniform(50, 300, n_samples)
distance_centre = np.random.uniform(1, 25, n_samples)
age_batiment = np.random.uniform(0, 30, n_samples)

# Prix rÃ©aliste avec relation non-linÃ©aire
prix_base = 150000  # FCFA/mÂ²
prix = (prix_base * surface * 
        (1.2 - 0.02 * distance_centre) *  # Effet distance
        (1.1 - 0.01 * age_batiment) +     # Effet Ã¢ge
        np.random.normal(0, 20000, n_samples))  # Bruit

X = np.column_stack([surface, distance_centre, age_batiment])
y = prix

print("ğŸ  VALIDATION COMPLÃˆTE - PRIX IMMOBILIER DAKAR")
print("=" * 55)

# 1. SPLIT INITIAL (garder test set sacrÃ©)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42  # 0.25 de 0.8 = 0.2 du total
)

print(f"ğŸ“Š Division des donnÃ©es :")
print(f"   Train : {len(X_train)} Ã©chantillons ({len(X_train)/len(X)*100:.0f}%)")
print(f"   Validation : {len(X_val)} Ã©chantillons ({len(X_val)/len(X)*100:.0f}%)")
print(f"   Test : {len(X_test)} Ã©chantillons ({len(X_test)/len(X)*100:.0f}%)")

# 2. TEST DE COMPLEXITÃ‰ (dÃ©tection overfitting)
degrees = range(1, 8)
train_scores = []
val_scores = []

print(f"\\nğŸ” Test de complexitÃ© (degrÃ© polynomial) :")
print("-" * 45)

for degree in degrees:
    # Transformation polynomiale
    poly = PolynomialFeatures(degree, include_bias=False)
    X_train_poly = poly.fit_transform(X_train)
    X_val_poly = poly.transform(X_val)
    
    # ModÃ¨le avec rÃ©gularisation lÃ©gÃ¨re
    model = Ridge(alpha=1000)
    model.fit(X_train_poly, y_train)
    
    # Scores RÂ²
    train_score = model.score(X_train_poly, y_train)
    val_score = model.score(X_val_poly, y_val)
    
    train_scores.append(train_score)
    val_scores.append(val_score)
    
    # Diagnostic automatique
    ratio = (1 - val_score) / (1 - train_score) if train_score < 0.99 else float('inf')
    status = "âš ï¸ OVERFITTING" if ratio > 2 else "âœ… OK"
    
    print(f"DegrÃ© {degree}: Train RÂ²={train_score:.3f}, Val RÂ²={val_score:.3f}, Ratio={ratio:.1f} {status}")

# Meilleur degrÃ©
best_degree = degrees[np.argmax(val_scores)]
print(f"\\nğŸ† Meilleur degrÃ© : {best_degree} (RÂ² validation = {max(val_scores):.3f})")`,
          },
          {
            type: "code",
            title: "Validation croisÃ©e et Ã©valuation finale",
            description: "Finalisons avec validation croisÃ©e et test final :",
            code: `from sklearn.model_selection import cross_val_score

# 3. VALIDATION CROISÃ‰E avec le meilleur degrÃ©
print(f"\\nğŸ”„ Validation croisÃ©e 5-fold (degrÃ© {best_degree}) :")
print("-" * 45)

poly_best = PolynomialFeatures(best_degree, include_bias=False)
X_train_val_poly = poly_best.fit_transform(np.vstack([X_train, X_val]))
y_train_val = np.concatenate([y_train, y_val])

model_cv = Ridge(alpha=1000)
cv_scores = cross_val_score(model_cv, X_train_val_poly, y_train_val, 
                           cv=5, scoring='r2')

for i, score in enumerate(cv_scores, 1):
    print(f"Fold {i}: RÂ² = {score:.3f}")

cv_mean = cv_scores.mean()
cv_std = cv_scores.std()
print(f"\\nğŸ“Š Score CV : {cv_mean:.3f} Â± {cv_std:.3f}")

# Intervalle de confiance Ã  95%
ic_lower = cv_mean - 1.96 * cv_std / np.sqrt(5)
ic_upper = cv_mean + 1.96 * cv_std / np.sqrt(5)
print(f"ğŸ“ˆ Intervalle confiance 95% : [{ic_lower:.3f}, {ic_upper:.3f}]")

# 4. Ã‰VALUATION FINALE sur TEST SET (une seule fois !)
print(f"\\nğŸ¯ Ã‰VALUATION FINALE sur TEST SET :")
print("=" * 55)

X_test_poly = poly_best.transform(X_test)
model_final = Ridge(alpha=1000)
model_final.fit(X_train_val_poly, y_train_val)
y_pred_test = model_final.predict(X_test_poly)

test_r2 = r2_score(y_test, y_pred_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
test_mae = np.mean(np.abs(y_test - y_pred_test))

print(f"RÂ² Test : {test_r2:.3f}")
print(f"RMSE Test : {test_rmse:,.0f} FCFA")
print(f"MAE Test : {test_mae:,.0f} FCFA")

# Diagnostic final
if abs(test_r2 - cv_mean) < 2 * cv_std:
    print("âœ… CohÃ©rence CV/Test : ModÃ¨le fiable")
else:
    print("âš ï¸ Ã‰cart CV/Test important : Possible problÃ¨me")

# Visualisation finale
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Courbes de validation
ax1.plot(degrees, train_scores, 'b-o', label='Train RÂ²', linewidth=2)
ax1.plot(degrees, val_scores, 'r-s', label='Validation RÂ²', linewidth=2)
ax1.axvline(best_degree, color='g', linestyle='--', alpha=0.7, label=f'Optimal (degrÃ© {best_degree})')
ax1.set_xlabel('DegrÃ© polynomial')
ax1.set_ylabel('Score RÂ²')
ax1.set_title('DÃ©tection Overfitting/Underfitting')
ax1.legend()
ax1.grid(True, alpha=0.3)

# PrÃ©dictions vs RÃ©el
ax2.scatter(y_test/1000, y_pred_test/1000, alpha=0.6, s=50)
ax2.plot([y_test.min()/1000, y_test.max()/1000], 
         [y_test.min()/1000, y_test.max()/1000], 'r--', linewidth=2)
ax2.set_xlabel('Prix rÃ©el (millions FCFA)')
ax2.set_ylabel('Prix prÃ©dit (millions FCFA)')
ax2.set_title(f'PrÃ©dictions Test (RÂ²={test_r2:.3f})')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\\nğŸ’¡ Conclusion finale :")
if test_r2 > 0.85:
    print("   âœ… ModÃ¨le excellent et bien gÃ©nÃ©ralisÃ© !")
elif test_r2 > 0.70:
    print("   ğŸŸ¡ ModÃ¨le correct mais perfectible")
else:
    print("   ğŸ”´ ModÃ¨le insuffisant, revoir l'approche")`,
          },
          {
            type: "warning",
            icon: "âš ï¸",
            title: "PiÃ¨ges mortels et bonnes pratiques",
            content: `
                        <p><strong>âŒ PIÃˆGES MORTELS Ã  Ã©viter absolument :</strong></p>
                        
                        <p><strong>1. Data Leakage (fuite de donnÃ©es) :</strong></p>
                        <ul>
                            <li>âŒ <strong>Normaliser sur tout le dataset</strong> avant split</li>
                            <li>âŒ <strong>SÃ©lection de features</strong> sur test set</li>
                            <li>âŒ <strong>Information du futur</strong> dans les prÃ©dictions passÃ©es</li>
                            <li>âŒ <strong>Preprocessing global</strong> avant division</li>
                        </ul>
                        
                        <p><strong>2. Mauvaise validation :</strong></p>
                        <ul>
                            <li>âŒ <strong>Test set trop petit</strong> (< 15%) â†’ estimations peu fiables</li>
                            <li>âŒ <strong>Pas de stratification</strong> sur classes rares</li>
                            <li>âŒ <strong>Optimiser sur le test set</strong> â†’ biais de sÃ©lection</li>
                            <li>âŒ <strong>Ignorer l'aspect temporel</strong> des donnÃ©es</li>
                        </ul>
                        
                        <p><strong>3. MÃ©triques inappropriÃ©es :</strong></p>
                        <ul>
                            <li>âŒ <strong>Accuracy seule</strong> sur donnÃ©es dÃ©sÃ©quilibrÃ©es (99% non-spam, 1% spam)</li>
                            <li>âŒ <strong>Ignorer le contexte mÃ©tier</strong> (coÃ»t des erreurs diffÃ©rent)</li>
                            <li>âŒ <strong>Se fier Ã  une seule mÃ©trique</strong></li>
                        </ul>
                        
                        <p><strong>âœ… BONNES PRATIQUES incontournables :</strong></p>
                        
                        <p><strong>1. Pipeline rigoureux :</strong></p>
                        <ol>
                            <li><strong>SÃ©parer test set</strong> dÃ¨s le dÃ©but (et l'oublier !)</li>
                            <li><strong>Preprocessing dans pipeline</strong> : fit sur train, transform sur val/test</li>
                            <li><strong>Cross-validation</strong> pour hyperparamÃ¨tres</li>
                            <li><strong>Test final</strong> une seule fois</li>
                        </ol>
                        
                        <p><strong>2. Validation adaptÃ©e au problÃ¨me :</strong></p>
                        <ul>
                            <li>ğŸ”„ <strong>K-fold standard</strong> : k=5 ou 10 pour donnÃ©es IID</li>
                            <li>ğŸ“Š <strong>Stratified K-fold</strong> : prÃ©server les proportions de classes</li>
                            <li>â° <strong>Time series split</strong> : respecter l'ordre temporel</li>
                            <li>ğŸ‘¥ <strong>Group K-fold</strong> : Ã©viter le leakage entre groupes liÃ©s</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Conseil d'or :</strong></p>
                        <div style="background: #d1ecf1; padding: 1rem; border-left: 4px solid #17a2b8; margin: 1rem 0;">
                            <strong>Un modÃ¨le simple bien validÃ© > modÃ¨le complexe mal Ã©valuÃ©</strong><br><br>
                            La validation rigoureuse est plus importante que l'algorithme choisi !
                        </div>
                        
                        <p><strong>ğŸ”® Prochaine Ã©tape :</strong></p>
                        <p>Maintenant que vous maÃ®trisez la validation, vous Ãªtes prÃªt pour le <strong>Deep Learning</strong> ! Nous commencerons par le <strong>Perceptron</strong> - le neurone artificiel qui a tout changÃ©.</p>
                    `,
          },
        ],
        quiz: {
          question:
            "ğŸ¤” Votre modÃ¨le a 2% d'erreur sur train, 25% sur validation, et vous n'avez pas encore touchÃ© au test set. Que faire ?",
          options: [
            "A) Tester immÃ©diatement sur le test set pour confirmer",
            "B) RÃ©duire la complexitÃ© du modÃ¨le ou ajouter de la rÃ©gularisation",
            "C) Augmenter la complexitÃ© pour amÃ©liorer le train",
            "D) Changer de mÃ©trique d'Ã©valuation",
          ],
          correct: 1,
          explanation:
            "Grand Ã©cart train (2%) vs validation (25%) = overfitting classique ! Il faut rÃ©duire la complexitÃ© ou ajouter de la rÃ©gularisation. Surtout PAS toucher au test set maintenant - il doit rester vierge jusqu'Ã  la fin !",
        },
        prevModule: "clustering.html",
        nextModule: "../dl/perceptron.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
