<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Validation Crois√©e | IA4Ndada</title>

    <!-- MathJax pour les formules math√©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>ü§ñ Machine Learning</span>
          <span>‚Ä∫</span>
          <span>Validation</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>‚úÖ Validation Crois√©e</h1>
      <p class="subtitle">Module 3.5 - √âvaluation Robuste des Mod√®les</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajout√©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajout√© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>üéâ Checkpoint - Validation Crois√©e</h3>
        <p>
          Vous ma√Ætrisez maintenant les techniques de validation pour √©valuer
          rigoureusement vos mod√®les ML.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme compl√©t√©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="clustering.html" class="nav-link" id="prev-link"
          >‚Üê Module pr√©c√©dent : Clustering</a
        >
        <a href="../dl/perceptron.html" class="nav-link" id="next-link"
          >Module suivant : Perceptron ‚Üí</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Validation Crois√©e
      const moduleConfig = {
        id: "ml-validation",
        title: "Validation Crois√©e",
        category: "Machine Learning",
        objectives: [
          "Comprendre pourquoi la validation est cruciale en ML",
          "Ma√Ætriser les fondements math√©matiques de la validation crois√©e",
          "Distinguer les diff√©rentes strat√©gies de validation",
          "Analyser le compromis biais-variance dans l'√©valuation",
        ],
        content: [
          {
            type: "concept",
            icon: "üí°",
            title: "Le probl√®me fondamental de l'√©valuation",
            content: `
                        <p><strong>üéØ Pourquoi la validation est-elle critique ?</strong></p>
                        <p>En ML, nous cherchons √† pr√©dire sur des donn√©es <strong>futures</strong>, pas √† m√©moriser des donn√©es <strong>pass√©es</strong>. C'est la diff√©rence entre comprendre et r√©citer.</p>
                        
                        <p><strong>‚ö†Ô∏è Le paradoxe de l'apprentissage :</strong></p>
                        <ul>
                            <li>üìä <strong>Performance apparente</strong> : excellente sur les donn√©es d'entra√Ænement</li>
                            <li>üéØ <strong>Performance r√©elle</strong> : m√©diocre sur de nouvelles donn√©es</li>
                            <li>üìà <strong>L'√©cart r√©v√©lateur</strong> : mesure du surapprentissage</li>
                        </ul>
                        
                        <p><strong>üí° Analogie √©clairante :</strong></p>
                        <p>Un √©tudiant qui m√©morise les questions-r√©ponses d'annales peut avoir 20/20 sur ces exercices pr√©cis, mais √©chouer face √† une variante. La validation teste la <strong>compr√©hension</strong>, pas la m√©morisation.</p>
                        
                        <p><strong>üî¨ Principe scientifique :</strong></p>
                        <p>La validation crois√©e applique la m√©thode scientifique : tester une hypoth√®se (mod√®le) sur des donn√©es ind√©pendantes de celles qui ont servi √† la formuler.</p>
                    `,
          },
          {
            type: "math",
            icon: "üî¢",
            title: "Formalisation math√©matique de la g√©n√©ralisation",
            content: `
                        <p><strong>üìä Cadre th√©orique rigoureux :</strong></p>
                        
                        <p><strong>Distribution des donn√©es :</strong></p>
                        <p>Les donn√©es proviennent d'une distribution jointe \\(P(X, Y)\\) inconnue. Notre dataset \\(D = \\{(x_i, y_i)\\}_{i=1}^n\\) est un √©chantillon de cette distribution.</p>
                        
                        <p><strong>üéØ Risque empirique vs risque r√©el :</strong></p>
                        
                        <p><strong>Risque r√©el</strong> (ce qu'on veut minimiser) :</p>
                        <p>$$R(f) = \\mathbb{E}_{(X,Y) \\sim P}[L(f(X), Y)] = \\int L(f(x), y) \\, dP(x,y)$$</p>
                        
                        <p><strong>Risque empirique</strong> (ce qu'on peut calculer) :</p>
                        <p>$$\\hat{R}_n(f) = \\frac{1}{n}\\sum_{i=1}^{n} L(f(x_i), y_i)$$</p>
                        
                        <p><strong>‚ö†Ô∏è Le pi√®ge :</strong> Si \\(f\\) est choisie en fonction de \\(D\\), alors \\(\\hat{R}_n(f)\\) sous-estime \\(R(f)\\) !</p>
                        
                        <p><strong>üîó Th√©or√®me fondamental (lien avec les <a href="../math/probability.html">probabilit√©s</a>) :</strong></p>
                        <p>Pour un ensemble de test ind√©pendant \\(T\\), l'estimateur :</p>
                        <p>$$\\hat{R}_T(f) = \\frac{1}{|T|}\\sum_{(x,y) \\in T} L(f(x), y)$$</p>
                        <p>v√©rifie : \\(\\mathbb{E}[\\hat{R}_T(f)] = R(f)\\) (estimateur non biais√©)</p>
                        
                        <p><strong>üìà Borne de g√©n√©ralisation (lien avec les <a href="../math/statistics.html">statistiques</a>) :</strong></p>
                        <p>Avec probabilit√© \\(1-\\delta\\) :</p>
                        <p>$$R(f) \\leq \\hat{R}_n(f) + \\sqrt{\\frac{\\log(2/\\delta)}{2n}}$$</p>
                        <p>Cette borne montre que l'√©cart diminue en \\(O(1/\\sqrt{n})\\).</p>
                    `,
          },
          {
            type: "intuition",
            icon: "üß†",
            title: "La k-fold validation : √©quilibre optimal",
            content: `
                        <p><strong>üîÑ Principe g√©om√©trique de la k-fold :</strong></p>
                        <p>Imaginez vos donn√©es comme un g√¢teau. Au lieu de le couper une fois (train/test simple), vous le d√©coupez en \\(k\\) parts √©gales et testez \\(k\\) fois, chaque part servant tour √† tour de test.</p>
                        
                        <p><strong>üìä D√©composition math√©matique :</strong></p>
                        <p>Partition de l'espace des donn√©es : \\(D = D_1 \\cup D_2 \\cup ... \\cup D_k\\) avec \\(D_i \\cap D_j = \\emptyset\\) pour \\(i \\neq j\\)</p>
                        
                        <p><strong>Pour chaque fold \\(i\\) :</strong></p>
                        <ul>
                            <li>Ensemble d'entra√Ænement : \\(D^{(i)}_{train} = D \\setminus D_i\\)</li>
                            <li>Ensemble de test : \\(D^{(i)}_{test} = D_i\\)</li>
                            <li>Taille d'entra√Ænement : \\(|D^{(i)}_{train}| = \\frac{(k-1)n}{k}\\)</li>
                        </ul>
                        
                        <p><strong>üéØ Estimation finale :</strong></p>
                        <p>$$\\hat{R}_{CV} = \\frac{1}{k}\\sum_{i=1}^{k} \\hat{R}_{D_i}(f_i)$$</p>
                        <p>o√π \\(f_i\\) est le mod√®le entra√Æn√© sur \\(D^{(i)}_{train}\\)</p>
                        
                        <p><strong>üí° Propri√©t√©s remarquables :</strong></p>
                        <ul>
                            <li>üìà <strong>Utilisation des donn√©es</strong> : chaque point est utilis√© exactement \\(k-1\\) fois pour l'entra√Ænement et 1 fois pour le test</li>
                            <li>üéØ <strong>R√©duction de variance</strong> : moyenner \\(k\\) estimations r√©duit la variance par un facteur \\(\\approx\\sqrt{k}\\)</li>
                            <li>‚öñÔ∏è <strong>Compromis</strong> : \\(k\\) grand ‚Üí moins de biais mais plus de corr√©lation entre folds</li>
                        </ul>
                        
                        <p><strong>üîó Lien avec les <a href="../math/matrices.html">matrices</a> :</strong></p>
                        <p>La matrice d'incidence \\(M \\in \\{0,1\\}^{k \\times n}\\) o√π \\(M_{ij} = 1\\) si l'exemple \\(j\\) est dans le fold \\(i\\) forme une partition √©quilibr√©e.</p>
                    `,
          },
          {
            type: "math",
            icon: "üî¢",
            title: "Analyse du compromis biais-variance",
            content: `
                        <p><strong>üìä D√©composition fondamentale de l'erreur :</strong></p>
                        
                        <p>Pour un point \\(x\\) fix√©, l'erreur quadratique se d√©compose :</p>
                        <p>$$\\mathbb{E}_{D,\\epsilon}[(y - \\hat{f}_D(x))^2] = \\underbrace{(f(x) - \\mathbb{E}_D[\\hat{f}_D(x)])^2}_{\\text{Biais}^2} + \\underbrace{\\mathbb{E}_D[(\\hat{f}_D(x) - \\mathbb{E}_D[\\hat{f}_D(x)])^2]}_{\\text{Variance}} + \\underbrace{\\sigma^2}_{\\text{Bruit}}$$</p>
                        
                        <p><strong>Interpr√©tation g√©om√©trique (lien avec les <a href="../math/vectors.html">vecteurs</a>) :</strong></p>
                        <ul>
                            <li><strong>Biais</strong> : distance entre le centre de la cible et le centre de nos tirs</li>
                            <li><strong>Variance</strong> : dispersion de nos tirs autour de leur centre</li>
                            <li><strong>Bruit</strong> : incertitude irr√©ductible de la cible elle-m√™me</li>
                        </ul>
                        
                        <p><strong>üéØ Impact du choix de \\(k\\) dans la k-fold :</strong></p>
                        
                        <p><strong>Analyse du biais :</strong></p>
                        <p>Taille d'entra√Ænement = \\(\\frac{k-1}{k}n\\)</p>
                        <ul>
                            <li>\\(k = 2\\) : utilise 50% des donn√©es ‚Üí biais √©lev√©</li>
                            <li>\\(k = n\\) (LOO) : utilise \\((n-1)\\) donn√©es ‚Üí biais minimal</li>
                            <li>Biais d√©cro√Æt comme : \\(O\\left(\\frac{1}{k}\\right)\\)</li>
                        </ul>
                        
                        <p><strong>Analyse de la variance :</strong></p>
                        <p>Corr√©lation entre les mod√®les \\(f_i\\) et \\(f_j\\) :</p>
                        <p>$$\\rho_{ij} = \\text{Corr}(f_i, f_j) \\approx \\frac{|D^{(i)}_{train} \\cap D^{(j)}_{train}|}{|D^{(i)}_{train}|} = \\frac{k-2}{k-1}$$</p>
                        
                        <p>Plus \\(k\\) augmente, plus \\(\\rho_{ij} \\to 1\\), augmentant la variance de l'estimation moyenne.</p>
                        
                        <p><strong>‚ú® R√©sultat optimal :</strong></p>
                        <p>√âtudes empiriques et th√©oriques convergent vers \\(k \\in \\{5, 10\\}\\) comme compromis optimal pour la plupart des probl√®mes.</p>
                    `,
          },
          {
            type: "concept",
            icon: "üí°",
            title: "Strat√©gies de validation sp√©cialis√©es",
            content: `
                        <p><strong>üéØ Adapter la validation au contexte du probl√®me :</strong></p>
                        
                        <p><strong>1Ô∏è‚É£ Validation stratifi√©e (classification d√©s√©quilibr√©e)</strong></p>
                        <p>Pr√©serve la distribution des classes : si \\(P(Y=c) = p_c\\) dans \\(D\\), alors \\(P(Y=c) = p_c\\) dans chaque fold.</p>
                        
                        <p><strong>Formalisation :</strong></p>
                        <p>Pour chaque classe \\(c\\) et fold \\(i\\) :</p>
                        <p>$$\\frac{|\\{(x,y) \\in D_i : y = c\\}|}{|D_i|} \\approx \\frac{|\\{(x,y) \\in D : y = c\\}|}{|D|}$$</p>
                        
                        <p><strong>Impact (lien avec les <a href="../math/probability.html">probabilit√©s conditionnelles</a>) :</strong></p>
                        <p>R√©duit la variance de l'estimation en pr√©servant \\(P(Y|\\text{fold})\\)</p>
                        
                        <p><strong>2Ô∏è‚É£ Validation temporelle (s√©ries temporelles)</strong></p>
                        <p><strong>Principe de causalit√© :</strong> jamais d'information future dans l'entra√Ænement</p>
                        
                        <p><strong>Forward chaining :</strong></p>
                        <ul>
                            <li>Fold 1 : train=[1:t‚ÇÅ], test=[t‚ÇÅ+1:t‚ÇÇ]</li>
                            <li>Fold 2 : train=[1:t‚ÇÇ], test=[t‚ÇÇ+1:t‚ÇÉ]</li>
                            <li>Fold k : train=[1:t‚Çñ‚Çã‚ÇÅ], test=[t‚Çñ‚Çã‚ÇÅ+1:t‚Çñ]</li>
                        </ul>
                        
                        <p><strong>Propri√©t√© importante :</strong> \\(D^{(i)}_{train} \\subset D^{(i+1)}_{train}\\) (entra√Ænement croissant)</p>
                        
                        <p><strong>3Ô∏è‚É£ Validation group√©e (donn√©es corr√©l√©es)</strong></p>
                        <p>Quand les donn√©es ont une structure de groupe (patients, utilisateurs, sessions)</p>
                        
                        <p><strong>Partition par groupes :</strong></p>
                        <p>$$D = \\bigcup_{g \\in G} D_g \\text{ o√π } D_g = \\{(x,y) : \\text{groupe}(x) = g\\}$$</p>
                        <p>Les folds respectent les groupes : un groupe entier dans train ou test, jamais divis√©.</p>
                        
                        <p><strong>4Ô∏è‚É£ Leave-One-Out (LOO) : cas limite</strong></p>
                        <p>Cas extr√™me o√π \\(k = n\\) (un seul exemple en test)</p>
                        
                        <p><strong>Propri√©t√©s math√©matiques :</strong></p>
                        <ul>
                            <li>Biais : \\(O(1/n)\\) (quasi-nul)</li>
                            <li>Variance : maximale (folds tr√®s corr√©l√©s)</li>
                            <li>Complexit√© : \\(O(n \\times T_{train})\\)</li>
                        </ul>
                        
                        <p><strong>Th√©or√®me (lien avec les <a href="../math/derivatives.html">d√©riv√©es</a>) :</strong></p>
                        <p>Pour certains mod√®les lin√©aires, LOO peut √™tre calcul√© efficacement via la formule :</p>
                        <p>$$CV_{LOO} = \\sum_{i=1}^n \\left(\\frac{y_i - \\hat{y}_i}{1 - h_{ii}}\\right)^2$$</p>
                        <p>o√π \\(h_{ii}\\) est le levier (√©l√©ment diagonal de la matrice hat).</p>
                    `,
          },
          {
            type: "intuition",
            icon: "üß†",
            title: "Validation imbriqu√©e pour les hyperparam√®tres",
            content: `
                        <p><strong>üéõÔ∏è Le probl√®me de la double s√©lection :</strong></p>
                        <p>Utiliser les m√™mes donn√©es pour choisir le mod√®le ET l'√©valuer introduit un biais d'optimisme.</p>
                        
                        <p><strong>üìä Architecture √† trois niveaux :</strong></p>
                        
                        <p><strong>Niveau 1 - Param√®tres \\(\\theta\\) :</strong></p>
                        <ul>
                            <li>Appris sur l'ensemble d'entra√Ænement</li>
                            <li>Exemple : poids d'un r√©seau de neurones</li>
                        </ul>
                        
                        <p><strong>Niveau 2 - Hyperparam√®tres \\(\\lambda\\) :</strong></p>
                        <ul>
                            <li>S√©lectionn√©s via l'ensemble de validation</li>
                            <li>Exemple : taux de r√©gularisation, profondeur d'arbre</li>
                        </ul>
                        
                        <p><strong>Niveau 3 - √âvaluation finale :</strong></p>
                        <ul>
                            <li>Performance mesur√©e sur l'ensemble de test</li>
                            <li>Jamais utilis√© pendant le d√©veloppement</li>
                        </ul>
                        
                        <p><strong>üîÑ Validation crois√©e imbriqu√©e :</strong></p>
                        
                        <p><strong>Structure double boucle :</strong></p>
                        <p>Pour chaque fold externe \\(i\\) :</p>
                        <ol>
                            <li>Diviser \\(D^{(i)}_{train}\\) en \\(m\\) folds internes</li>
                            <li>Pour chaque configuration \\(\\lambda\\) :
                                <ul>
                                    <li>Faire une m-fold CV interne</li>
                                    <li>Calculer le score moyen \\(S(\\lambda)\\)</li>
                                </ul>
                            </li>
                            <li>S√©lectionner \\(\\lambda^* = \\arg\\max_\\lambda S(\\lambda)\\)</li>
                            <li>R√©entra√Æner sur tout \\(D^{(i)}_{train}\\) avec \\(\\lambda^*\\)</li>
                            <li>√âvaluer sur \\(D^{(i)}_{test}\\)</li>
                        </ol>
                        
                        <p><strong>Complexit√© totale :</strong> \\(O(k \\times m \\times |\\Lambda| \\times T_{train})\\)</p>
                        
                        <p><strong>üí° Garantie th√©orique :</strong></p>
                        <p>L'estimation finale est non biais√©e car chaque fold externe est ind√©pendant de la s√©lection d'hyperparam√®tres.</p>
                        
                        <p><strong>üîó Lien avec l'<a href="../math/probability.html">ind√©pendance statistique</a> :</strong></p>
                        <p>\\(P(\\text{performance} | \\text{test}) = P(\\text{performance})\\) car test n'influence pas le choix du mod√®le.</p>
                    `,
          },
          {
            type: "math",
            icon: "üî¢",
            title: "Bornes th√©oriques et intervalles de confiance",
            content: `
                        <p><strong>üìä Intervalles de confiance pour la k-fold :</strong></p>
                        
                        <p>Soit \\(e_1, ..., e_k\\) les erreurs sur chaque fold. L'erreur moyenne :</p>
                        <p>$$\\bar{e} = \\frac{1}{k}\\sum_{i=1}^k e_i$$</p>
                        
                        <p><strong>Variance empirique :</strong></p>
                        <p>$$s^2 = \\frac{1}{k-1}\\sum_{i=1}^k (e_i - \\bar{e})^2$$</p>
                        
                        <p><strong>Intervalle de confiance (lien avec les <a href="../math/statistics.html">statistiques</a>) :</strong></p>
                        <p>Sous hypoth√®se de normalit√©, IC √† 95% :</p>
                        <p>$$\\bar{e} \\pm t_{0.975, k-1} \\cdot \\frac{s}{\\sqrt{k}}$$</p>
                        
                        <p><strong>‚ö†Ô∏è Attention :</strong> Les folds ne sont pas ind√©pendants ! Correction :</p>
                        <p>$$\\text{Var}(\\bar{e}) = \\frac{\\sigma^2}{k}\\left(1 + (k-1)\\rho\\right)$$</p>
                        <p>o√π \\(\\rho\\) est la corr√©lation moyenne entre folds.</p>
                        
                        <p><strong>üéØ Test statistique pour comparer deux mod√®les :</strong></p>
                        
                        <p>Diff√©rences appari√©es : \\(d_i = e_i^{(A)} - e_i^{(B)}\\) pour chaque fold</p>
                        
                        <p><strong>Statistique de test :</strong></p>
                        <p>$$t = \\frac{\\bar{d}}{s_d/\\sqrt{k}} \\sim t_{k-1}$$</p>
                        
                        <p><strong>R√®gle de d√©cision :</strong></p>
                        <p>Rejeter \\(H_0\\) (mod√®les √©quivalents) si \\(|t| > t_{\\alpha/2, k-1}\\)</p>
                        
                        <p><strong>üîó Lien avec les <a href="../math/gradients.html">gradients</a> :</strong></p>
                        <p>La variance de l'estimation du gradient dans SGD suit une loi similaire, d'o√π l'importance de moyenner sur plusieurs mini-batches.</p>
                    `,
          },
        ],
        quiz: {
          question:
            "ü§î Pourquoi la k-fold validation avec k=n (Leave-One-Out) n'est-elle pas toujours optimale malgr√© son biais minimal ?",
          options: [
            "A) Elle utilise trop peu de donn√©es pour l'entra√Ænement",
            "B) Sa variance est maximale car les mod√®les sont tr√®s corr√©l√©s",
            "C) Elle ne peut pas g√©rer les classes d√©s√©quilibr√©es",
            "D) Son temps de calcul est trop faible",
          ],
          correct: 1,
          explanation:
            "LOO a une variance maximale car les k mod√®les sont entra√Æn√©s sur des ensembles quasi-identiques (n-1 exemples en commun), cr√©ant une forte corr√©lation. Cette variance √©lev√©e peut dominer le gain en biais, rendant k=5 ou k=10 souvent pr√©f√©rables.",
        },
        prevModule: "clustering.html",
        nextModule: "../dl/perceptron.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
