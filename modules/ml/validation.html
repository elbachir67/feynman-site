<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Validation de Mod√®les | IA4Ndada</title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">üè† Accueil</a>
          <span>‚Ä∫</span>
          <span>ü§ñ Machine Learning</span>
          <span>‚Ä∫</span>
          <span>Validation</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div class="progress-fill" id="progress-fill" style="width: 0%"></div>
          </div>
        </div>
      </div>
    </nav>

    <div class="container">
      <h1>‚úÖ Validation de Mod√®les</h1>
      <p class="subtitle">Module 3.5 - √âvaluer correctement vos mod√®les</p>

      <div id="pyodide-status" class="pyodide-status">
        <span class="status-loading">‚è≥ Chargement de Python...</span>
      </div>

      <div class="objectives">
        <h2>üéØ Objectifs d'apprentissage</h2>
        <ul id="objectives-list"></ul>
      </div>

      <div id="module-content"></div>

      <div class="checkpoint">
        <h3>üéâ Checkpoint - Validation</h3>
        <p>Vous savez maintenant √©valuer vos mod√®les rigoureusement !</p>
        <button class="checkpoint-btn" id="checkpoint-btn" onclick="completeCheckpoint()" disabled>
          Valider le module
        </button>
      </div>

      <div class="module-nav">
        <a href="clustering.html" class="nav-link">‚Üê Clustering</a>
        <a href="../dl/perceptron.html" class="nav-link">Deep Learning ‚Üí</a>
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      const moduleConfig = {
        id: "ml-validation",
        title: "Validation de Mod√®les",
        objectives: [
          "Comprendre pourquoi s√©parer train/test",
          "Ma√Ætriser la validation crois√©e K-Fold",
          "√âviter les fuites de donn√©es",
          "Choisir les bonnes m√©triques",
        ],
        content: [
          {
            type: "concept",
            icon: "üéØ",
            title: "Pourquoi valider rigoureusement ?",
            content: `
              <p><strong>Objectif du ML :</strong> Pr√©dire sur de <strong>nouvelles donn√©es</strong>, pas m√©moriser les anciennes.</p>

              <p><strong>Le probl√®me :</strong></p>
              <p>Un mod√®le peut avoir 99% de pr√©cision sur l'entra√Ænement mais 50% sur de nouvelles donn√©es ‚Üí overfitting.</p>

              <p><strong>Solution :</strong> S√©parer les donn√©es</p>
              <ul>
                <li><strong>Train (60-80%)</strong> : pour apprendre</li>
                <li><strong>Validation (10-20%)</strong> : pour ajuster les hyperparam√®tres</li>
                <li><strong>Test (10-20%)</strong> : √©valuation finale (jamais touch√© avant !)</li>
              </ul>

              <p style="background: #ffcdd2; padding: 1rem; border-radius: 8px;">
                <strong>‚ö†Ô∏è R√®gle d'or :</strong> Ne JAMAIS utiliser les donn√©es de test pour prendre des d√©cisions de mod√©lisation !
              </p>
            `,
          },
          {
            type: "quiz",
            title: "Quiz - S√©paration des donn√©es",
            question: "Vous avez optimis√© vos hyperparam√®tres en regardant les performances sur le set de test. Quel est le probl√®me ?",
            options: [
              "Aucun probl√®me, c'est la bonne m√©thode",
              "Le test devient du validation, vous n'avez plus d'estimation non-biais√©e",
              "Le mod√®le va underfitter",
              "Il faut plus de donn√©es",
            ],
            correctAnswer: 1,
            explanation: "En optimisant sur le test, vous 'fuitez' de l'information. Le test n'est plus une estimation honn√™te de la performance r√©elle. Utilisez un set de validation s√©par√© pour l'optimisation !",
          },
          {
            type: "concept",
            icon: "üîÑ",
            title: "Validation crois√©e K-Fold",
            content: `
              <p><strong>Probl√®me du split simple :</strong> Le r√©sultat d√©pend du hasard de la division.</p>

              <p><strong>Solution : K-Fold Cross-Validation</strong></p>
              <ol>
                <li>Diviser les donn√©es en K parties (folds)</li>
                <li>Pour i = 1 √† K : utiliser fold i comme validation, les autres comme train</li>
                <li>Moyenner les K scores</li>
              </ol>

              <p><strong>Avantages :</strong></p>
              <ul>
                <li>Chaque donn√©e sert une fois pour la validation</li>
                <li>Estimation plus robuste</li>
                <li>On obtient aussi l'√©cart-type (variabilit√©)</li>
              </ul>
            `,
          },
          {
            type: "exercise",
            title: "Calcul de moyenne cross-validation",
            exerciseType: "numeric",
            content: `
              <p>Une 5-fold cross-validation donne les scores :</p>
              <p>0.85, 0.82, 0.88, 0.84, 0.86</p>
              <p><strong>Quelle est la performance moyenne ?</strong></p>
            `,
            correctAnswer: 0.85,
            tolerance: 0.001,
            hint: "Moyenne = (0.85 + 0.82 + 0.88 + 0.84 + 0.86) / 5",
            explanation: "Moyenne = 4.25 / 5 = 0.85",
          },
          {
            type: "code",
            title: "Impl√©mentation de K-Fold",
            description: "Validation crois√©e from scratch :",
            code: `import numpy as np

# Donn√©es simul√©es
np.random.seed(42)
n = 100
X = np.random.randn(n, 2)
y = (X[:, 0] + X[:, 1] > 0).astype(int)

print("üìä VALIDATION CROIS√âE 5-FOLD")

def kfold_split(n, k=5):
    indices = np.arange(n)
    np.random.shuffle(indices)
    fold_size = n // k
    for i in range(k):
        val_idx = indices[i*fold_size:(i+1)*fold_size]
        train_idx = np.concatenate([indices[:i*fold_size], indices[(i+1)*fold_size:]])
        yield train_idx, val_idx

def simple_classifier(X_train, y_train, X_val):
    c0 = X_train[y_train == 0].mean(axis=0)
    c1 = X_train[y_train == 1].mean(axis=0)
    d0 = np.sum((X_val - c0)**2, axis=1)
    d1 = np.sum((X_val - c1)**2, axis=1)
    return (d1 < d0).astype(int)

scores = []
for fold, (train_idx, val_idx) in enumerate(kfold_split(n, k=5)):
    X_train, y_train = X[train_idx], y[train_idx]
    X_val, y_val = X[val_idx], y[val_idx]
    y_pred = simple_classifier(X_train, y_train, X_val)
    accuracy = np.mean(y_pred == y_val)
    scores.append(accuracy)
    print(f"Fold {fold+1}: {accuracy:.2%}")

print(f"\\nüìä Moyenne: {np.mean(scores):.2%} ¬± {np.std(scores):.2%}")`,
          },
          {
            type: "quiz",
            title: "Quiz - K-Fold",
            question: "Avec K=10 folds sur 1000 donn√©es, combien d'exemples pour l'entra√Ænement √† chaque fold ?",
            options: [
              "100 exemples",
              "900 exemples",
              "500 exemples",
              "1000 exemples",
            ],
            correctAnswer: 1,
            explanation: "1000/10 = 100 par fold. √Ä chaque it√©ration: 1 fold (100) pour validation, 9 folds (900) pour entra√Ænement.",
          },
          {
            type: "concept",
            icon: "‚ö†Ô∏è",
            title: "Fuites de donn√©es (Data Leakage)",
            content: `
              <p><strong>D√©finition :</strong> Information du futur ou du test qui s'infiltre dans l'entra√Ænement.</p>

              <p><strong>Exemple typique :</strong></p>
              <pre style="background: #ffcdd2; padding: 0.5rem; border-radius: 4px;">
# ‚ùå MAUVAIS
X_norm = (X - X.mean()) / X.std()
X_train, X_test = split(X_norm)</pre>

              <pre style="background: #c8e6c9; padding: 0.5rem; border-radius: 4px;">
# ‚úÖ BON
X_train, X_test = split(X)
X_train_norm = (X_train - X_train.mean()) / X_train.std()
X_test_norm = (X_test - X_train.mean()) / X_train.std()</pre>

              <p><strong>R√®gle :</strong> Fit uniquement sur train, puis transform sur test.</p>
            `,
          },
          {
            type: "exercise",
            title: "D√©tection de fuite",
            exerciseType: "mcq",
            content: `
              <p>Vous pr√©disez si un patient est malade. Features :</p>
              <ul>
                <li>√Çge, Poids, <strong>Date du diagnostic</strong>, Pression art√©rielle</li>
              </ul>
              <p><strong>Quelle feature cr√©e une fuite ?</strong></p>
            `,
            options: [
              "√Çge",
              "Poids",
              "Date du diagnostic",
              "Pression art√©rielle",
            ],
            correctAnswer: 2,
            explanation: "La 'date du diagnostic' n'existe que si le patient EST diagnostiqu√© ! C'est une information du futur qu'on n'aurait pas en production.",
          },
          {
            type: "exercise-code",
            title: "Corrigez la fuite de donn√©es",
            content: `<p>Compl√©tez le code pour √©viter la fuite :</p>`,
            starterCode: `import numpy as np

np.random.seed(42)
X = np.random.randn(100, 2)
y = (X[:, 0] > 0).astype(int)

# TODO: Split AVANT normalisation
# Puis normaliser avec les stats du train seulement

# 1. Split
n_train = 80
X_train, X_test = X[:n_train], X[n_train:]
y_train, y_test = y[:n_train], y[n_train:]

# 2. Normaliser (fit sur train)
train_mean = X_train.mean(axis=0)
train_std = X_train.std(axis=0)

X_train_norm = (X_train - train_mean) / train_std
X_test_norm = (X_test - train_mean) / train_std

print("‚úÖ Pas de fuite !")
print(f"Train: {X_train_norm.shape}, Test: {X_test_norm.shape}")`,
            solution: `import numpy as np
np.random.seed(42)
X = np.random.randn(100, 2)
y = (X[:, 0] > 0).astype(int)

X_train, X_test = X[:80], X[80:]
train_mean, train_std = X_train.mean(axis=0), X_train.std(axis=0)
X_train_norm = (X_train - train_mean) / train_std
X_test_norm = (X_test - train_mean) / train_std
print("‚úÖ Pas de fuite !")`,
            expectedOutput: "Pas de fuite",
          },
          {
            type: "quiz",
            title: "Quiz final - Validation",
            question: "Dataset de 10000 exemples dont 50 frauduleux (0.5%). Quelle validation ?",
            options: [
              "Simple split 80/20",
              "K-Fold standard",
              "Stratified K-Fold",
              "Pas besoin de validation",
            ],
            correctAnswer: 2,
            explanation: "Avec 0.5% de fraudes, un fold pourrait n'en contenir aucune ! La stratification garantit la m√™me proportion de fraudes dans chaque fold.",
          },
        ],
        prevModule: "clustering.html",
        nextModule: "../dl/perceptron.html",
      };

      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
