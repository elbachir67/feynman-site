<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CNN | IA4Ndada</title>

    <!-- MathJax pour les formules mathÃ©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">ğŸ  Accueil</a>
          <span>â€º</span>
          <span>ğŸ§  Deep Learning</span>
          <span>â€º</span>
          <span>CNN</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>ğŸ–¼ï¸ CNN : RÃ©seaux de Neurones Convolutifs</h1>
      <p class="subtitle">Module 4.4 - Vision par Ordinateur</p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>ğŸ¯ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajoutÃ©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajoutÃ© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>ğŸ‰ Checkpoint - CNN</h3>
        <p>
          FÃ©licitations ! Vous comprenez maintenant comment l'IA "voit" et
          analyse les images.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme complÃ©tÃ©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="backpropagation.html" class="nav-link" id="prev-link"
          >â† Module prÃ©cÃ©dent : Backpropagation</a
        >
        <a href="rnn.html" class="nav-link" id="next-link"
          >Module suivant : RNN/LSTM â†’</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module CNN
      const moduleConfig = {
        id: "dl-cnn",
        title: "CNN : RÃ©seaux de Neurones Convolutifs",
        category: "Deep Learning",
        objectives: [
          "Comprendre pourquoi les rÃ©seaux classiques Ã©chouent sur les images",
          "MaÃ®triser l'opÃ©ration de convolution mathÃ©matiquement",
          "Calculer manuellement convolutions et pooling",
          "Comprendre l'architecture hiÃ©rarchique des CNN",
          "ImplÃ©menter un CNN simple from scratch",
        ],
        content: [
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Le dÃ©fi impossible : comprendre les images",
            content: `
                        <p>Les <strong>images</strong> reprÃ©sentent le dÃ©fi le plus complexe pour l'IA : transformer des millions de pixels en comprÃ©hension sÃ©mantique. Les CNN ont rÃ©volutionnÃ© ce domaine en s'inspirant du systÃ¨me visuel humain.</p>
                        
                        <p><strong>ğŸ”‘ ProblÃ¨me fondamental :</strong></p>
                        <ul>
                            <li>ğŸ–¼ï¸ <strong>Image 224Ã—224 RGB</strong> = 224 Ã— 224 Ã— 3 = <strong>150 528 pixels</strong></li>
                            <li>ğŸ§  <strong>RÃ©seau classique</strong> = 150 528 neurones d'entrÃ©e</li>
                            <li>âš¡ <strong>PremiÃ¨re couche cachÃ©e (1000 neurones)</strong> = 150 millions de poids !</li>
                            <li>ğŸ’¥ <strong>RÃ©sultat</strong> : explosion combinatoire, surapprentissage garanti</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ RÃ©volution CNN :</strong></p>
                        <ul>
                            <li>ğŸ” <strong>LocalitÃ©</strong> : un pixel dÃ©pend de ses voisins, pas de pixels lointains</li>
                            <li>ğŸ”„ <strong>Partage de poids</strong> : mÃªme dÃ©tecteur utilisÃ© partout</li>
                            <li>ğŸ“ <strong>HiÃ©rarchie</strong> : contours â†’ formes â†’ objets â†’ scÃ¨nes</li>
                            <li>âš¡ <strong>EfficacitÃ©</strong> : millions de fois moins de paramÃ¨tres</li>
                        </ul>
                        
                        <p><strong>ğŸš€ Applications rÃ©volutionnaires :</strong></p>
                        <ul>
                            <li>ğŸ“± <strong>Reconnaissance faciale</strong> : dÃ©verrouillage tÃ©lÃ©phone</li>
                            <li>ğŸ¥ <strong>Diagnostic mÃ©dical</strong> : dÃ©tection cancer, COVID sur radios</li>
                            <li>ğŸš— <strong>Voitures autonomes</strong> : reconnaissance panneaux, piÃ©tons</li>
                            <li>ğŸ›¡ï¸ <strong>SÃ©curitÃ©</strong> : surveillance automatique, dÃ©tection d'intrusion</li>
                            <li>ğŸ¨ <strong>Art gÃ©nÃ©ratif</strong> : crÃ©ation d'images, style transfer</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Point clÃ© :</strong> Les CNN ne sont pas juste "des rÃ©seaux pour images" - ils reprÃ©sentent un <strong>changement de paradigme</strong> : exploiter la structure des donnÃ©es pour crÃ©er des architectures spÃ©cialisÃ©es.</p>
                    `,
          },
          {
            type: "intuition",
            icon: "ğŸ§ ",
            title: "L'analogie du systÃ¨me visuel humain",
            content: `
                        <p>Imaginez comment <strong>votre Å“il et votre cerveau</strong> reconnaissent un visage familier dans une foule :</p>
                        
                        <p><strong>ğŸ‘ï¸ Ã‰tape 1 - RÃ©tine (dÃ©tection de base) :</strong></p>
                        <ul>
                            <li>ğŸ” <strong>Cellules spÃ©cialisÃ©es</strong> : dÃ©tectent contours, coins, mouvements</li>
                            <li>ğŸ“ <strong>Champ rÃ©cepteur local</strong> : chaque cellule "voit" une petite zone</li>
                            <li>ğŸ”„ <strong>MÃªme dÃ©tecteur partout</strong> : dÃ©tecteur de contour vertical fonctionne partout</li>
                        </ul>
                        
                        <p><strong>ğŸ§  Ã‰tape 2 - Cortex visuel primaire (formes simples) :</strong></p>
                        <ul>
                            <li>ğŸ“ <strong>Combinaison de contours</strong> : lignes â†’ angles â†’ formes gÃ©omÃ©triques</li>
                            <li>ğŸ¯ <strong>Invariance position</strong> : triangle reconnu partout dans l'image</li>
                            <li>ğŸ“ <strong>RÃ©duction progressive</strong> : moins de dÃ©tails, plus d'abstraction</li>
                        </ul>
                        
                        <p><strong>ğŸ­ Ã‰tape 3 - Cortex visuel supÃ©rieur (objets) :</strong></p>
                        <ul>
                            <li>ğŸ‘ï¸ <strong>Yeux</strong> : 2 cercles + point central</li>
                            <li>ğŸ‘ƒ <strong>Nez</strong> : triangle + 2 points</li>
                            <li>ğŸ‘„ <strong>Bouche</strong> : ligne courbe horizontale</li>
                        </ul>
                        
                        <p><strong>ğŸ§  Ã‰tape 4 - Reconnaissance (concepts) :</strong></p>
                        <ul>
                            <li>ğŸ‘¤ <strong>Visage</strong> : yeux + nez + bouche dans la bonne configuration</li>
                            <li>ğŸ¯ <strong>IdentitÃ©</strong> : comparaison avec visages mÃ©morisÃ©s</li>
                            <li>âš¡ <strong>Reconnaissance</strong> : "C'est Aminata !" en 0.1 seconde</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ C'est exactement l'architecture CNN :</strong></p>
                        <ul>
                            <li>ğŸ” <strong>Convolution</strong> = dÃ©tecteurs de caractÃ©ristiques locales</li>
                            <li>ğŸ“ <strong>Pooling</strong> = rÃ©duction et invariance spatiale</li>
                            <li>ğŸ§  <strong>Couches profondes</strong> = concepts de plus en plus abstraits</li>
                            <li>ğŸ¯ <strong>Classification finale</strong> = dÃ©cision basÃ©e sur les concepts</li>
                        </ul>
                    `,
          },
          {
            type: "intuition",
            icon: "ğŸ§ ",
            title: "Qu'est-ce que la convolution ? L'analogie du tampon",
            content: `
                        <p>Imaginez que vous Ãªtes <strong>artisan textile Ã  Saint-Louis</strong> et que vous voulez dÃ©corer un tissu avec un motif rÃ©pÃ©titif :</p>
                        
                        <p><strong>ğŸ¨ Votre outil :</strong> Un petit tampon avec un motif gravÃ© (ex: Ã©toile)</p>
                        <p><strong>ğŸ§µ Votre tissu :</strong> Grande surface blanche Ã  dÃ©corer</p>
                        
                        <p><strong>ğŸ”„ Votre mÃ©thode :</strong></p>
                        <ol>
                            <li>ğŸ“ <strong>Positionner</strong> le tampon sur le coin du tissu</li>
                            <li>ğŸ¯ <strong>Appuyer</strong> pour imprimer le motif</li>
                            <li>â¡ï¸ <strong>DÃ©placer</strong> le tampon d'un cran vers la droite</li>
                            <li>ğŸ”„ <strong>RÃ©pÃ©ter</strong> jusqu'au bout de la ligne</li>
                            <li>â¬‡ï¸ <strong>Descendre</strong> d'une ligne et recommencer</li>
                        </ol>
                        
                        <p><strong>ğŸ’¡ C'est exactement la convolution !</strong></p>
                        <ul>
                            <li>ğŸ¨ <strong>Tampon</strong> = filtre/kernel (ex: 3Ã—3)</li>
                            <li>ğŸ§µ <strong>Tissu</strong> = image d'entrÃ©e</li>
                            <li>âœ¨ <strong>Motif imprimÃ©</strong> = feature map (carte de caractÃ©ristiques)</li>
                            <li>ğŸ”„ <strong>DÃ©placement systÃ©matique</strong> = convolution</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ DiffÃ©rents tampons = diffÃ©rents dÃ©tecteurs :</strong></p>
                        <ul>
                            <li>ğŸ“ <strong>Tampon "lignes verticales"</strong> â†’ dÃ©tecte les bords verticaux</li>
                            <li>ğŸ“ <strong>Tampon "lignes horizontales"</strong> â†’ dÃ©tecte les bords horizontaux</li>
                            <li>ğŸ” <strong>Tampon "coins"</strong> â†’ dÃ©tecte les angles</li>
                            <li>ğŸŒ€ <strong>Tampon "courbes"</strong> â†’ dÃ©tecte les formes arrondies</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Convolution manuelle : exemple 4Ã—4",
            content: `
                        <p><strong>ğŸ“ Exemple concret :</strong> DÃ©tection de contour vertical dans une image 4Ã—4</p>
                        
                        <p><strong>ğŸ–¼ï¸ Image d'entrÃ©e (noir=0, blanc=1) :</strong></p>
                        <div style="font-family: monospace; text-align: center; background: #f4f4f4; padding: 1rem; border-radius: 4px;">
                        $$\\text{Image} = \\begin{bmatrix} 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & 1 \\end{bmatrix}$$
                        </div>
                        <p><strong>InterprÃ©tation :</strong> MoitiÃ© gauche noire, moitiÃ© droite blanche â†’ contour vertical au milieu</p>
                        
                        <p><strong>ğŸ” Filtre dÃ©tecteur de contour vertical :</strong></p>
                        <div style="font-family: monospace; text-align: center; background: #e8f5e9; padding: 1rem; border-radius: 4px;">
                        $$\\text{Filtre} = \\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1 \\end{bmatrix}$$
                        </div>
                        <p><strong>Logique :</strong> -1 (gauche) + 1 (droite) = dÃ©tecte transition noirâ†’blanc</p>
                        
                        <p><strong>ğŸ”¢ Calcul position (0,0) :</strong></p>
                        <p>Superposer le filtre sur le coin supÃ©rieur gauche :</p>
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                        $$\\text{RÃ©sultat}_{0,0} = (-1)Ã—0 + 0Ã—0 + 1Ã—1 + (-1)Ã—0 + 0Ã—0 + 1Ã—1 + (-1)Ã—0 + 0Ã—0 + 1Ã—1$$
                        $$= 0 + 0 + 1 + 0 + 0 + 1 + 0 + 0 + 1 = 3$$
                        </div>
                        
                        <p><strong>ğŸ”¢ Calcul position (0,1) :</strong></p>
                        <p>DÃ©placer le filtre d'une case vers la droite :</p>
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                        $$\\text{RÃ©sultat}_{0,1} = (-1)Ã—0 + 0Ã—1 + 1Ã—1 + (-1)Ã—0 + 0Ã—1 + 1Ã—1 + (-1)Ã—0 + 0Ã—1 + 1Ã—1$$
                        $$= 0 + 0 + 1 + 0 + 0 + 1 + 0 + 0 + 1 = 3$$
                        </div>
                        
                        <p><strong>ğŸ¯ Feature map complÃ¨te (2Ã—2) :</strong></p>
                        <div style="font-family: monospace; text-align: center; background: #e8f5e9; padding: 1rem; border-radius: 4px;">
                        $$\\text{Feature Map} = \\begin{bmatrix} 3 & 3 \\\\ 3 & 3 \\end{bmatrix}$$
                        </div>
                        
                        <p><strong>ğŸ’¡ InterprÃ©tation :</strong> Valeurs Ã©levÃ©es (3) partout â†’ contour vertical dÃ©tectÃ© sur toute la hauteur ! Le filtre a parfaitement identifiÃ© la transition noirâ†’blanc.</p>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "L'opÃ©ration de convolution : formalisation rigoureuse",
            content: `
                        <p><strong>ğŸ“ DÃ©finition mathÃ©matique de la convolution 2D :</strong></p>
                        <p>Pour une image \\(I\\) et un filtre (kernel) \\(K\\) :</p>
                        <p>$$(I * K)(i, j) = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} I(i+m, j+n) \\cdot K(m, n)$$</p>
                        
                        <p><strong>ğŸ” DÃ©cryptage de la formule :</strong></p>
                        <ul>
                            <li>\\(I(i, j)\\) = <strong>valeur du pixel</strong> en position (i, j)</li>
                            <li>\\(K(m, n)\\) = <strong>poids du filtre</strong> en position (m, n)</li>
                            <li>\\(M \\times N\\) = <strong>taille du filtre</strong> (ex: 3Ã—3, 5Ã—5)</li>
                            <li>\\((I * K)(i, j)\\) = <strong>valeur de sortie</strong> aprÃ¨s convolution</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ InterprÃ©tation intuitive :</strong></p>
                        <p>La convolution <strong>glisse le filtre</strong> sur toute l'image et calcule Ã  chaque position le <strong>produit scalaire</strong> entre le filtre et la zone d'image correspondante.</p>
                        
                        <p><strong>ğŸ”§ ParamÃ¨tres de contrÃ´le :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ Stride (s) :</strong> pas de dÃ©placement du filtre</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Padding (p) :</strong> bordure ajoutÃ©e Ã  l'image</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ Taille de sortie :</strong> \\(\\frac{W - F + 2P}{S} + 1\\)</li>
                        </ul>
                        
                        <p><strong>ğŸ” OÃ¹ :</strong></p>
                        <ul>
                            <li>W = largeur d'entrÃ©e</li>
                            <li>F = taille du filtre</li>
                            <li>P = padding</li>
                            <li>S = stride</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ PropriÃ©tÃ©s fondamentales :</strong></p>
                        <ul>
                            <li>ğŸ”„ <strong>Partage de poids</strong> : mÃªme filtre appliquÃ© partout</li>
                            <li>ğŸ“ <strong>LocalitÃ© spatiale</strong> : connexions locales uniquement</li>
                            <li>ğŸ¯ <strong>Invariance par translation</strong> : dÃ©tecte la caractÃ©ristique oÃ¹ qu'elle soit</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Calcul manuel de convolution 3Ã—3",
            content: `
                        <p><strong>ğŸ“ Exemple concret :</strong> DÃ©tection de contours verticaux</p>
                        
                        <p><strong>ğŸ–¼ï¸ Image d'entrÃ©e 5Ã—5 (niveaux de gris) :</strong></p>
                        <p>$$I = \\begin{bmatrix} 
                        0 & 0 & 255 & 255 & 255 \\\\
                        0 & 0 & 255 & 255 & 255 \\\\
                        0 & 0 & 255 & 255 & 255 \\\\
                        0 & 0 & 255 & 255 & 255 \\\\
                        0 & 0 & 255 & 255 & 255
                        \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ” Filtre de dÃ©tection de contours verticaux 3Ã—3 :</strong></p>
                        <p>$$K = \\begin{bmatrix} 
                        -1 & 0 & 1 \\\\
                        -1 & 0 & 1 \\\\
                        -1 & 0 & 1
                        \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ”¢ Calcul position (1,1) :</strong></p>
                        <p>Zone d'image 3Ã—3 centrÃ©e en (1,1) :</p>
                        <p>$$\\begin{bmatrix} 0 & 0 & 255 \\\\ 0 & 0 & 255 \\\\ 0 & 0 & 255 \\end{bmatrix}$$</p>
                        
                        <p><strong>Produit Ã©lÃ©ment par Ã©lÃ©ment :</strong></p>
                        <p>$$(-1) \\times 0 + 0 \\times 0 + 1 \\times 255 + (-1) \\times 0 + 0 \\times 0 + 1 \\times 255 + (-1) \\times 0 + 0 \\times 0 + 1 \\times 255$$</p>
                        <p>$$= 0 + 0 + 255 + 0 + 0 + 255 + 0 + 0 + 255 = 765$$</p>
                        
                        <p><strong>ğŸ¯ RÃ©sultat complet (sortie 3Ã—3) :</strong></p>
                        <p>$$\\text{Sortie} = \\begin{bmatrix} 
                        765 & 765 & 765 \\\\
                        765 & 765 & 765 \\\\
                        765 & 765 & 765
                        \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ’¡ InterprÃ©tation :</strong> Valeur Ã©levÃ©e (765) = <strong>contour vertical dÃ©tectÃ©</strong> ! Le filtre a trouvÃ© la transition noirâ†’blanc.</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice pratique : convolution manuelle",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Appliquez le filtre de dÃ©tection de contours horizontaux sur cette image :</p>
                        
                        <p><strong>ğŸ–¼ï¸ Image 4Ã—4 :</strong></p>
                        <p>$$I = \\begin{bmatrix} 
                        100 & 100 & 100 & 100 \\\\
                        100 & 100 & 100 & 100 \\\\
                        200 & 200 & 200 & 200 \\\\
                        200 & 200 & 200 & 200
                        \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ” Filtre horizontal 3Ã—3 :</strong></p>
                        <p>$$K = \\begin{bmatrix} 
                        -1 & -1 & -1 \\\\
                        0 & 0 & 0 \\\\
                        1 & 1 & 1
                        \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Calculez :</strong></p>
                        <ol>
                            <li>La convolution en position (1,1)</li>
                            <li>La matrice de sortie complÃ¨te 2Ã—2</li>
                            <li>InterprÃ©tez le rÃ©sultat</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('convolution-manual-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="convolution-manual-exercise" style="display: none;">
                        <ol>
                            <li><strong>Position (1,1) :</strong><br>
                                Zone 3Ã—3 : \\(\\begin{bmatrix} 100 & 100 & 100 \\\\ 100 & 100 & 100 \\\\ 200 & 200 & 200 \\end{bmatrix}\\)<br>
                                Calcul : (-1)Ã—100 + (-1)Ã—100 + (-1)Ã—100 + 0Ã—100 + 0Ã—100 + 0Ã—100 + 1Ã—200 + 1Ã—200 + 1Ã—200<br>
                                = -300 + 0 + 600 = <strong>300</strong></li>
                            <li><strong>Sortie complÃ¨te :</strong><br>
                                Position (1,0) : 300<br>
                                Position (1,1) : 300<br>
                                Position (0,0) : 300<br>
                                Position (0,1) : 300<br>
                                Donc : \\(\\begin{bmatrix} 300 & 300 \\\\ 300 & 300 \\end{bmatrix}\\)</li>
                            <li><strong>InterprÃ©tation :</strong><br>
                                Valeur positive Ã©levÃ©e (300) = <strong>contour horizontal dÃ©tectÃ©</strong> !<br>
                                Le filtre a trouvÃ© la transition du haut (100) vers le bas (200).</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Pooling : rÃ©duction intelligente de l'information",
            content: `
                        <p><strong>ğŸ¤” Pourquoi rÃ©duire la taille des images ?</strong></p>
                        <p>Le <strong>pooling</strong> (mise en commun) rÃ©duit la taille spatiale tout en prÃ©servant l'information importante. C'est comme faire un rÃ©sumÃ© intelligent d'une image.</p>
                        
                        <p><strong>ğŸ¯ Objectifs du pooling :</strong></p>
                        <ul>
                            <li>ğŸ“ <strong>RÃ©duction de taille</strong> : moins de paramÃ¨tres, calculs plus rapides</li>
                            <li>ğŸ¯ <strong>Invariance spatiale</strong> : "chat en haut Ã  gauche" = "chat en bas Ã  droite"</li>
                            <li>ğŸ” <strong>Extraction d'essence</strong> : garder l'information importante</li>
                            <li>ğŸ›¡ï¸ <strong>Robustesse au bruit</strong> : petites variations ignorÃ©es</li>
                        </ul>
                        
                        <p><strong>ğŸ“ Types de pooling :</strong></p>
                        
                        <p><strong>1ï¸âƒ£ Max Pooling :</strong></p>
                        <p>$$\\text{MaxPool}(R) = \\max_{(i,j) \\in R} I(i,j)$$</p>
                        <p><strong>Principe :</strong> Prendre la valeur maximale dans chaque rÃ©gion</p>
                        
                        <p><strong>2ï¸âƒ£ Average Pooling :</strong></p>
                        <p>$$\\text{AvgPool}(R) = \\frac{1}{|R|} \\sum_{(i,j) \\in R} I(i,j)$$</p>
                        <p><strong>Principe :</strong> Prendre la moyenne dans chaque rÃ©gion</p>
                        
                        <p><strong>ğŸ’¡ Analogie du rÃ©sumÃ© :</strong></p>
                        <p>Imaginez rÃ©sumer un article de 1000 mots en 100 mots :</p>
                        <ul>
                            <li>ğŸ“° <strong>Max pooling</strong> : garder les phrases les plus importantes</li>
                            <li>ğŸ“Š <strong>Average pooling</strong> : faire la synthÃ¨se de chaque paragraphe</li>
                        </ul>
                        
                        <p><strong>ğŸ”§ ParamÃ¨tres typiques :</strong></p>
                        <ul>
                            <li><strong>Taille</strong> : 2Ã—2 (divise par 4 la taille)</li>
                            <li><strong>Stride</strong> : 2 (pas de chevauchement)</li>
                            <li><strong>Effet</strong> : image 224Ã—224 â†’ 112Ã—112</li>
                        </ul>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Calcul manuel de pooling",
            content: `
                        <p><strong>ğŸ“ Exemple concret :</strong> Max pooling 2Ã—2 sur une feature map</p>
                        
                        <p><strong>ğŸ–¼ï¸ Feature map d'entrÃ©e 4Ã—4 :</strong></p>
                        <p>$$\\text{Input} = \\begin{bmatrix} 
                        1 & 3 & 2 & 4 \\\\
                        5 & 6 & 1 & 2 \\\\
                        2 & 1 & 8 & 3 \\\\
                        4 & 2 & 1 & 7
                        \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ”¢ Max pooling 2Ã—2 avec stride 2 :</strong></p>
                        
                        <p><strong>RÃ©gion 1 (haut-gauche) :</strong></p>
                        <p>$$\\begin{bmatrix} 1 & 3 \\\\ 5 & 6 \\end{bmatrix} \\rightarrow \\max(1, 3, 5, 6) = 6$$</p>
                        
                        <p><strong>RÃ©gion 2 (haut-droite) :</strong></p>
                        <p>$$\\begin{bmatrix} 2 & 4 \\\\ 1 & 2 \\end{bmatrix} \\rightarrow \\max(2, 4, 1, 2) = 4$$</p>
                        
                        <p><strong>RÃ©gion 3 (bas-gauche) :</strong></p>
                        <p>$$\\begin{bmatrix} 2 & 1 \\\\ 4 & 2 \\end{bmatrix} \\rightarrow \\max(2, 1, 4, 2) = 4$$</p>
                        
                        <p><strong>RÃ©gion 4 (bas-droite) :</strong></p>
                        <p>$$\\begin{bmatrix} 8 & 3 \\\\ 1 & 7 \\end{bmatrix} \\rightarrow \\max(8, 3, 1, 7) = 8$$</p>
                        
                        <p><strong>ğŸ¯ RÃ©sultat final 2Ã—2 :</strong></p>
                        <p>$$\\text{Output} = \\begin{bmatrix} 6 & 4 \\\\ 4 & 8 \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ’¡ Observation :</strong> Taille divisÃ©e par 4 (16 â†’ 4 Ã©lÃ©ments), mais les valeurs importantes (6, 8) sont prÃ©servÃ©es !</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : pooling comparatif",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Comparez Max pooling vs Average pooling sur cette feature map :</p>
                        
                        <p><strong>ğŸ–¼ï¸ Feature map 4Ã—4 :</strong></p>
                        <p>$$\\text{Input} = \\begin{bmatrix} 
                        10 & 2 & 8 & 1 \\\\
                        3 & 15 & 4 & 6 \\\\
                        7 & 1 & 12 & 2 \\\\
                        5 & 9 & 3 & 14
                        \\end{bmatrix}$$</p>
                        
                        <p><strong>ğŸ“ Calculez :</strong></p>
                        <ol>
                            <li>Max pooling 2Ã—2 avec stride 2</li>
                            <li>Average pooling 2Ã—2 avec stride 2</li>
                            <li>Quelle mÃ©thode prÃ©serve mieux les pics d'activation ?</li>
                            <li>Quelle mÃ©thode est plus robuste au bruit ?</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('pooling-comparison-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="pooling-comparison-exercise" style="display: none;">
                        <ol>
                            <li><strong>Max pooling :</strong><br>
                                RÃ©gion 1: max(10,2,3,15) = 15<br>
                                RÃ©gion 2: max(8,1,4,6) = 8<br>
                                RÃ©gion 3: max(7,1,5,9) = 9<br>
                                RÃ©gion 4: max(12,2,3,14) = 14<br>
                                RÃ©sultat: \\(\\begin{bmatrix} 15 & 8 \\\\ 9 & 14 \\end{bmatrix}\\)</li>
                            <li><strong>Average pooling :</strong><br>
                                RÃ©gion 1: (10+2+3+15)/4 = 7.5<br>
                                RÃ©gion 2: (8+1+4+6)/4 = 4.75<br>
                                RÃ©gion 3: (7+1+5+9)/4 = 5.5<br>
                                RÃ©gion 4: (12+2+3+14)/4 = 7.75<br>
                                RÃ©sultat: \\(\\begin{bmatrix} 7.5 & 4.75 \\\\ 5.5 & 7.75 \\end{bmatrix}\\)</li>
                            <li><strong>PrÃ©servation des pics :</strong> <strong>Max pooling</strong> (15 vs 7.5)</li>
                            <li><strong>Robustesse au bruit :</strong> <strong>Average pooling</strong> (lisse les variations)</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Architecture CNN complÃ¨te : formalisation",
            content: `
                        <p><strong>ğŸ—ï¸ Architecture typique d'un CNN :</strong></p>
                        <p>$$\\text{Image} \\xrightarrow{\\text{Conv}} \\text{Feature Maps} \\xrightarrow{\\text{Pool}} \\text{RÃ©duction} \\xrightarrow{\\text{Conv}} \\text{Features} \\xrightarrow{\\text{FC}} \\text{Classification}$$</p>
                        
                        <p><strong>ğŸ“ Ã‰volution des dimensions :</strong></p>
                        <table style="width: 100%; border-collapse: collapse; margin: 1rem 0;">
                            <tr style="background: #f8f9fa;">
                                <th style="padding: 0.8rem; border: 1px solid #dee2e6;">Couche</th>
                                <th style="padding: 0.8rem; border: 1px solid #dee2e6;">OpÃ©ration</th>
                                <th style="padding: 0.8rem; border: 1px solid #dee2e6;">Taille</th>
                                <th style="padding: 0.8rem; border: 1px solid #dee2e6;">ParamÃ¨tres</th>
                            </tr>
                            <tr>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">EntrÃ©e</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Image RGB</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">224Ã—224Ã—3</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">0</td>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Conv1</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">32 filtres 3Ã—3</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">224Ã—224Ã—32</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">896</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Pool1</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Max pool 2Ã—2</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">112Ã—112Ã—32</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">0</td>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Conv2</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">64 filtres 3Ã—3</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">112Ã—112Ã—64</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">18 496</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Pool2</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Max pool 2Ã—2</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">56Ã—56Ã—64</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">0</td>
                            </tr>
                            <tr style="background: #f8f9fa;">
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Flatten</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Vectorisation</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">200 704Ã—1</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">0</td>
                            </tr>
                            <tr>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">FC</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">Dense 1000</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">1000Ã—1</td>
                                <td style="padding: 0.8rem; border: 1px solid #dee2e6;">200M</td>
                            </tr>
                        </table>
                        
                        <p><strong>ğŸ” Calcul des paramÃ¨tres :</strong></p>
                        <ul>
                            <li><strong>Conv1 :</strong> (3Ã—3Ã—3 + 1) Ã— 32 = 896 paramÃ¨tres</li>
                            <li><strong>Conv2 :</strong> (3Ã—3Ã—32 + 1) Ã— 64 = 18 496 paramÃ¨tres</li>
                            <li><strong>FC :</strong> (200 704 + 1) Ã— 1000 = 200M paramÃ¨tres</li>
                        </ul>
                        
                        <p><strong>âš ï¸ Observation cruciale :</strong> 99% des paramÃ¨tres sont dans les couches fully connected ! C'est pourquoi les architectures modernes minimisent ces couches.</p>
                    `,
          },
          {
            type: "code",
            title: "ImplÃ©mentation convolution from scratch",
            description: "ImplÃ©mentons l'opÃ©ration de convolution :",
            code: `import numpy as np
import matplotlib.pyplot as plt

class Convolution2D:
    """ImplÃ©mentation de la convolution 2D from scratch"""
    
    def __init__(self, nb_filtres, taille_filtre, stride=1, padding=0):
        self.nb_filtres = nb_filtres
        self.taille_filtre = taille_filtre
        self.stride = stride
        self.padding = padding
        
        # Initialisation des filtres (Xavier)
        limite = np.sqrt(6 / (taille_filtre * taille_filtre))
        self.filtres = np.random.uniform(-limite, limite, 
                                       (nb_filtres, taille_filtre, taille_filtre))
        self.biais = np.zeros(nb_filtres)
        
        print(f"ğŸ” Couche convolutive crÃ©Ã©e:")
        print(f"   {nb_filtres} filtres {taille_filtre}Ã—{taille_filtre}")
        print(f"   Stride: {stride}, Padding: {padding}")
    
    def ajouter_padding(self, image):
        """Ajoute du padding autour de l'image"""
        if self.padding == 0:
            return image
        return np.pad(image, self.padding, mode='constant', constant_values=0)
    
    def convolution_simple(self, image, filtre):
        """Convolution d'une image avec un seul filtre"""
        h_img, w_img = image.shape
        h_filtre, w_filtre = filtre.shape
        
        # Taille de sortie
        h_out = (h_img - h_filtre) // self.stride + 1
        w_out = (w_img - w_filtre) // self.stride + 1
        
        sortie = np.zeros((h_out, w_out))
        
        for i in range(h_out):
            for j in range(w_out):
                # Position dans l'image originale
                start_i = i * self.stride
                start_j = j * self.stride
                
                # Extraction de la rÃ©gion
                region = image[start_i:start_i + h_filtre, start_j:start_j + w_filtre]
                
                # Produit scalaire (convolution)
                sortie[i, j] = np.sum(region * filtre)
        
        return sortie
    
    def forward(self, image):
        """Propagation avant complÃ¨te"""
        # Ajouter padding si nÃ©cessaire
        image_paddee = self.ajouter_padding(image)
        
        # Appliquer chaque filtre
        sorties = []
        for i, filtre in enumerate(self.filtres):
            feature_map = self.convolution_simple(image_paddee, filtre) + self.biais[i]
            sorties.append(feature_map)
        
        return np.array(sorties)

# Test avec une image simple
print("ğŸ–¼ï¸ TEST CONVOLUTION SUR IMAGE SYNTHÃ‰TIQUE")
print("=" * 45)

# CrÃ©ation d'une image test 6Ã—6 avec un motif
image_test = np.array([
    [0, 0, 0, 255, 255, 255],
    [0, 0, 0, 255, 255, 255],
    [0, 0, 0, 255, 255, 255],
    [0, 0, 0, 255, 255, 255],
    [0, 0, 0, 255, 255, 255],
    [0, 0, 0, 255, 255, 255]
])

print("Image d'entrÃ©e (transition noirâ†’blanc):")
print(image_test)

# CrÃ©ation de filtres spÃ©cialisÃ©s
conv_layer = Convolution2D(nb_filtres=3, taille_filtre=3, stride=1, padding=0)

# Filtres manuels pour dÃ©monstration
conv_layer.filtres[0] = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])  # Contours verticaux
conv_layer.filtres[1] = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])  # Contours horizontaux
conv_layer.filtres[2] = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9  # Lissage

print(f"\nğŸ” Filtres utilisÃ©s:")
print("Filtre 1 (contours verticaux):")
print(conv_layer.filtres[0])
print("Filtre 2 (contours horizontaux):")
print(conv_layer.filtres[1])
print("Filtre 3 (lissage):")
print(conv_layer.filtres[2])

# Application des filtres
feature_maps = conv_layer.forward(image_test)

print(f"\nğŸ“Š RÃ©sultats convolution:")
for i, fm in enumerate(feature_maps):
    print(f"\nFeature map {i+1}:")
    print(fm.round(1))`,
          },
          {
            type: "code",
            title: "ImplÃ©mentation pooling",
            description: "Ajoutons les opÃ©rations de pooling :",
            code: `class MaxPooling2D:
    """ImplÃ©mentation du max pooling 2D"""
    
    def __init__(self, taille_pool=2, stride=2):
        self.taille_pool = taille_pool
        self.stride = stride
        print(f"ğŸŠ Max pooling {taille_pool}Ã—{taille_pool}, stride {stride}")
    
    def forward(self, feature_maps):
        """Applique max pooling Ã  toutes les feature maps"""
        nb_maps, h_in, w_in = feature_maps.shape
        
        # Calcul taille de sortie
        h_out = (h_in - self.taille_pool) // self.stride + 1
        w_out = (w_in - self.taille_pool) // self.stride + 1
        
        sortie = np.zeros((nb_maps, h_out, w_out))
        
        for map_idx in range(nb_maps):
            for i in range(h_out):
                for j in range(w_out):
                    # Position dans la feature map
                    start_i = i * self.stride
                    start_j = j * self.stride
                    
                    # Extraction de la rÃ©gion
                    region = feature_maps[map_idx, 
                                        start_i:start_i + self.taille_pool,
                                        start_j:start_j + self.taille_pool]
                    
                    # Max pooling
                    sortie[map_idx, i, j] = np.max(region)
        
        return sortie

# Test du pooling
pooling_layer = MaxPooling2D(taille_pool=2, stride=2)
feature_maps_pooled = pooling_layer.forward(feature_maps)

print(f"\nğŸŠ RÃ‰SULTATS APRÃˆS POOLING:")
print(f"Taille avant pooling: {feature_maps.shape}")
print(f"Taille aprÃ¨s pooling: {feature_maps_pooled.shape}")

for i, fm in enumerate(feature_maps_pooled):
    print(f"\nFeature map {i+1} aprÃ¨s pooling:")
    print(fm.round(1))`,
          },
          {
            type: "code",
            title: "Visualisation des feature maps",
            description: "Visualisons l'effet des convolutions :",
            code: `# Visualisation complÃ¨te du processus
fig, axes = plt.subplots(3, 4, figsize=(16, 12))

# Image originale
axes[0, 0].imshow(image_test, cmap='gray')
axes[0, 0].set_title('Image Originale')
axes[0, 0].axis('off')

# Filtres
for i in range(3):
    axes[0, i+1].imshow(conv_layer.filtres[i], cmap='RdBu', vmin=-1, vmax=1)
    axes[0, i+1].set_title(f'Filtre {i+1}')
    axes[0, i+1].axis('off')

# Feature maps aprÃ¨s convolution
for i in range(3):
    axes[1, i].imshow(feature_maps[i], cmap='viridis')
    axes[1, i].set_title(f'Feature Map {i+1}\\n(aprÃ¨s conv)')
    axes[1, i].axis('off')

# Feature maps aprÃ¨s pooling
for i in range(3):
    axes[2, i].imshow(feature_maps_pooled[i], cmap='viridis')
    axes[2, i].set_title(f'Feature Map {i+1}\\n(aprÃ¨s pooling)')
    axes[2, i].axis('off')

# Masquer les axes inutilisÃ©s
axes[1, 3].axis('off')
axes[2, 3].axis('off')

plt.suptitle('Pipeline CNN: Image â†’ Convolution â†’ Pooling', fontsize=16)
plt.tight_layout()
plt.show()

print("ğŸ¨ Visualisation du pipeline CNN terminÃ©e !")`,
          },
          {
            type: "code",
            title: "CNN complet pour classification",
            description: "Assemblons tout pour crÃ©er un CNN complet :",
            code: `class CNNSimple:
    """CNN simple pour classification d'images"""
    
    def __init__(self):
        # Architecture: Conv â†’ Pool â†’ Conv â†’ Pool â†’ FC
        self.conv1 = Convolution2D(nb_filtres=4, taille_filtre=3, stride=1, padding=1)
        self.pool1 = MaxPooling2D(taille_pool=2, stride=2)
        self.conv2 = Convolution2D(nb_filtres=8, taille_filtre=3, stride=1, padding=1)
        self.pool2 = MaxPooling2D(taille_pool=2, stride=2)
        
        print("ğŸ§  CNN Simple crÃ©Ã©:")
        print("   Conv1: 4 filtres 3Ã—3 â†’ Pool 2Ã—2")
        print("   Conv2: 8 filtres 3Ã—3 â†’ Pool 2Ã—2")
        print("   FC: Classification finale")
    
    def relu(self, x):
        """Fonction d'activation ReLU"""
        return np.maximum(0, x)
    
    def forward(self, image):
        """Propagation avant complÃ¨te"""
        print(f"ğŸ“Š Propagation avant - Image {image.shape}")
        
        # PremiÃ¨re couche convolutive + activation
        conv1_out = self.conv1.forward(image)
        conv1_activated = self.relu(conv1_out)
        print(f"   AprÃ¨s Conv1 + ReLU: {conv1_activated.shape}")
        
        # Premier pooling
        pool1_out = self.pool1.forward(conv1_activated)
        print(f"   AprÃ¨s Pool1: {pool1_out.shape}")
        
        # DeuxiÃ¨me couche convolutive + activation
        # Adapter les filtres pour la nouvelle profondeur
        if self.conv2.filtres.shape[1] != pool1_out.shape[0]:
            # RÃ©initialiser conv2 avec la bonne profondeur
            profondeur = pool1_out.shape[0]
            limite = np.sqrt(6 / (3 * 3 * profondeur))
            self.conv2.filtres = np.random.uniform(-limite, limite, 
                                                 (8, profondeur, 3, 3))
        
        # Pour simplifier, on fait une convolution sur chaque canal sÃ©parÃ©ment
        conv2_results = []
        for canal in range(pool1_out.shape[0]):
            for filtre_idx in range(self.conv2.nb_filtres):
                if filtre_idx < len(self.conv2.filtres):
                    # Utiliser le premier canal du filtre
                    filtre_2d = self.conv2.filtres[filtre_idx, 0, :, :]
                    result = self.conv2.convolution_simple(pool1_out[canal], filtre_2d)
                    conv2_results.append(result)
                    if len(conv2_results) >= 8:  # Limiter Ã  8 feature maps
                        break
            if len(conv2_results) >= 8:
                break
        
        conv2_out = np.array(conv2_results[:8])
        conv2_activated = self.relu(conv2_out)
        print(f"   AprÃ¨s Conv2 + ReLU: {conv2_activated.shape}")
        
        # DeuxiÃ¨me pooling
        pool2_out = self.pool2.forward(conv2_activated)
        print(f"   AprÃ¨s Pool2: {pool2_out.shape}")
        
        # Aplatissement pour couche dense
        flattened = pool2_out.flatten()
        print(f"   AprÃ¨s Flatten: {flattened.shape}")
        
        return flattened, {
            'conv1': conv1_activated,
            'pool1': pool1_out,
            'conv2': conv2_activated,
            'pool2': pool2_out
        }

# Test du CNN complet
print("ğŸ§  TEST CNN COMPLET")
print("=" * 30)

# Image test plus grande
image_grande = np.random.randint(0, 256, (8, 8))
print(f"Image test: {image_grande.shape}")

# CrÃ©ation et test du CNN
cnn = CNNSimple()
sortie_finale, intermediaires = cnn.forward(image_grande)

print(f"\nğŸ¯ Sortie finale: {sortie_finale.shape}")
print(f"ğŸ“Š PrÃªte pour classification avec {len(sortie_finale)} features")`,
          },
          {
            type: "code",
            title: "Filtres classiques de vision",
            description: "DÃ©couvrons les filtres fondamentaux de la vision :",
            code: `# Filtres classiques en vision par ordinateur
filtres_classiques = {
    'Sobel Vertical': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),
    'Sobel Horizontal': np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),
    'Laplacien': np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]]),
    'Gaussien': np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16,
    'DÃ©tection coins': np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]),
    'NettetÃ©': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
}

# Image test avec diffÃ©rents motifs
image_complexe = np.array([
    [50,  50,  50, 200, 200, 200],
    [50,  50,  50, 200, 200, 200],
    [50,  50,  50, 200, 200, 200],
    [100, 100, 100, 150, 150, 150],
    [100, 100, 100, 150, 150, 150],
    [100, 100, 100, 150, 150, 150]
])

print("ğŸ” APPLICATION DES FILTRES CLASSIQUES")
print("=" * 40)
print("Image test (motifs gÃ©omÃ©triques):")
print(image_complexe)

# Test de chaque filtre
conv_test = Convolution2D(nb_filtres=1, taille_filtre=3)

for nom, filtre in filtres_classiques.items():
    conv_test.filtres[0] = filtre
    resultat = conv_test.convolution_simple(image_complexe, filtre)
    
    print(f"\n{nom}:")
    print(f"Filtre:")
    print(filtre)
    print(f"RÃ©sultat:")
    print(resultat.round(1))`,
          },
          {
            type: "code",
            title: "Visualisation des filtres appris",
            description:
              "Visualisons comment les filtres dÃ©tectent diffÃ©rentes caractÃ©ristiques :",
            code: `# Simulation de filtres appris par un CNN rÃ©el
def generer_filtres_realistes():
    """GÃ©nÃ¨re des filtres similaires Ã  ceux appris par de vrais CNN"""
    
    # Filtre dÃ©tecteur de contours diagonaux
    diag1 = np.array([[1, 0, -1], [0, 0, 0], [-1, 0, 1]])
    
    # Filtre dÃ©tecteur de textures
    texture = np.array([[1, -1, 1], [-1, 1, -1], [1, -1, 1]])
    
    # Filtre passe-bas (lissage)
    lissage = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9
    
    # Filtre dÃ©tecteur de coins
    coins = np.array([[-1, -1, 0], [-1, 0, 1], [0, 1, 1]])
    
    return [diag1, texture, lissage, coins]

# Visualisation des filtres et leurs effets
filtres_realistes = generer_filtres_realistes()
noms_filtres = ['Diagonales', 'Textures', 'Lissage', 'Coins']

fig, axes = plt.subplots(2, 4, figsize=(16, 8))

# Ligne 1: Filtres
for i, (filtre, nom) in enumerate(zip(filtres_realistes, noms_filtres)):
    im = axes[0, i].imshow(filtre, cmap='RdBu', vmin=-1, vmax=1)
    axes[0, i].set_title(f'Filtre: {nom}')
    axes[0, i].axis('off')
    plt.colorbar(im, ax=axes[0, i], fraction=0.046)

# Ligne 2: RÃ©sultats sur image complexe
conv_demo = Convolution2D(nb_filtres=1, taille_filtre=3)

for i, (filtre, nom) in enumerate(zip(filtres_realistes, noms_filtres)):
    resultat = conv_demo.convolution_simple(image_complexe, filtre)
    im = axes[1, i].imshow(resultat, cmap='viridis')
    axes[1, i].set_title(f'RÃ©sultat: {nom}')
    axes[1, i].axis('off')
    plt.colorbar(im, ax=axes[1, i], fraction=0.046)

plt.suptitle('Filtres CNN et leurs Effets', fontsize=16)
plt.tight_layout()
plt.show()

print("ğŸ¨ Visualisation des filtres terminÃ©e !")`,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : architecture CNN pour MNIST",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Concevez un CNN pour classifier des chiffres manuscrits (MNIST) :</p>
                        
                        <p><strong>ğŸ“Š Contraintes :</strong></p>
                        <ul>
                            <li>Images d'entrÃ©e : 28Ã—28Ã—1 (niveaux de gris)</li>
                            <li>10 classes de sortie (chiffres 0-9)</li>
                            <li>Budget : maximum 100 000 paramÃ¨tres</li>
                            <li>PrÃ©cision cible : >95%</li>
                        </ul>
                        
                        <p><strong>ğŸ“ Concevez :</strong></p>
                        <ol>
                            <li>Architecture complÃ¨te (couches, tailles, activations)</li>
                            <li>Calcul du nombre de paramÃ¨tres</li>
                            <li>Justification de chaque choix</li>
                            <li>Taille des feature maps Ã  chaque Ã©tape</li>
                        </ol>
                        
                        <p><strong>âœ… Solution :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('cnn-mnist-architecture')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="cnn-mnist-architecture" style="display: none;">
                        <p><strong>ğŸ—ï¸ Architecture proposÃ©e :</strong></p>
                        <ol>
                            <li><strong>Conv1 :</strong> 16 filtres 3Ã—3, ReLU â†’ 28Ã—28Ã—16</li>
                            <li><strong>Pool1 :</strong> Max pool 2Ã—2 â†’ 14Ã—14Ã—16</li>
                            <li><strong>Conv2 :</strong> 32 filtres 3Ã—3, ReLU â†’ 14Ã—14Ã—32</li>
                            <li><strong>Pool2 :</strong> Max pool 2Ã—2 â†’ 7Ã—7Ã—32</li>
                            <li><strong>Flatten :</strong> â†’ 1568 neurones</li>
                            <li><strong>FC1 :</strong> 128 neurones, ReLU</li>
                            <li><strong>FC2 :</strong> 10 neurones, Softmax</li>
                        </ol>
                        
                        <p><strong>ğŸ“Š Calcul des paramÃ¨tres :</strong></p>
                        <ul>
                            <li>Conv1: (3Ã—3Ã—1 + 1) Ã— 16 = 160</li>
                            <li>Conv2: (3Ã—3Ã—16 + 1) Ã— 32 = 4 640</li>
                            <li>FC1: (1568 + 1) Ã— 128 = 200 832</li>
                            <li>FC2: (128 + 1) Ã— 10 = 1 290</li>
                            <li><strong>Total: 206 922 paramÃ¨tres</strong> (dÃ©passe le budget !)</li>
                        </ul>
                        
                        <p><strong>ğŸ”§ Optimisation :</strong></p>
                        <p>RÃ©duire FC1 Ã  64 neurones â†’ Total: 106 602 paramÃ¨tres âœ“</p>
                        </div>
                    `,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "HiÃ©rarchie des caractÃ©ristiques : du pixel au concept",
            content: `
                        <p><strong>ğŸ§  Les CNN apprennent une hiÃ©rarchie naturelle de concepts :</strong></p>
                        
                        <p><strong>ğŸ” Couche 1 - DÃ©tecteurs primitifs :</strong></p>
                        <ul>
                            <li>ğŸ“ <strong>Contours</strong> : lignes verticales, horizontales, diagonales</li>
                            <li>ğŸ”µ <strong>Formes simples</strong> : coins, courbes, points</li>
                            <li>ğŸŒˆ <strong>Couleurs</strong> : transitions de couleurs, gradients</li>
                            <li>ğŸ“ <strong>Textures</strong> : motifs rÃ©pÃ©titifs de base</li>
                        </ul>
                        
                        <p><strong>ğŸ” Couche 2 - Combinaisons locales :</strong></p>
                        <ul>
                            <li>ğŸ‘ï¸ <strong>Formes gÃ©omÃ©triques</strong> : triangles, cercles, rectangles</li>
                            <li>ğŸ¨ <strong>Motifs</strong> : rayures, damiers, spirales</li>
                            <li>ğŸ“ <strong>Jonctions</strong> : T, L, X, Y</li>
                            <li>ğŸ”„ <strong>SymÃ©tries</strong> : patterns symÃ©triques</li>
                        </ul>
                        
                        <p><strong>ğŸ” Couche 3 - Parties d'objets :</strong></p>
                        <ul>
                            <li>ğŸ‘ï¸ <strong>Yeux</strong> : cercle + pupille + cils</li>
                            <li>ğŸš— <strong>Roues</strong> : cercle + rayons + pneu</li>
                            <li>ğŸ  <strong>FenÃªtres</strong> : rectangle + croisillons</li>
                            <li>ğŸŒ³ <strong>Feuilles</strong> : forme ovale + nervures</li>
                        </ul>
                        
                        <p><strong>ğŸ” Couche 4 - Objets complets :</strong></p>
                        <ul>
                            <li>ğŸ‘¤ <strong>Visages</strong> : yeux + nez + bouche dans la bonne configuration</li>
                            <li>ğŸš— <strong>Voitures</strong> : carrosserie + roues + phares</li>
                            <li>ğŸ  <strong>Maisons</strong> : murs + toit + fenÃªtres + porte</li>
                            <li>ğŸ• <strong>Animaux</strong> : corps + pattes + tÃªte + queue</li>
                        </ul>
                        
                        <p><strong>ğŸ” Couche 5 - ScÃ¨nes et contextes :</strong></p>
                        <ul>
                            <li>ğŸ–ï¸ <strong>Plage</strong> : sable + mer + palmiers + personnes</li>
                            <li>ğŸ™ï¸ <strong>Ville</strong> : bÃ¢timents + routes + voitures + foule</li>
                            <li>ğŸŒ³ <strong>ForÃªt</strong> : arbres + vÃ©gÃ©tation + chemins</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Ã‰mergence spontanÃ©e :</strong></p>
                        <p>Cette hiÃ©rarchie <strong>Ã©merge automatiquement</strong> pendant l'entraÃ®nement ! Le CNN dÃ©couvre seul que pour reconnaÃ®tre un visage, il faut d'abord dÃ©tecter des contours, puis des yeux, puis assembler le tout.</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice : analyse de rÃ©ceptive field",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Calculez le <strong>champ rÃ©cepteur</strong> (receptive field) d'un neurone dans un CNN :</p>
                        
                        <p><strong>ğŸ—ï¸ Architecture :</strong></p>
                        <ol>
                            <li>Conv1: filtre 3Ã—3, stride 1, padding 0</li>
                            <li>Pool1: 2Ã—2, stride 2</li>
                            <li>Conv2: filtre 3Ã—3, stride 1, padding 0</li>
                            <li>Pool2: 2Ã—2, stride 2</li>
                        </ol>
                        
                        <p><strong>ğŸ“ Questions :</strong></p>
                        <ol>
                            <li>Quelle zone de l'image originale influence un neurone aprÃ¨s Conv1 ?</li>
                            <li>Et aprÃ¨s Pool1 ?</li>
                            <li>Et aprÃ¨s Conv2 ?</li>
                            <li>Champ rÃ©cepteur final aprÃ¨s Pool2 ?</li>
                        </ol>
                        
                        <p><strong>âœ… Solution :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('receptive-field-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="receptive-field-exercise" style="display: none;">
                        <ol>
                            <li><strong>AprÃ¨s Conv1 :</strong> 3Ã—3 pixels<br>
                                <em>Chaque neurone voit une zone 3Ã—3 de l'image originale</em></li>
                            <li><strong>AprÃ¨s Pool1 :</strong> 6Ã—6 pixels<br>
                                <em>Pool 2Ã—2 avec stride 2 double le champ rÃ©cepteur</em></li>
                            <li><strong>AprÃ¨s Conv2 :</strong> 10Ã—10 pixels<br>
                                <em>Filtre 3Ã—3 ajoute 2 pixels de chaque cÃ´tÃ© : 6+2+2 = 10</em></li>
                            <li><strong>AprÃ¨s Pool2 :</strong> 20Ã—20 pixels<br>
                                <em>Pool 2Ã—2 avec stride 2 double encore : 10Ã—2 = 20</em></li>
                        </ol>
                        <p><strong>ğŸ’¡ Conclusion :</strong> Un neurone en sortie "voit" une zone 20Ã—20 de l'image originale. Plus le rÃ©seau est profond, plus le champ rÃ©cepteur grandit !</p>
                        </div>
                    `,
          },
          {
            type: "warning",
            icon: "âš ï¸",
            title: "CNN : rÃ©volution de la vision par ordinateur",
            content: `
                        <p><strong>ğŸš€ Les CNN ont rÃ©volutionnÃ© notre monde numÃ©rique :</strong></p>
                        
                        <p><strong>ğŸ“± Applications quotidiennes :</strong></p>
                        <ul>
                            <li>ğŸ“¸ <strong>Photos</strong> : reconnaissance automatique de visages, objets, scÃ¨nes</li>
                            <li>ğŸ”’ <strong>SÃ©curitÃ©</strong> : dÃ©verrouillage facial, surveillance intelligente</li>
                            <li>ğŸš— <strong>Transport</strong> : voitures autonomes, reconnaissance de panneaux</li>
                            <li>ğŸ›’ <strong>Commerce</strong> : recherche visuelle, rÃ©alitÃ© augmentÃ©e</li>
                            <li>ğŸ® <strong>Divertissement</strong> : filtres Instagram, effets spÃ©ciaux</li>
                        </ul>
                        
                        <p><strong>ğŸ¥ Impact mÃ©dical rÃ©volutionnaire :</strong></p>
                        <ul>
                            <li>ğŸ©» <strong>Radiologie</strong> : dÃ©tection cancer plus prÃ©cise que les humains</li>
                            <li>ğŸ‘ï¸ <strong>Ophtalmologie</strong> : diagnostic rÃ©tinopathie diabÃ©tique</li>
                            <li>ğŸ§  <strong>Neurologie</strong> : analyse IRM, dÃ©tection AVC</li>
                            <li>ğŸ”¬ <strong>Pathologie</strong> : analyse automatique de biopsies</li>
                        </ul>
                        
                        <p><strong>ğŸŒ Applications au SÃ©nÃ©gal :</strong></p>
                        <ul>
                            <li>ğŸŒ¾ <strong>Agriculture</strong> : surveillance des cultures par satellite</li>
                            <li>ğŸ¥ <strong>TÃ©lÃ©mÃ©decine</strong> : diagnostic Ã  distance dans les zones rurales</li>
                            <li>ğŸ›¡ï¸ <strong>SÃ©curitÃ©</strong> : surveillance des frontiÃ¨res, ports</li>
                            <li>ğŸ“š <strong>Ã‰ducation</strong> : numÃ©risation et reconnaissance de documents</li>
                            <li>ğŸŒŠ <strong>Environnement</strong> : surveillance cÃ´tiÃ¨re, dÃ©forestation</li>
                        </ul>
                        
                        <p><strong>ğŸ”® Ã‰volution vers l'avenir :</strong></p>
                        <ul>
                            <li>ğŸ§  <strong>Vision Transformers</strong> : remplacent progressivement les CNN</li>
                            <li>ğŸ¯ <strong>Architectures hybrides</strong> : CNN + Attention pour le meilleur des deux</li>
                            <li>âš¡ <strong>EfficacitÃ©</strong> : MobileNets, EfficientNets pour mobile</li>
                            <li>ğŸ¨ <strong>GÃ©nÃ©ration</strong> : GANs, Diffusion Models pour crÃ©er des images</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Point clÃ© :</strong> Les CNN ont prouvÃ© qu'en s'inspirant de la biologie (cortex visuel), on peut crÃ©er des systÃ¨mes artificiels qui surpassent les humains dans certaines tÃ¢ches visuelles. C'est la puissance de l'<strong>architecture spÃ©cialisÃ©e</strong> !</p>
                        
                        <p><strong>ğŸ”® Prochaine Ã©tape :</strong> RNN/LSTM - l'architecture pour comprendre les sÃ©quences et le temps !</p>
                    `,
          },
        ],
        quiz: {
          question:
            "ğŸ¤” Pourquoi utilise-t-on le partage de poids (weight sharing) dans les CNN ?",
          options: [
            "A) Pour rÃ©duire le temps de calcul",
            "B) Pour dÃ©tecter la mÃªme caractÃ©ristique partout dans l'image",
            "C) Pour Ã©viter le surapprentissage",
            "D) Pour amÃ©liorer la prÃ©cision",
          ],
          correct: 1,
          explanation:
            "Le partage de poids permet au mÃªme filtre de dÃ©tecter une caractÃ©ristique (comme un contour vertical) n'importe oÃ¹ dans l'image. Cela crÃ©e l'invariance par translation : un chat reste un chat qu'il soit en haut Ã  gauche ou en bas Ã  droite de l'image.",
        },
        prevModule: "backpropagation.html",
        nextModule: "rnn.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
