<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Backpropagation | IA4Ndada</title>

    <!-- MathJax pour les formules mathÃ©matiques -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- Pyodide pour Python dans le navigateur -->
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>

    <link rel="stylesheet" href="../../styles/module.css" />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="nav">
      <div class="nav-container">
        <div class="nav-breadcrumb">
          <a href="../../index.html">ğŸ  Accueil</a>
          <span>â€º</span>
          <span>ğŸ§  Deep Learning</span>
          <span>â€º</span>
          <span>Backpropagation</span>
        </div>
        <div class="progress-indicator">
          <span id="progress-text">Progression: 0%</span>
          <div class="progress-bar">
            <div
              class="progress-fill"
              id="progress-fill"
              style="width: 0%"
            ></div>
          </div>
        </div>
      </div>
    </nav>

    <!-- Contenu principal -->
    <div class="container">
      <h1>ğŸ”„ Backpropagation : L'Algorithme Magique</h1>
      <p class="subtitle">
        Module 4.3 - L'Apprentissage Automatique des RÃ©seaux
      </p>

      <!-- Objectifs -->
      <div class="objectives">
        <h2>ğŸ¯ Objectifs d'apprentissage</h2>
        <ul id="objectives-list">
          <!-- Les objectifs seront ajoutÃ©s dynamiquement -->
        </ul>
      </div>

      <!-- Contenu du module -->
      <div id="module-content">
        <!-- Le contenu sera ajoutÃ© dynamiquement -->
      </div>

      <!-- Quiz -->
      <div class="quiz" id="module-quiz" style="display: none">
        <div class="quiz-question" id="quiz-question"></div>
        <div class="quiz-options" id="quiz-options"></div>
        <div class="quiz-feedback" id="quiz-feedback"></div>
      </div>

      <!-- Checkpoint -->
      <div class="checkpoint">
        <h3>ğŸ‰ Checkpoint - Backpropagation</h3>
        <p>
          FÃ©licitations ! Vous comprenez maintenant l'algorithme qui a rendu
          possible l'IA moderne.
        </p>
        <button
          class="checkpoint-btn"
          id="checkpoint-btn"
          onclick="completeCheckpoint()"
        >
          Marquer comme complÃ©tÃ©
        </button>
      </div>

      <!-- Navigation entre modules -->
      <div class="module-nav">
        <a href="neural-networks.html" class="nav-link" id="prev-link"
          >â† Module prÃ©cÃ©dent : RÃ©seaux de Neurones</a
        >
        <a href="cnn.html" class="nav-link" id="next-link"
          >Module suivant : CNN â†’</a
        >
      </div>
    </div>

    <script src="../../scripts/module-engine.js"></script>
    <script>
      // Configuration du module Backpropagation
      const moduleConfig = {
        id: "dl-backpropagation",
        title: "Backpropagation : L'Algorithme Magique",
        category: "Deep Learning",
        objectives: [
          "Comprendre le problÃ¨me fondamental : comment ajuster des millions de poids ?",
          "MaÃ®triser la rÃ¨gle de dÃ©rivation en chaÃ®ne appliquÃ©e aux rÃ©seaux",
          "Calculer manuellement la backpropagation sur un rÃ©seau simple",
          "Comprendre pourquoi c'est l'algorithme le plus important de l'IA",
          "ImplÃ©menter backpropagation from scratch avec gradient checking",
        ],
        content: [
          {
            type: "concept",
            icon: "ğŸ’¡",
            title:
              "Le problÃ¨me impossible : ajuster des millions de paramÃ¨tres",
            content: `
                        <p>La <strong>backpropagation</strong> rÃ©sout le problÃ¨me le plus complexe de l'IA : comment ajuster automatiquement des millions (voire des milliards) de paramÃ¨tres pour minimiser l'erreur ?</p>
                        
                        <p><strong>ğŸ¤¯ Ampleur du dÃ©fi :</strong></p>
                        <ul>
                            <li>ğŸ§  <strong>RÃ©seau simple</strong> : 1000 paramÃ¨tres Ã  optimiser</li>
                            <li>ğŸ–¼ï¸ <strong>ResNet-50</strong> : 25 millions de paramÃ¨tres</li>
                            <li>ğŸ’¬ <strong>GPT-3</strong> : 175 milliards de paramÃ¨tres</li>
                            <li>ğŸ¤– <strong>GPT-4</strong> : ~1.7 trillion de paramÃ¨tres (estimation)</li>
                        </ul>
                        
                        <p><strong>âŒ Approches impossibles :</strong></p>
                        <ul>
                            <li>ğŸ² <strong>Essai-erreur alÃ©atoire</strong> : 10^1000000000 combinaisons possibles</li>
                            <li>ğŸ” <strong>Recherche exhaustive</strong> : plus d'atomes dans l'univers</li>
                            <li>ğŸ§  <strong>Ajustement manuel</strong> : impossible humainement</li>
                        </ul>
                        
                        <p><strong>âœ… Solution Ã©lÃ©gante : Backpropagation</strong></p>
                        <ul>
                            <li>ğŸ“ <strong>MathÃ©matiquement optimale</strong> : utilise les gradients exacts</li>
                            <li>âš¡ <strong>Computationnellement efficace</strong> : O(nombre de paramÃ¨tres)</li>
                            <li>ğŸ¯ <strong>Automatiquement prÃ©cise</strong> : pas d'approximation</li>
                        </ul>
                        
                        <p><strong>ğŸš€ Impact rÃ©volutionnaire :</strong></p>
                        <p>Sans backpropagation, pas de deep learning, pas de ChatGPT, pas de reconnaissance d'images, pas d'IA moderne ! C'est <strong>l'algorithme qui a changÃ© le monde</strong>.</p>
                    `,
          },
          {
            type: "intuition",
            icon: "ğŸ§ ",
            title: "L'analogie de l'orchestre symphonique sÃ©nÃ©galais",
            content: `
                        <p>Imaginez que vous dirigez <strong>l'Orchestre National du SÃ©nÃ©gal</strong> avec 100 musiciens pour jouer une mÃ©lodie parfaite :</p>
                        
                        <p><strong>ğŸµ ProblÃ¨me initial :</strong></p>
                        <ul>
                            <li>ğŸº <strong>Chaque musicien</strong> = un paramÃ¨tre du rÃ©seau</li>
                            <li>ğŸ¼ <strong>MÃ©lodie finale</strong> = sortie du rÃ©seau</li>
                            <li>ğŸ‘‚ <strong>Votre oreille</strong> = fonction de coÃ»t (mesure l'erreur)</li>
                            <li>ğŸ¯ <strong>Objectif</strong> : harmonie parfaite (erreur minimale)</li>
                        </ul>
                        
                        <p><strong>âŒ Approche naÃ¯ve impossible :</strong></p>
                        <p>"Musicien 47, jouez plus fort ! Musicien 23, plus doucement !" â†’ Chaos total avec 100 ajustements simultanÃ©s</p>
                        
                        <p><strong>âœ… Approche backpropagation :</strong></p>
                        <ol>
                            <li>ğŸµ <strong>Ã‰couter le rÃ©sultat final</strong> (propagation avant)</li>
                            <li>ğŸ‘‚ <strong>Identifier l'erreur globale</strong> (fonction de coÃ»t)</li>
                            <li>ğŸ” <strong>Remonter la chaÃ®ne</strong> : "Cette fausse note vient de quelle section ?"</li>
                            <li>ğŸ¯ <strong>Ajuster prÃ©cisÃ©ment</strong> : "Violons : -2%, Cuivres : +5%"</li>
                            <li>ğŸ”„ <strong>RÃ©pÃ©ter</strong> jusqu'Ã  perfection</li>
                        </ol>
                        
                        <p><strong>ğŸ’¡ GÃ©nie de l'algorithme :</strong></p>
                        <ul>
                            <li>ğŸ§  <strong>ResponsabilitÃ© calculÃ©e</strong> : chaque musicien sait exactement son impact</li>
                            <li>âš¡ <strong>Ajustement simultanÃ©</strong> : tous s'amÃ©liorent en mÃªme temps</li>
                            <li>ğŸ¯ <strong>Convergence garantie</strong> : vers l'harmonie parfaite</li>
                        </ul>
                        
                        <p><strong>ğŸŒŸ C'est exactement ce que fait backpropagation :</strong> elle calcule la responsabilitÃ© exacte de chaque paramÃ¨tre dans l'erreur finale et les ajuste tous simultanÃ©ment de maniÃ¨re optimale !</p>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title:
              "Formalisation rigoureuse : la rÃ¨gle de dÃ©rivation en chaÃ®ne",
            content: `
                        <p><strong>ğŸ”§ Backpropagation = application systÃ©matique de la rÃ¨gle de dÃ©rivation en chaÃ®ne</strong></p>
                        
                        <p><strong>ğŸ“ Rappel de la rÃ¨gle en chaÃ®ne (voir <a href="../math/derivatives.html">Module 1.4</a>) :</strong></p>
                        <p>Si \\(y = f(g(x))\\), alors \\(\\frac{dy}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}\\)</p>
                        
                        <p><strong>ğŸ§  Application aux rÃ©seaux de neurones :</strong></p>
                        <p>Pour un rÃ©seau \\(y = f_L(f_{L-1}(...f_2(f_1(\\vec{x}))...))\\), le gradient de la fonction de coÃ»t \\(\\mathcal{L}\\) par rapport aux poids \\(W^{(l)}\\) est :</p>
                        
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial W^{(l)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(l)}} \\cdot \\frac{\\partial \\vec{z}^{(l)}}{\\partial W^{(l)}}$$</p>
                        
                        <p><strong>ğŸ” DÃ©cryptage des termes :</strong></p>
                        <ul>
                            <li>\\(\\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(l)}}\\) = <strong>erreur qui "remonte"</strong> vers la couche l</li>
                            <li>\\(\\frac{\\partial \\vec{z}^{(l)}}{\\partial W^{(l)}}\\) = <strong>impact local</strong> des poids sur leur sortie</li>
                        </ul>
                        
                        <p><strong>ğŸ”„ Propagation rÃ©cursive :</strong></p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(l)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(l+1)}} \\cdot \\frac{\\partial \\vec{z}^{(l+1)}}{\\partial \\vec{h}^{(l)}} \\cdot \\frac{\\partial \\vec{h}^{(l)}}{\\partial \\vec{z}^{(l)}}$$</p>
                        
                        <p><strong>ğŸ¯ OÃ¹ :</strong></p>
                        <ul style="list-style: none; padding-left: 0">
                            <li><strong>â€¢ \\(\\frac{\\partial \\vec{z}^{(l+1)}}{\\partial \\vec{h}^{(l)}} = (W^{(l+1)})^T\\)</strong> (poids de la couche suivante)</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ \\(\\frac{\\partial \\vec{h}^{(l)}}{\\partial \\vec{z}^{(l)}} = \\sigma'(\\vec{z}^{(l)})\\)</strong> (dÃ©rivÃ©e de l'activation)</li>
                            <li style="margin-top: 0.5rem"><strong>â€¢ \\(\\frac{\\partial \\vec{z}^{(l)}}{\\partial W^{(l)}} = (\\vec{h}^{(l-1)})^T\\)</strong> (activations de la couche prÃ©cÃ©dente)</li>
                        </ul>
                        
                        <div style="background: #e8f5e9; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>ğŸ’¡ Algorithme en 2 Ã©tapes :</strong><br>
                            <strong>1ï¸âƒ£ Forward Pass :</strong> Calculer toutes les activations de l'entrÃ©e vers la sortie<br>
                            <strong>2ï¸âƒ£ Backward Pass :</strong> Calculer tous les gradients de la sortie vers l'entrÃ©e
                        </div>
                    `,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "DÃ©rivation complÃ¨te : Ã©tape par Ã©tape",
            content: `
                        <p><strong>ğŸ“ DÃ©rivons backpropagation pour un rÃ©seau 2-2-1 :</strong></p>
                        
                        <p><strong>ğŸ—ï¸ Architecture :</strong></p>
                        <ul>
                            <li>\\(\\vec{x} \\in \\mathbb{R}^2\\) â†’ \\(\\vec{h}^{(1)} \\in \\mathbb{R}^2\\) â†’ \\(y \\in \\mathbb{R}\\)</li>
                            <li>Fonction de coÃ»t : \\(\\mathcal{L} = \\frac{1}{2}(y - \\hat{y})^2\\)</li>
                        </ul>
                        
                        <p><strong>ğŸ”„ Forward Pass :</strong></p>
                        <p>$$\\vec{z}^{(1)} = W^{(1)} \\vec{x} + \\vec{b}^{(1)}$$</p>
                        <p>$$\\vec{h}^{(1)} = \\sigma(\\vec{z}^{(1)})$$</p>
                        <p>$$z^{(2)} = W^{(2)} \\vec{h}^{(1)} + b^{(2)}$$</p>
                        <p>$$\\hat{y} = \\sigma(z^{(2)})$$</p>
                        
                        <p><strong>â¬…ï¸ Backward Pass :</strong></p>
                        
                        <p><strong>Ã‰tape 1 :</strong> Gradient de la sortie</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} = \\hat{y} - y$$</p>
                        
                        <p><strong>Ã‰tape 2 :</strong> Gradient de la derniÃ¨re couche</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(2)}} = (\\hat{y} - y) \\cdot \\sigma'(z^{(2)})$$</p>
                        
                        <p><strong>Ã‰tape 3 :</strong> Gradients des poids de sortie</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial W^{(2)}} = \\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}} \\cdot (\\vec{h}^{(1)})^T$$</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial b^{(2)}} = \\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}}$$</p>
                        
                        <p><strong>Ã‰tape 4 :</strong> Propagation vers la couche cachÃ©e</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\vec{h}^{(1)}} = (W^{(2)})^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}}$$</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(1)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\vec{h}^{(1)}} \\odot \\sigma'(\\vec{z}^{(1)})$$</p>
                        
                        <p><strong>Ã‰tape 5 :</strong> Gradients des poids d'entrÃ©e</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial W^{(1)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(1)}} \\cdot \\vec{x}^T$$</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\vec{b}^{(1)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(1)}}$$</p>
                        
                        <div style="background: #fff3cd; padding: 1rem; border-radius: 4px; margin: 1rem 0;">
                            <strong>ğŸ”‘ Notation :</strong> \\(\\odot\\) = produit Ã©lÃ©ment par Ã©lÃ©ment (Hadamard)
                        </div>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Calcul manuel complet : rÃ©seau 2-2-1",
            content: `
                        <p><strong>ğŸ“ Exemple concret :</strong> RÃ©seau pour prÃ©dire si un Ã©tudiant rÃ©ussira (1) ou Ã©chouera (0) selon ses heures d'Ã©tude et de sommeil.</p>
                        
                        <p><strong>âš™ï¸ ParamÃ¨tres initiaux :</strong></p>
                        <p>$$W^{(1)} = \\begin{bmatrix} 0.5 & 0.3 \\\\ -0.2 & 0.8 \\end{bmatrix}, \\quad \\vec{b}^{(1)} = \\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix}$$</p>
                        <p>$$W^{(2)} = \\begin{bmatrix} 0.7 & -0.4 \\end{bmatrix}, \\quad b^{(2)} = 0.2$$</p>
                        
                        <p><strong>ğŸ“Š DonnÃ©es :</strong> Ã‰tudiant avec [heures_Ã©tude=6, heures_sommeil=8], rÃ©sultat rÃ©el y=1 (rÃ©ussite)</p>
                        <p>$$\\vec{x} = \\begin{bmatrix} 6 \\\\ 8 \\end{bmatrix}, \\quad y = 1$$</p>
                        
                        <p><strong>â¡ï¸ Forward Pass :</strong></p>
                        <p>$$\\vec{z}^{(1)} = \\begin{bmatrix} 0.5 \\times 6 + 0.3 \\times 8 + 0.1 \\\\ -0.2 \\times 6 + 0.8 \\times 8 - 0.1 \\end{bmatrix} = \\begin{bmatrix} 5.5 \\\\ 5.1 \\end{bmatrix}$$</p>
                        
                        <p>$$\\vec{h}^{(1)} = \\sigma(\\vec{z}^{(1)}) = \\begin{bmatrix} \\sigma(5.5) \\\\ \\sigma(5.1) \\end{bmatrix} â‰ˆ \\begin{bmatrix} 0.996 \\\\ 0.994 \\end{bmatrix}$$</p>
                        
                        <p>$$z^{(2)} = 0.7 \\times 0.996 + (-0.4) \\times 0.994 + 0.2 = 0.697 - 0.398 + 0.2 = 0.499$$</p>
                        
                        <p>$$\\hat{y} = \\sigma(0.499) â‰ˆ 0.622$$</p>
                        
                        <p><strong>ğŸ“Š Erreur :</strong> \\(\\mathcal{L} = \\frac{1}{2}(0.622 - 1)^2 = \\frac{1}{2}(-0.378)^2 = 0.071\\)</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Calcul manuel : backward pass complet",
            content: `
                        <p><strong>â¬…ï¸ Backward Pass :</strong> Calculons tous les gradients</p>
                        
                        <p><strong>Ã‰tape 1 :</strong> Gradient de la sortie</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} = \\hat{y} - y = 0.622 - 1 = -0.378$$</p>
                        
                        <p><strong>Ã‰tape 2 :</strong> Gradient de zâ½Â²â¾</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\sigma'(z^{(2)}) = -0.378 \\times \\sigma(0.499)(1-\\sigma(0.499))$$</p>
                        <p>$$= -0.378 \\times 0.622 \\times 0.378 = -0.089$$</p>
                        
                        <p><strong>Ã‰tape 3 :</strong> Gradients des poids de sortie</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial W^{(2)}} = \\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}} \\cdot (\\vec{h}^{(1)})^T = -0.089 \\times \\begin{bmatrix} 0.996 & 0.994 \\end{bmatrix}$$</p>
                        <p>$$= \\begin{bmatrix} -0.089 & -0.088 \\end{bmatrix}$$</p>
                        
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial b^{(2)}} = -0.089$$</p>
                        
                        <p><strong>Ã‰tape 4 :</strong> Propagation vers couche cachÃ©e</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\vec{h}^{(1)}} = (W^{(2)})^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}} = \\begin{bmatrix} 0.7 \\\\ -0.4 \\end{bmatrix} \\times (-0.089) = \\begin{bmatrix} -0.062 \\\\ 0.036 \\end{bmatrix}$$</p>
                        
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(1)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\vec{h}^{(1)}} \\odot \\sigma'(\\vec{z}^{(1)})$$</p>
                        
                        <p>Avec \\(\\sigma'(5.5) â‰ˆ 0.004\\) et \\(\\sigma'(5.1) â‰ˆ 0.006\\) :</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(1)}} = \\begin{bmatrix} -0.062 \\\\ 0.036 \\end{bmatrix} \\odot \\begin{bmatrix} 0.004 \\\\ 0.006 \\end{bmatrix} = \\begin{bmatrix} -0.0002 \\\\ 0.0002 \\end{bmatrix}$$</p>
                        
                        <p><strong>Ã‰tape 5 :</strong> Gradients des poids d'entrÃ©e</p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial W^{(1)}} = \\frac{\\partial \\mathcal{L}}{\\partial \\vec{z}^{(1)}} \\cdot \\vec{x}^T = \\begin{bmatrix} -0.0002 \\\\ 0.0002 \\end{bmatrix} \\times \\begin{bmatrix} 6 & 8 \\end{bmatrix}$$</p>
                        <p>$$= \\begin{bmatrix} -0.0012 & -0.0016 \\\\ 0.0012 & 0.0016 \\end{bmatrix}$$</p>
                    `,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice pratique : calcul manuel backpropagation",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>RÃ©seau 2-1-1 pour prÃ©dire le succÃ¨s d'une startup (donnÃ©es normalisÃ©es) :</p>
                        
                        <p><strong>âš™ï¸ ParamÃ¨tres :</strong></p>
                        <p>$$W^{(1)} = \\begin{bmatrix} 0.6 & -0.3 \\end{bmatrix}, \\quad b^{(1)} = 0.1$$</p>
                        <p>$$W^{(2)} = \\begin{bmatrix} 0.8 \\end{bmatrix}, \\quad b^{(2)} = -0.2$$</p>
                        
                        <p><strong>ğŸ“Š DonnÃ©es :</strong> [capital_initial=0.7, experience_fondateur=0.4], succÃ¨s rÃ©el y=1</p>
                        
                        <p><strong>ğŸ“ Calculez :</strong></p>
                        <ol>
                            <li>Forward pass complet (zâ½Â¹â¾, hâ½Â¹â¾, zâ½Â²â¾, Å·)</li>
                            <li>Fonction de coÃ»t L = Â½(Å· - y)Â²</li>
                            <li>Backward pass : tous les gradients</li>
                            <li>Mise Ã  jour des poids avec Î± = 0.1</li>
                            <li>Nouvelle prÃ©diction aprÃ¨s mise Ã  jour</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('backprop-manual-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="backprop-manual-exercise" style="display: none;">
                        <ol>
                            <li><strong>Forward pass :</strong><br>
                                zâ½Â¹â¾ = 0.6Ã—0.7 + (-0.3)Ã—0.4 + 0.1 = 0.42 - 0.12 + 0.1 = 0.4<br>
                                hâ½Â¹â¾ = Ïƒ(0.4) â‰ˆ 0.599<br>
                                zâ½Â²â¾ = 0.8Ã—0.599 + (-0.2) = 0.479 - 0.2 = 0.279<br>
                                Å· = Ïƒ(0.279) â‰ˆ 0.569</li>
                            <li><strong>CoÃ»t :</strong> L = Â½(0.569 - 1)Â² = Â½(-0.431)Â² = 0.093</li>
                            <li><strong>Backward pass :</strong><br>
                                âˆ‚L/âˆ‚Å· = 0.569 - 1 = -0.431<br>
                                âˆ‚L/âˆ‚zâ½Â²â¾ = -0.431 Ã— 0.569 Ã— 0.431 = -0.106<br>
                                âˆ‚L/âˆ‚Wâ½Â²â¾ = -0.106 Ã— 0.599 = -0.063<br>
                                âˆ‚L/âˆ‚hâ½Â¹â¾ = 0.8 Ã— (-0.106) = -0.085<br>
                                âˆ‚L/âˆ‚zâ½Â¹â¾ = -0.085 Ã— 0.599 Ã— 0.401 = -0.020<br>
                                âˆ‚L/âˆ‚Wâ½Â¹â¾ = -0.020 Ã— [0.7, 0.4] = [-0.014, -0.008]</li>
                            <li><strong>Mise Ã  jour (Î±=0.1) :</strong><br>
                                Wâ½Â²â¾ â† 0.8 - 0.1Ã—(-0.063) = 0.806<br>
                                Wâ½Â¹â¾ â† [0.6, -0.3] - 0.1Ã—[-0.014, -0.008] = [0.601, -0.299]</li>
                            <li><strong>Nouvelle prÃ©diction :</strong> Å· â‰ˆ 0.573 (amÃ©lioration !)</li>
                        </ol>
                        </div>
                    `,
          },
          {
            type: "code",
            title: "ImplÃ©mentation backpropagation from scratch",
            description: "ImplÃ©mentons l'algorithme complet :",
            code: `import numpy as np
import matplotlib.pyplot as plt

class ReseauAvecBackprop:
    def __init__(self, architecture, learning_rate=0.01):
        """
        RÃ©seau de neurones avec backpropagation
        architecture: [n_entree, n_cache1, n_cache2, ..., n_sortie]
        """
        self.architecture = architecture
        self.lr = learning_rate
        self.nb_couches = len(architecture)
        
        # Initialisation Xavier/Glorot
        self.poids = {}
        self.biais = {}
        
        for i in range(1, self.nb_couches):
            fan_in, fan_out = architecture[i-1], architecture[i]
            limite = np.sqrt(6 / (fan_in + fan_out))
            
            self.poids[i] = np.random.uniform(-limite, limite, (fan_out, fan_in))
            self.biais[i] = np.zeros((fan_out, 1))
        
        print(f"ğŸ§  RÃ©seau crÃ©Ã©: {' â†’ '.join(map(str, architecture))}")
        print(f"ğŸ“Š ParamÃ¨tres: {self.compter_parametres()}")
        print(f"ğŸ“ˆ Learning rate: {learning_rate}")
    
    def compter_parametres(self):
        """Compter le nombre total de paramÃ¨tres"""
        total = 0
        for i in range(1, self.nb_couches):
            total += self.poids[i].size + self.biais[i].size
        return total
    
    def sigmoid(self, x):
        """Sigmoid avec protection overflow"""
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    def sigmoid_derivee(self, x):
        """DÃ©rivÃ©e de sigmoid"""
        s = self.sigmoid(x)
        return s * (1 - s)
    
    def forward_pass(self, X):
        """Propagation avant avec stockage pour backprop"""
        self.activations = {0: X}
        self.z_values = {}
        
        for i in range(1, self.nb_couches):
            self.z_values[i] = self.poids[i] @ self.activations[i-1] + self.biais[i]
            self.activations[i] = self.sigmoid(self.z_values[i])
        
        return self.activations[self.nb_couches - 1]
    
    def backward_pass(self, y_true):
        """Backpropagation complÃ¨te"""
        m = y_true.shape[1]  # Nombre d'exemples
        
        # Gradients pour stockage
        self.gradients_poids = {}
        self.gradients_biais = {}
        
        # Gradient de la sortie (MSE)
        dA = self.activations[self.nb_couches - 1] - y_true
        
        # Remonter couche par couche
        for i in range(self.nb_couches - 1, 0, -1):
            # Gradient avant activation
            dZ = dA * self.sigmoid_derivee(self.z_values[i])
            
            # Gradients des paramÃ¨tres
            self.gradients_poids[i] = (1/m) * dZ @ self.activations[i-1].T
            self.gradients_biais[i] = (1/m) * np.sum(dZ, axis=1, keepdims=True)
            
            # Gradient pour la couche prÃ©cÃ©dente
            if i > 1:
                dA = self.poids[i].T @ dZ
    
    def mettre_a_jour_parametres(self):
        """Mise Ã  jour des poids et biais"""
        for i in range(1, self.nb_couches):
            self.poids[i] -= self.lr * self.gradients_poids[i]
            self.biais[i] -= self.lr * self.gradients_biais[i]
    
    def entrainer_une_epoque(self, X, y):
        """Une Ã©poque d'entraÃ®nement complÃ¨te"""
        # Forward pass
        predictions = self.forward_pass(X)
        
        # Calcul du coÃ»t
        cout = np.mean((predictions - y)**2)
        
        # Backward pass
        self.backward_pass(y)
        
        # Mise Ã  jour
        self.mettre_a_jour_parametres()
        
        return cout, predictions
    
    def entrainer(self, X, y, epochs=1000, verbose=True):
        """EntraÃ®nement complet avec suivi"""
        couts = []
        
        if verbose:
            print(f"ğŸš€ ENTRAÃNEMENT - {epochs} Ã©poques")
            print("=" * 40)
        
        for epoch in range(epochs):
            cout, predictions = self.entrainer_une_epoque(X, y)
            couts.append(cout)
            
            if verbose and (epoch % 100 == 0 or epoch < 10):
                precision = np.mean((predictions > 0.5) == (y > 0.5)) * 100
                print(f"Ã‰poque {epoch:4d}: CoÃ»t = {cout:.4f}, PrÃ©cision = {precision:.1f}%")
        
        return couts

# Test sur problÃ¨me de classification simple
print("ğŸ¯ TEST: CLASSIFICATION RÃ‰USSITE Ã‰TUDIANTS")
print("=" * 50)

# GÃ©nÃ©ration de donnÃ©es synthÃ©tiques
np.random.seed(42)
n_samples = 100

# Features: [heures_Ã©tude, heures_sommeil] normalisÃ©es
heures_etude = np.random.uniform(0, 1, n_samples)
heures_sommeil = np.random.uniform(0, 1, n_samples)

# Target: rÃ©ussite basÃ©e sur une rÃ¨gle complexe
# RÃ©ussite si: Ã©tude Ã©levÃ©e ET sommeil suffisant OU Ã©tude trÃ¨s Ã©levÃ©e
reussite = ((heures_etude > 0.6) & (heures_sommeil > 0.4)) | (heures_etude > 0.8)
reussite = reussite.astype(float)

# PrÃ©paration des donnÃ©es
X = np.vstack([heures_etude, heures_sommeil])
y = reussite.reshape(1, -1)

print(f"ğŸ“Š Dataset: {n_samples} Ã©tudiants")
print(f"ğŸ“ˆ Taux de rÃ©ussite: {np.mean(reussite)*100:.1f}%")

# CrÃ©ation et entraÃ®nement du rÃ©seau
reseau = ReseauAvecBackprop([2, 4, 1], learning_rate=0.5)
couts = reseau.entrainer(X, y, epochs=500, verbose=True)`,
          },
          {
            type: "code",
            title: "Visualisation de l'apprentissage",
            description: "Visualisons comment le rÃ©seau apprend :",
            code: `# Visualisation des rÃ©sultats
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

# 1. Courbe d'apprentissage
ax1.plot(couts, 'b-', linewidth=2)
ax1.set_title('Courbe d\'Apprentissage')
ax1.set_xlabel('Ã‰poque')
ax1.set_ylabel('CoÃ»t (MSE)')
ax1.grid(True, alpha=0.3)

# 2. DonnÃ©es originales
colors = ['red' if r == 0 else 'green' for r in reussite]
ax2.scatter(heures_etude, heures_sommeil, c=colors, alpha=0.7)
ax2.set_title('DonnÃ©es Originales')
ax2.set_xlabel('Heures d\'Ã©tude (normalisÃ©es)')
ax2.set_ylabel('Heures de sommeil (normalisÃ©es)')

# 3. PrÃ©dictions du rÃ©seau
predictions_finales = reseau.forward_pass(X)[0]
ax3.scatter(heures_etude, heures_sommeil, c=predictions_finales, 
           cmap='RdYlGn', alpha=0.7)
ax3.set_title('PrÃ©dictions du RÃ©seau')
ax3.set_xlabel('Heures d\'Ã©tude')
ax3.set_ylabel('Heures de sommeil')
plt.colorbar(ax3.collections[0], ax=ax3, label='ProbabilitÃ© de rÃ©ussite')

# 4. FrontiÃ¨re de dÃ©cision
xx, yy = np.meshgrid(np.linspace(0, 1, 50), np.linspace(0, 1, 50))
grid_points = np.vstack([xx.ravel(), yy.ravel()])
grid_predictions = reseau.forward_pass(grid_points)[0]

ax4.contourf(xx, yy, grid_predictions.reshape(xx.shape), 
            levels=20, cmap='RdYlGn', alpha=0.6)
ax4.scatter(heures_etude, heures_sommeil, c=colors, alpha=0.8, edgecolors='black')
ax4.set_title('FrontiÃ¨re de DÃ©cision Apprise')
ax4.set_xlabel('Heures d\'Ã©tude')
ax4.set_ylabel('Heures de sommeil')

plt.tight_layout()
plt.show()

# Ã‰valuation finale
predictions_binaires = (predictions_finales > 0.5).astype(int)
precision = np.mean(predictions_binaires == reussite) * 100
print(f"\\nğŸ¯ RÃ‰SULTATS FINAUX:")
print(f"ğŸ“Š PrÃ©cision finale: {precision:.1f}%")
print(f"ğŸ“‰ CoÃ»t final: {couts[-1]:.4f}")
print(f"ğŸ”„ Convergence: {'Oui' if couts[-1] < 0.1 else 'Non'}")`,
          },
          {
            type: "concept",
            icon: "ğŸ’¡",
            title: "Gradient checking : vÃ©rifier nos calculs",
            content: `
                        <p><strong>ğŸ” Comment s'assurer que notre backpropagation est correcte ?</strong></p>
                        <p>Le <strong>gradient checking</strong> compare nos gradients analytiques avec des gradients numÃ©riques calculÃ©s par approximation.</p>
                        
                        <p><strong>ğŸ“ Approximation numÃ©rique du gradient :</strong></p>
                        <p>$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta} â‰ˆ \\frac{\\mathcal{L}(\\theta + \\epsilon) - \\mathcal{L}(\\theta - \\epsilon)}{2\\epsilon}$$</p>
                        
                        <p><strong>ğŸ” OÃ¹ :</strong></p>
                        <ul>
                            <li>\\(\\theta\\) = <strong>paramÃ¨tre Ã  tester</strong> (un poids ou biais)</li>
                            <li>\\(\\epsilon\\) = <strong>petite perturbation</strong> (typiquement 10â»â·)</li>
                            <li>\\(\\mathcal{L}(\\theta Â± \\epsilon)\\) = <strong>coÃ»t avec paramÃ¨tre perturbÃ©</strong></li>
                        </ul>
                        
                        <p><strong>âœ… Test de validitÃ© :</strong></p>
                        <p>$$\\text{erreur relative} = \\frac{|\\text{gradient analytique} - \\text{gradient numÃ©rique}|}{|\\text{gradient analytique}| + |\\text{gradient numÃ©rique}|}$$</p>
                        
                        <p><strong>ğŸ¯ CritÃ¨res d'acceptation :</strong></p>
                        <ul>
                            <li>âœ… <strong>Excellent</strong> : erreur < 10â»â·</li>
                            <li>ğŸ‘ <strong>Bon</strong> : erreur < 10â»âµ</li>
                            <li>âš ï¸ <strong>Suspect</strong> : erreur < 10â»Â³</li>
                            <li>âŒ <strong>Bug</strong> : erreur > 10â»Â³</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Pourquoi crucial ?</strong></p>
                        <p>Un bug dans backpropagation peut passer inaperÃ§u (le rÃ©seau "apprend" quand mÃªme) mais sera beaucoup moins efficace. Le gradient checking dÃ©tecte ces erreurs subtiles.</p>
                    `,
          },
          {
            type: "code",
            title: "ImplÃ©mentation gradient checking",
            description: "VÃ©rifions la correction de notre backpropagation :",
            code: `def gradient_checking(reseau, X, y, epsilon=1e-7):
    """VÃ©rifie la correction de la backpropagation"""
    print("ğŸ” GRADIENT CHECKING")
    print("=" * 30)
    
    # Forward + backward pour obtenir gradients analytiques
    reseau.forward_pass(X)
    reseau.backward_pass(y)
    
    # Test sur quelques paramÃ¨tres reprÃ©sentatifs
    parametres_test = [
        ('W^(1)[0,0]', 1, 0, 0),  # Premier poids premiÃ¨re couche
        ('W^(2)[0,0]', 2, 0, 0),  # Premier poids deuxiÃ¨me couche
        ('b^(1)[0]', 1, 0, None), # Premier biais premiÃ¨re couche
    ]
    
    for nom, couche, i, j in parametres_test:
        # Gradient analytique
        if j is None:  # Biais
            grad_analytique = reseau.gradients_biais[couche][i, 0]
            param_original = reseau.biais[couche][i, 0]
        else:  # Poids
            grad_analytique = reseau.gradients_poids[couche][i, j]
            param_original = reseau.poids[couche][i, j]
        
        # Gradient numÃ©rique
        # CoÃ»t avec +epsilon
        if j is None:
            reseau.biais[couche][i, 0] = param_original + epsilon
        else:
            reseau.poids[couche][i, j] = param_original + epsilon
        
        pred_plus = reseau.forward_pass(X)
        cout_plus = np.mean((pred_plus - y)**2)
        
        # CoÃ»t avec -epsilon
        if j is None:
            reseau.biais[couche][i, 0] = param_original - epsilon
        else:
            reseau.poids[couche][i, j] = param_original - epsilon
        
        pred_moins = reseau.forward_pass(X)
        cout_moins = np.mean((pred_moins - y)**2)
        
        # Restaurer valeur originale
        if j is None:
            reseau.biais[couche][i, 0] = param_original
        else:
            reseau.poids[couche][i, j] = param_original
        
        # Gradient numÃ©rique
        grad_numerique = (cout_plus - cout_moins) / (2 * epsilon)
        
        # Erreur relative
        erreur = abs(grad_analytique - grad_numerique) / (abs(grad_analytique) + abs(grad_numerique) + 1e-8)
        
        # Affichage
        status = "âœ…" if erreur < 1e-5 else "âš ï¸" if erreur < 1e-3 else "âŒ"
        print(f"{status} {nom}: Analytique={grad_analytique:.6f}, NumÃ©rique={grad_numerique:.6f}, Erreur={erreur:.2e}")
    
    print("\\nğŸ’¡ Gradient checking terminÃ© !")

# Test du gradient checking
print("\\nğŸ§ª VÃ‰RIFICATION DE LA BACKPROPAGATION")
print("=" * 50)

# Petit Ã©chantillon pour le test
X_test = X[:, :5]  # 5 premiers exemples
y_test = y[:, :5]

gradient_checking(reseau, X_test, y_test)`,
          },
          {
            type: "mathematique",
            icon: "âˆ‘",
            title: "Optimisation : au-delÃ  du gradient descent simple",
            content: `
                        <p><strong>ğŸš€ Backpropagation fournit les gradients, mais comment les utiliser optimalement ?</strong></p>
                        
                        <p><strong>ğŸ“ Gradient Descent classique :</strong></p>
                        <p>$$\\theta_{t+1} = \\theta_t - \\alpha \\nabla_{\\theta} \\mathcal{L}(\\theta_t)$$</p>
                        
                        <p><strong>âš ï¸ ProblÃ¨mes du GD simple :</strong></p>
                        <ul>
                            <li>ğŸŒ <strong>Convergence lente</strong> : oscillations dans les vallÃ©es</li>
                            <li>ğŸ¯ <strong>Minima locaux</strong> : peut rester bloquÃ©</li>
                            <li>ğŸ“Š <strong>Learning rate fixe</strong> : pas adaptatif</li>
                        </ul>
                        
                        <p><strong>ğŸš€ Momentum (amÃ©lioration 1) :</strong></p>
                        <p>$$v_t = \\beta v_{t-1} + (1-\\beta) \\nabla_{\\theta} \\mathcal{L}(\\theta_t)$$</p>
                        <p>$$\\theta_{t+1} = \\theta_t - \\alpha v_t$$</p>
                        <p><strong>ğŸ’¡ IdÃ©e :</strong> "MÃ©moire" des gradients prÃ©cÃ©dents pour Ã©viter les oscillations</p>
                        
                        <p><strong>ğŸ§  Adam (amÃ©lioration 2) :</strong></p>
                        <p>$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) \\nabla_{\\theta} \\mathcal{L}$$</p>
                        <p>$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2) (\\nabla_{\\theta} \\mathcal{L})^2$$</p>
                        <p>$$\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$$</p>
                        <p>$$\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t$$</p>
                        
                        <p><strong>ğŸ” Composants d'Adam :</strong></p>
                        <ul>
                            <li>\\(m_t\\) = <strong>momentum</strong> (moyenne mobile du gradient)</li>
                            <li>\\(v_t\\) = <strong>variance</strong> (moyenne mobile du gradientÂ²)</li>
                            <li>\\(\\hat{m}_t, \\hat{v}_t\\) = <strong>correction de biais</strong> (dÃ©but d'entraÃ®nement)</li>
                            <li>\\(\\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon}\\) = <strong>learning rate adaptatif</strong></li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Valeurs typiques :</strong> \\(\\beta_1 = 0.9\\), \\(\\beta_2 = 0.999\\), \\(\\epsilon = 10^{-8}\\)</p>
                    `,
          },
          {
            type: "code",
            title: "ImplÃ©mentation optimiseur Adam",
            description: "ImplÃ©mentons l'optimiseur Adam complet :",
            code: `class OptimiseurAdam:
    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):
        self.lr = learning_rate
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        self.t = 0  # Compteur d'itÃ©rations
        
        # Moments pour chaque paramÃ¨tre
        self.m_poids = {}
        self.v_poids = {}
        self.m_biais = {}
        self.v_biais = {}
    
    def initialiser(self, reseau):
        """Initialiser les moments pour tous les paramÃ¨tres"""
        for i in range(1, reseau.nb_couches):
            self.m_poids[i] = np.zeros_like(reseau.poids[i])
            self.v_poids[i] = np.zeros_like(reseau.poids[i])
            self.m_biais[i] = np.zeros_like(reseau.biais[i])
            self.v_biais[i] = np.zeros_like(reseau.biais[i])
    
    def mettre_a_jour(self, reseau):
        """Mise Ã  jour Adam des paramÃ¨tres"""
        self.t += 1
        
        for i in range(1, reseau.nb_couches):
            # Poids
            grad_w = reseau.gradients_poids[i]
            self.m_poids[i] = self.beta1 * self.m_poids[i] + (1 - self.beta1) * grad_w
            self.v_poids[i] = self.beta2 * self.v_poids[i] + (1 - self.beta2) * grad_w**2
            
            # Correction de biais
            m_hat = self.m_poids[i] / (1 - self.beta1**self.t)
            v_hat = self.v_poids[i] / (1 - self.beta2**self.t)
            
            # Mise Ã  jour
            reseau.poids[i] -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)
            
            # Biais
            grad_b = reseau.gradients_biais[i]
            self.m_biais[i] = self.beta1 * self.m_biais[i] + (1 - self.beta1) * grad_b
            self.v_biais[i] = self.beta2 * self.v_biais[i] + (1 - self.beta2) * grad_b**2
            
            m_hat_b = self.m_biais[i] / (1 - self.beta1**self.t)
            v_hat_b = self.v_biais[i] / (1 - self.beta2**self.t)
            
            reseau.biais[i] -= self.lr * m_hat_b / (np.sqrt(v_hat_b) + self.epsilon)

# Comparaison SGD vs Adam
print("\\nâš”ï¸ COMPARAISON: SGD vs ADAM")
print("=" * 35)

# RÃ©seau avec SGD
reseau_sgd = ReseauAvecBackprop([2, 4, 1], learning_rate=0.1)
couts_sgd = reseau_sgd.entrainer(X, y, epochs=300, verbose=False)

# RÃ©seau avec Adam
reseau_adam = ReseauAvecBackprop([2, 4, 1], learning_rate=0.001)
optimiseur = OptimiseurAdam()
optimiseur.initialiser(reseau_adam)

couts_adam = []
for epoch in range(300):
    cout, _ = reseau_adam.entrainer_une_epoque(X, y)
    optimiseur.mettre_a_jour(reseau_adam)
    couts_adam.append(cout)

# Visualisation comparative
plt.figure(figsize=(12, 6))
plt.plot(couts_sgd, 'b-', label='SGD', linewidth=2)
plt.plot(couts_adam, 'r-', label='Adam', linewidth=2)
plt.title('Comparaison Optimiseurs: SGD vs Adam')
plt.xlabel('Ã‰poque')
plt.ylabel('CoÃ»t')
plt.legend()
plt.grid(True, alpha=0.3)
plt.yscale('log')  # Ã‰chelle logarithmique pour mieux voir
plt.show()

print(f"ğŸ“Š CoÃ»t final SGD: {couts_sgd[-1]:.4f}")
print(f"ğŸ“Š CoÃ»t final Adam: {couts_adam[-1]:.4f}")
print(f"ğŸš€ Adam converge {couts_sgd[-1]/couts_adam[-1]:.1f}x plus vite !")`,
          },
          {
            type: "exemple",
            icon: "ğŸ’»",
            title: "Exercice pratique : dÃ©rivation manuelle",
            content: `
                        <p><strong>ğŸ¯ Exercice Ã  rÃ©soudre :</strong></p>
                        <p>Pour un rÃ©seau 1-1-1 trÃ¨s simple avec fonction de coÃ»t MSE :</p>
                        
                        <p><strong>âš™ï¸ Architecture :</strong></p>
                        <ul>
                            <li>\\(z^{(1)} = w_1 x + b_1\\)</li>
                            <li>\\(h^{(1)} = \\sigma(z^{(1)})\\)</li>
                            <li>\\(z^{(2)} = w_2 h^{(1)} + b_2\\)</li>
                            <li>\\(\\hat{y} = \\sigma(z^{(2)})\\)</li>
                            <li>\\(\\mathcal{L} = \\frac{1}{2}(\\hat{y} - y)^2\\)</li>
                        </ul>
                        
                        <p><strong>ğŸ“ DÃ©rivez analytiquement :</strong></p>
                        <ol>
                            <li>\\(\\frac{\\partial \\mathcal{L}}{\\partial w_2}\\) (poids de sortie)</li>
                            <li>\\(\\frac{\\partial \\mathcal{L}}{\\partial b_2}\\) (biais de sortie)</li>
                            <li>\\(\\frac{\\partial \\mathcal{L}}{\\partial w_1}\\) (poids d'entrÃ©e)</li>
                            <li>\\(\\frac{\\partial \\mathcal{L}}{\\partial b_1}\\) (biais d'entrÃ©e)</li>
                        </ol>
                        
                        <p><strong>âœ… Solutions :</strong></p>
                        <button class="btn btn-copy" onclick="toggleSolution('manual-derivation-exercise')" style="margin-bottom: 1rem;">
                            ğŸ‘ï¸ Voir la solution
                        </button>
                        <div id="manual-derivation-exercise" style="display: none;">
                        <ol>
                            <li><strong>\\(\\frac{\\partial \\mathcal{L}}{\\partial w_2}\\) :</strong><br>
                                \\(\\frac{\\partial \\mathcal{L}}{\\partial w_2} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(2)}} \\cdot \\frac{\\partial z^{(2)}}{\\partial w_2}\\)<br>
                                \\(= (\\hat{y} - y) \\cdot \\sigma'(z^{(2)}) \\cdot h^{(1)}\\)</li>
                            <li><strong>\\(\\frac{\\partial \\mathcal{L}}{\\partial b_2}\\) :</strong><br>
                                \\(\\frac{\\partial \\mathcal{L}}{\\partial b_2} = (\\hat{y} - y) \\cdot \\sigma'(z^{(2)}) \\cdot 1 = (\\hat{y} - y) \\cdot \\sigma'(z^{(2)})\\)</li>
                            <li><strong>\\(\\frac{\\partial \\mathcal{L}}{\\partial w_1}\\) :</strong><br>
                                \\(\\frac{\\partial \\mathcal{L}}{\\partial w_1} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(2)}} \\cdot \\frac{\\partial z^{(2)}}{\\partial h^{(1)}} \\cdot \\frac{\\partial h^{(1)}}{\\partial z^{(1)}} \\cdot \\frac{\\partial z^{(1)}}{\\partial w_1}\\)<br>
                                \\(= (\\hat{y} - y) \\cdot \\sigma'(z^{(2)}) \\cdot w_2 \\cdot \\sigma'(z^{(1)}) \\cdot x\\)</li>
                            <li><strong>\\(\\frac{\\partial \\mathcal{L}}{\\partial b_1}\\) :</strong><br>
                                \\(\\frac{\\partial \\mathcal{L}}{\\partial b_1} = (\\hat{y} - y) \\cdot \\sigma'(z^{(2)}) \\cdot w_2 \\cdot \\sigma'(z^{(1)}) \\cdot 1\\)</li>
                        </ol>
                        <p><strong>ğŸ’¡ Pattern :</strong> Plus on s'Ã©loigne de la sortie, plus la chaÃ®ne de dÃ©rivÃ©es s'allonge !</p>
                        </div>
                    `,
          },
          {
            type: "code",
            title: "EntraÃ®nement sur problÃ¨me rÃ©el",
            description: "Appliquons backpropagation Ã  un problÃ¨me concret :",
            code: `# ProblÃ¨me rÃ©el: prÃ©diction de succÃ¨s de startups sÃ©nÃ©galaises
def generer_donnees_startups(n=200):
    """GÃ©nÃ¨re des donnÃ©es rÃ©alistes de startups"""
    np.random.seed(42)
    
    # Features normalisÃ©es [0,1]
    capital_initial = np.random.beta(2, 5, n)  # PlutÃ´t faible (rÃ©aliste)
    experience_fondateur = np.random.beta(3, 3, n)  # Distribution Ã©quilibrÃ©e
    taille_marche = np.random.beta(4, 2, n)  # PlutÃ´t Ã©levÃ©e
    
    # RÃ¨gle complexe pour le succÃ¨s (non-linÃ©aire)
    # SuccÃ¨s si: (capital ET expÃ©rience) OU (marchÃ© Ã©norme)
    prob_succes = (
        0.3 * capital_initial * experience_fondateur +  # Synergie capital-expÃ©rience
        0.4 * taille_marche +                          # Impact marchÃ©
        0.2 * (capital_initial > 0.7).astype(float) +  # Bonus gros capital
        0.1 * (experience_fondateur > 0.8).astype(float)  # Bonus expert
    )
    
    # Ajout de bruit rÃ©aliste
    bruit = np.random.normal(0, 0.1, n)
    prob_succes = np.clip(prob_succes + bruit, 0, 1)
    
    # Conversion en succÃ¨s binaire
    succes = (prob_succes > 0.5).astype(float)
    
    X = np.vstack([capital_initial, experience_fondateur, taille_marche])
    return X, succes.reshape(1, -1), prob_succes

# GÃ©nÃ©ration des donnÃ©es
X_startups, y_startups, prob_reelles = generer_donnees_startups(150)

print("ğŸš€ DATASET: STARTUPS SÃ‰NÃ‰GALAISES")
print("=" * 40)
print(f"ğŸ“Š Nombre de startups: {X_startups.shape[1]}")
print(f"ğŸ“ˆ Taux de succÃ¨s: {np.mean(y_startups)*100:.1f}%")
print(f"ğŸ’° Capital moyen: {np.mean(X_startups[0])*100:.1f}%")
print(f"ğŸ§  ExpÃ©rience moyenne: {np.mean(X_startups[1])*100:.1f}%")
print(f"ğŸ“Š Taille marchÃ© moyenne: {np.mean(X_startups[2])*100:.1f}%")

# EntraÃ®nement avec Adam
reseau_startups = ReseauAvecBackprop([3, 8, 4, 1], learning_rate=0.001)
optimiseur_adam = OptimiseurAdam(learning_rate=0.01)
optimiseur_adam.initialiser(reseau_startups)

print(f"\\nğŸ§  RÃ©seau pour startups: {reseau_startups.architecture}")
print(f"ğŸ“Š ParamÃ¨tres totaux: {reseau_startups.compter_parametres()}")

# EntraÃ®nement avec suivi
couts_startups = []
precisions = []

for epoch in range(500):
    cout, predictions = reseau_startups.entrainer_une_epoque(X_startups, y_startups)
    optimiseur_adam.mettre_a_jour(reseau_startups)
    
    couts_startups.append(cout)
    precision = np.mean((predictions > 0.5) == (y_startups > 0.5)) * 100
    precisions.append(precision)
    
    if epoch % 100 == 0:
        print(f"Ã‰poque {epoch:3d}: CoÃ»t = {cout:.4f}, PrÃ©cision = {precision:.1f}%")

print(f"\\nğŸ¯ RÃ‰SULTATS FINAUX:")
print(f"ğŸ“Š PrÃ©cision finale: {precisions[-1]:.1f}%")
print(f"ğŸ“‰ CoÃ»t final: {couts_startups[-1]:.4f}")`,
          },
          {
            type: "code",
            title: "Analyse des rÃ©sultats",
            description: "Analysons les performances de notre rÃ©seau :",
            code: `# Visualisation des rÃ©sultats d'entraÃ®nement
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

# 1. Courbes d'apprentissage
ax1.plot(couts_startups, 'b-', linewidth=2, label='CoÃ»t')
ax1.set_title('Ã‰volution du CoÃ»t')
ax1.set_xlabel('Ã‰poque')
ax1.set_ylabel('CoÃ»t (MSE)')
ax1.grid(True, alpha=0.3)
ax1.legend()

ax2.plot(precisions, 'g-', linewidth=2, label='PrÃ©cision')
ax2.set_title('Ã‰volution de la PrÃ©cision')
ax2.set_xlabel('Ã‰poque')
ax2.set_ylabel('PrÃ©cision (%)')
ax2.grid(True, alpha=0.3)
ax2.legend()

# 2. PrÃ©dictions vs rÃ©alitÃ©
predictions_finales = reseau_startups.forward_pass(X_startups)[0]
ax3.scatter(prob_reelles, predictions_finales, alpha=0.6)
ax3.plot([0, 1], [0, 1], 'r--', label='PrÃ©diction parfaite')
ax3.set_title('PrÃ©dictions vs RÃ©alitÃ©')
ax3.set_xlabel('ProbabilitÃ© rÃ©elle')
ax3.set_ylabel('PrÃ©diction du rÃ©seau')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 3. Distribution des erreurs
erreurs = predictions_finales.flatten() - prob_reelles
ax4.hist(erreurs, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
ax4.axvline(np.mean(erreurs), color='red', linestyle='--', 
           label=f'Erreur moyenne: {np.mean(erreurs):.3f}')
ax4.set_title('Distribution des Erreurs')
ax4.set_xlabel('Erreur (prÃ©diction - rÃ©alitÃ©)')
ax4.set_ylabel('FrÃ©quence')
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Analyse des cas extrÃªmes
print("\\nğŸ” ANALYSE DES CAS EXTRÃŠMES:")
print("=" * 35)

# Meilleures prÃ©dictions
indices_tries = np.argsort(np.abs(erreurs))
print("âœ… 3 meilleures prÃ©dictions:")
for i in range(3):
    idx = indices_tries[i]
    print(f"  Startup {idx}: RÃ©el={prob_reelles[idx]:.3f}, PrÃ©dit={predictions_finales[0,idx]:.3f}, Erreur={erreurs[idx]:.3f}")

print("\\nâŒ 3 pires prÃ©dictions:")
for i in range(3):
    idx = indices_tries[-(i+1)]
    print(f"  Startup {idx}: RÃ©el={prob_reelles[idx]:.3f}, PrÃ©dit={predictions_finales[0,idx]:.3f}, Erreur={erreurs[idx]:.3f}")`,
          },
          {
            type: "warning",
            icon: "âš ï¸",
            title: "Backpropagation : l'algorithme qui a changÃ© le monde",
            content: `
                        <p><strong>ğŸŒ Impact rÃ©volutionnaire de la backpropagation :</strong></p>
                        
                        <p><strong>ğŸ“… Chronologie historique :</strong></p>
                        <ul>
                            <li>ğŸ“š <strong>1986</strong> : Rumelhart, Hinton & Williams formalisent l'algorithme</li>
                            <li>ğŸ§  <strong>1990s</strong> : Premiers succÃ¨s sur problÃ¨mes simples</li>
                            <li>ğŸ’» <strong>2000s</strong> : Limitations computationnelles</li>
                            <li>ğŸš€ <strong>2010s</strong> : Renaissance avec GPU et big data</li>
                            <li>ğŸŒŸ <strong>2020s</strong> : Transformers et LLMs rÃ©volutionnent tout</li>
                        </ul>
                        
                        <p><strong>ğŸ¯ Pourquoi rÃ©volutionnaire ?</strong></p>
                        <ul>
                            <li>ğŸ§® <strong>EfficacitÃ© computationnelle</strong> : O(paramÃ¨tres) au lieu de O(exponentiel)</li>
                            <li>ğŸ¯ <strong>PrÃ©cision mathÃ©matique</strong> : gradients exacts, pas d'approximation</li>
                            <li>ğŸ”„ <strong>GÃ©nÃ©ralitÃ©</strong> : fonctionne pour toute architecture diffÃ©rentiable</li>
                            <li>âš¡ <strong>ParallÃ©lisation</strong> : parfait pour les GPU modernes</li>
                        </ul>
                        
                        <p><strong>ğŸš€ Applications qui ont changÃ© le monde :</strong></p>
                        <ul>
                            <li>ğŸ–¼ï¸ <strong>Vision par ordinateur</strong> : reconnaissance faciale, diagnostic mÃ©dical</li>
                            <li>ğŸ’¬ <strong>Traitement du langage</strong> : traduction, ChatGPT, assistants vocaux</li>
                            <li>ğŸ® <strong>IA de jeux</strong> : AlphaGo, AlphaStar, OpenAI Five</li>
                            <li>ğŸš— <strong>VÃ©hicules autonomes</strong> : Tesla, Waymo</li>
                            <li>ğŸ¨ <strong>IA gÃ©nÃ©rative</strong> : DALL-E, Midjourney, Stable Diffusion</li>
                        </ul>
                        
                        <p><strong>ğŸ’¡ Point clÃ© :</strong> Backpropagation n'est pas juste un algorithme technique - c'est <strong>l'algorithme qui a rendu possible l'IA moderne</strong>. Sans lui, pas de deep learning, pas de ChatGPT, pas de rÃ©volution IA !</p>
                        
                        <p><strong>ğŸ”® Prochaine Ã©tape :</strong> CNN - comment appliquer ces rÃ©seaux Ã  la vision par ordinateur !</p>
                    `,
          },
        ],
        quiz: {
          question:
            "ğŸ¤” Pourquoi la backpropagation utilise-t-elle la rÃ¨gle de dÃ©rivation en chaÃ®ne ?",
          options: [
            "A) Pour calculer plus rapidement",
            "B) Pour propager l'erreur de la sortie vers l'entrÃ©e couche par couche",
            "C) Pour Ã©viter les calculs matriciels",
            "D) Pour initialiser les poids correctement",
          ],
          correct: 1,
          explanation:
            "La backpropagation utilise la rÃ¨gle de dÃ©rivation en chaÃ®ne pour calculer comment l'erreur de sortie se propage vers chaque paramÃ¨tre du rÃ©seau. Cela permet de calculer le gradient exact de la fonction de coÃ»t par rapport Ã  chaque poids, mÃªme dans des rÃ©seaux trÃ¨s profonds.",
        },
        prevModule: "neural-networks.html",
        nextModule: "cnn.html",
      };

      // Initialiser le module
      document.addEventListener("DOMContentLoaded", function () {
        initializeModule(moduleConfig);
      });
    </script>
  </body>
</html>
